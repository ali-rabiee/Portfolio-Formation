{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZlSMQU35o0K8"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-rabiee/Portfolio-Formation/blob/DQN/DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements & Packages"
      ],
      "metadata": {
        "id": "_weG2085js1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install Keras\n",
        "!pip3 install keras-rl\n",
        "!pip install tensorflow==1.15\n",
        "!pip install keras\n",
        "!pip install keras-rl\n",
        "!pip install gym\n",
        "!pip install pandas\n",
        "!pip install rl\n",
        "!pip install keras-rl2\n",
        "!pip install callbacks \n",
        "!pip install tf-nightly"
      ],
      "metadata": {
        "id": "tO48s139j1ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enviroment"
      ],
      "metadata": {
        "id": "ZlSMQU35o0K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MergedDataStructure"
      ],
      "metadata": {
        "id": "o9vXtGVO_ddA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MergedDataStructure.py\n",
        "'''\n",
        "# Library used to manipulate the CSV Dataset\n",
        "# organize the dataset for the Enviroment\n",
        "import pandas\n",
        "\n",
        "#Library used to manipulate dates\n",
        "import datetime\n",
        "\n",
        "class MergedDataStructure():\n",
        "\n",
        "    def __init__(self, delta=4, filename=\"sp500Week.csv\"):\n",
        "        self.delta=delta\n",
        "\n",
        "        #Read the CSV\n",
        "        timeserie = pandas.read_csv(filename)\n",
        "        \n",
        "        #Transform each column into a list\n",
        "        Date = timeserie.loc[:, 'Date'].tolist()\n",
        "        Time = timeserie.loc[:, 'Time'].tolist()\n",
        "        Open = timeserie.loc[:, 'Open'].tolist()\n",
        "        High = timeserie.loc[:, 'High'].tolist()\n",
        "        Low = timeserie.loc[:, 'Low'].tolist()\n",
        "        Close = timeserie.loc[:, 'Close'].tolist()\n",
        "\n",
        "        #Create empty list and dictionary\n",
        "        self.list=[]\n",
        "        self.dict={}\n",
        "\n",
        "        #The limit is the number of dates\n",
        "        limit = len(Date)\n",
        "\n",
        "        #Just converting pandas data to a list\n",
        "        #lets pick up the csv data and put them in the list (self.list) \n",
        "        for i in range(0,limit-1):\n",
        "            self.list.append({'Date' : Date[i],'Time' : Time[i], 'Open': Open[i], 'High': High[i], 'Low': Low[i], 'Close': Close[i]})\n",
        "            \n",
        "            #Fill the gaps with days that do not exist \n",
        "            dateList = [datetime.datetime.strptime(Date[i+1], \"%m/%d/%Y\") - datetime.timedelta(days=x) for x in range(0, ( datetime.datetime.strptime(Date[i+1], \"%m/%d/%Y\")- datetime.datetime.strptime(Date[i], \"%m/%d/%Y\") ).days )]\n",
        "            \n",
        "            for date in dateList:\n",
        "                dateString=date.strftime(\"%m/%d/%Y\")\n",
        "                #Contains dates and indexes for the list self.list\n",
        "                self.dict[dateString]=i\n",
        "\n",
        "    def get(self, date):\n",
        "        #Converts the date to string\n",
        "        dateString=str(date)\n",
        "        #given the date, you get an interval of past days or weeks\n",
        "        return self.list[self.dict[dateString]-(self.delta):self.dict[dateString]]"
      ],
      "metadata": {
        "id": "suBLM3zNo285"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback"
      ],
      "metadata": {
        "id": "3Kv-fhwc_grp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Callback.py\n",
        "'''\n",
        "\n",
        "#Callbacks are functions used to give a feedback about each epoch calculated metrics\n",
        "from rl.callbacks import Callback\n",
        "\n",
        "class ValidationCallback(Callback):\n",
        "\n",
        "    def __init__(self):\n",
        "        #Initially, the metrics are zero\n",
        "        self.episodes = 0\n",
        "        self.rewardSum = 0\n",
        "        self.accuracy = 0\n",
        "        self.coverage = 0\n",
        "        self.short = 0\n",
        "        self.long = 0\n",
        "        self.shortAcc =0\n",
        "        self.longAcc =0\n",
        "        self.longPrec =0\n",
        "        self.shortPrec =0\n",
        "        self.marketRise =0\n",
        "        self.marketFall =0\n",
        "\n",
        "    def reset(self):\n",
        "        #The metrics are also zero when the epoch ends\n",
        "        self.episodes = 0\n",
        "        self.rewardSum = 0\n",
        "        self.accuracy = 0\n",
        "        self.coverage = 0\n",
        "        self.short = 0\n",
        "        self.long = 0\n",
        "        self.shortAcc =0\n",
        "        self.longAcc =0\n",
        "        self.longPrec =0\n",
        "        self.shortPrec =0\n",
        "        self.marketRise =0\n",
        "        self.marketFall =0\n",
        "        \n",
        "    #all information is given by the environment: action, reward and market\n",
        "    #Then, when the episode ends, metrics are calculated\n",
        "    def on_episode_end(self, action, reward, market):\n",
        "        \n",
        "        #After the episode ends, increments the episodes \n",
        "        self.episodes+=1\n",
        "\n",
        "        #Increments the reward\n",
        "        self.rewardSum+=reward\n",
        "\n",
        "        #If the action is not a hold, there is coverage because the agent decided \n",
        "        self.coverage+=1 if (action != 0) else 0\n",
        "\n",
        "        #increments the accuracy if the reward is positive (we have a hit)\n",
        "        self.accuracy+=1 if (reward >= 0 and action != 0) else 0\n",
        "        \n",
        "        #Increments the counter for short if the action is a short (id 2)\n",
        "        self.short +=1 if(action == 2) else 0\n",
        "        \n",
        "        #Increments the counter for long if the action is a long (id 1)\n",
        "        self.long +=1 if(action == 1) else 0\n",
        "        \n",
        "        #We will also calculate the accuracy for a given action. Here, it increments\n",
        "        #the accuracy for short if the action is short and the reward is positive\n",
        "        self.shortAcc +=1 if(action == 2 and reward >=0) else 0\n",
        "        \n",
        "        #Increments the accuracy for long if the action is long and the reward is positive\n",
        "        self.longAcc +=1 if(action == 1 and reward >=0) else 0\n",
        "        \n",
        "        #If the market increases, increments the marketRise variable. If the prediction is 1 (long), increments the precision for long\n",
        "        if(market>0):\n",
        "            self.marketRise+=1\n",
        "            self.longPrec+=1 if(action == 1) else 0\n",
        "\n",
        "        #If market decreases, increments the marketFall. If the prediction is 2 (short), increments the precision for short   \n",
        "        elif(market<0):\n",
        "            self.marketFall+=1\n",
        "            self.shortPrec+=1 if(action == 2) else 0\n",
        "\n",
        "    #Function to show the metrics of the episode  \n",
        "    def getInfo(self):\n",
        "        #Start setting them to zero\n",
        "        acc = 0\n",
        "        cov = 0\n",
        "        short = 0\n",
        "        long = 0\n",
        "        longAcc = 0\n",
        "        shortAcc = 0\n",
        "        longPrec = 0\n",
        "        shortPrec = 0\n",
        "        \n",
        "        #If there is coverage, we will calculate the accuracy only related to when decisions were made. \n",
        "        #In other words, we dont calculate accuracy for hold operations\n",
        "        if self.coverage > 0:\n",
        "            acc = self.accuracy/self.coverage\n",
        "        \n",
        "        #Now, we calculate the mean coverage, short and long operations from the episodes\n",
        "        if self.episodes > 0:\n",
        "            cov = self.coverage/self.episodes\n",
        "            short = self.short/self.episodes\n",
        "            long = self.long/self.episodes\n",
        "\n",
        "        #Calculate the mean accuracy for short operations. \n",
        "        #That is, the number of total short correctly predicted (self.shortAcc) \n",
        "        #divided by the total of shorts predicted (self.short)\n",
        "        if self.short > 0:\n",
        "            shortAcc = self.shortAcc/self.short\n",
        "        \n",
        "        #Calculate the mean accuracy for long operations. \n",
        "        #That is, the number of total short correctly predicted (long.shortAcc) \n",
        "        #divided by the total of longs predicted (long.short) \n",
        "        if self.long > 0:\n",
        "            longAcc = self.longAcc/self.long\n",
        "\n",
        "        if self.marketRise > 0:\n",
        "            longPrec = self.longPrec/self.marketRise\n",
        "\n",
        "        if self.marketFall > 0:\n",
        "            shortPrec = self.shortPrec/self.marketFall\n",
        "\n",
        "        #Returns the metrics to the user    \n",
        "        return self.episodes,cov,acc,self.rewardSum,long,short,longAcc,shortAcc,longPrec,shortPrec"
      ],
      "metadata": {
        "id": "iVfzIUkPpQh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## spEnv"
      ],
      "metadata": {
        "id": "EwYvhtPN_ldD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "spEnv.py\n",
        "'''\n",
        "#Environment used for spenv \n",
        "#gym is the library of videogames used by reinforcement learning\n",
        "import gym\n",
        "from gym import spaces\n",
        "#Numpy is the library to deal with matrices\n",
        "import numpy\n",
        "#Pandas is the library used to deal with the CSV dataset\n",
        "import pandas\n",
        "#datetime is the library used to manipulate time and date\n",
        "from datetime import datetime\n",
        "#Library created by Tonio to merge data used as feature vectors\n",
        "# from mergedDataStructure import MergedDataStructure\n",
        "#Callback is the library used to show metrics \n",
        "# import callback\n",
        "\n",
        "#This is the prefix of the files that will be opened. It is related to the s&p500 stock market datasets\n",
        "MK = \"dax\"\n",
        "\n",
        "\n",
        "class SpEnv(gym.Env):\n",
        "    #Just for the gym library. In a continuous environment, you can do infinite decisions. \n",
        "    #We dont want this because we have just three possible actions.\n",
        "    continuous = False\n",
        "\n",
        "    #Observation window is the time window regarding the \"hourly\" dataset \n",
        "    #ensemble variable tells to save or not the decisions at each walk\n",
        "    def __init__(self, minLimit=None, maxLimit=None, operationCost = 0, observationWindow = 40, ensamble = None, callback = None, isOnlyShort=False, columnName = \"iteration-1\"):\n",
        "        #Declare the episode as the first episode\n",
        "        self.episode=1\n",
        "\n",
        "        self.isOnlyShort=isOnlyShort\n",
        "        \n",
        "        #Open the time series as the hourly dataset of S&P500\n",
        "        #the input feature vector is composed of data from hours, weeks and days\n",
        "        #20 from days, 8 from weeks and 40 hours, ending with 68 dimensional feature vectors\n",
        "        spTimeserie = pandas.read_csv('./datasets/'+MK+'Hour.csv')[minLimit:maxLimit] # opening the dataset\n",
        "        \n",
        "        #Converts each column to a list\n",
        "        Date = spTimeserie.loc[:, 'Date'].tolist()\n",
        "        Time = spTimeserie.loc[:, 'Time'].tolist()\n",
        "        Open = spTimeserie.loc[:, 'Open'].tolist()\n",
        "        High = spTimeserie.loc[:, 'High'].tolist()\n",
        "        Low = spTimeserie.loc[:, 'Low'].tolist()\n",
        "        Close = spTimeserie.loc[:, 'Close'].tolist()\n",
        "        \n",
        "        #Open the weekly and daily data as a merged data structure\n",
        "        #Get 20 dimensional vectors (close-open) considering 20 past days and 8 dimensional vectors (close-open) \n",
        "        #considering 8 weeks\n",
        "        self.weekData = MergedDataStructure(delta=8,filename='./datasets/'+MK+\"Week.csv\")# this DS allows me to obtain previous historical data with different resolution\n",
        "        self.dayData = MergedDataStructure(delta=20,filename='./datasets/'+MK+\"Day.csv\")#  with low computational complexity\n",
        "        \n",
        "        #Load the data\n",
        "        self.output=False\n",
        "\n",
        "        #ensamble is the table of validation and testing\n",
        "        #If its none, you will not save csvs of validation and testing    \n",
        "        if(ensamble is not None): # managing the ensamble output (maybe in the wrong way)\n",
        "            self.output=True\n",
        "            self.ensamble=ensamble\n",
        "            self.columnName = columnName\n",
        "            #self.ensemble is a big table (before file writing) containing observations as lines and epochs as columns\n",
        "            #each column will contain a decision for each epoch at each date. It is saved later.\n",
        "            #We read this table later in order to make ensemble decisions at each epoch\n",
        "            self.ensamble[self.columnName]=0\n",
        "\n",
        "        #Declare low and high as vectors with -inf values \n",
        "        self.low = numpy.array([-numpy.inf])\n",
        "        self.high = numpy.array([+numpy.inf])\n",
        "\n",
        "        #Define the space of actions as 3\n",
        "        #the action space is just 0,1,2 which means hold,long,short\n",
        "        self.action_space = spaces.Discrete(3) \n",
        "        \n",
        "        #low and high are the minimun and maximum accepted values for this problem\n",
        "        #Tonio used random values\n",
        "        #We dont know what are the minimum and maximum values of Close-Open, so we put these values\n",
        "        self.observation_space = spaces.Box(self.low, self.high, dtype=numpy.float32)\n",
        "\n",
        "        #The history begins empty\n",
        "        self.history=[]\n",
        "        #Set observationWindow = 40\n",
        "        self.observationWindow = observationWindow\n",
        "        \n",
        "        #Set the current observation as 40\n",
        "        self.currentObservation = observationWindow\n",
        "        #The operation cost is defined as \n",
        "        self.operationCost=operationCost\n",
        "        #Defines that the environment is not done yet\n",
        "        self.done = False\n",
        "        #The limit is the number of open values in the dataset (could be any other value)\n",
        "        self.limit = len(Open)\n",
        "        #organizing the dataset as a list of dictionaries \n",
        "        for i in range(0,self.limit): \n",
        "            self.history.append({'Date' : Date[i],'Time' : Time[i], 'Open': Open[i], 'High': High[i], 'Low': Low[i], 'Close': Close[i]})\n",
        "        \n",
        "        #Next observation starts\n",
        "        self.nextObservation=0\n",
        "        \n",
        "        #self.history contains all the hour data. Here we search for the next day \n",
        "        while(self.history[self.currentObservation]['Date']==self.history[(self.currentObservation+self.nextObservation)%self.limit]['Date']):\n",
        "            self.nextObservation+=1\n",
        "        \n",
        "        #Initiates the values to be returned by the environment\n",
        "        self.reward = None\n",
        "        self.possibleGain = 0\n",
        "        self.openValue = 0\n",
        "        self.closeValue = 0\n",
        "        self.callback=callback\n",
        "\n",
        "\n",
        "    #This is the action that is done in the environment. \n",
        "    #Receives the action and returns the state, the reward and if its done \n",
        "    def step(self, action):\n",
        "        #Initiates the reward, weeklist and daylist\n",
        "        self.reward=0\n",
        "        \n",
        "\n",
        "        ##UNCOMMENT NEXT LINE FOR ONLY SHORT AGENT\n",
        "        if(self.isOnlyShort):\n",
        "            action *= 2\n",
        "\n",
        "\n",
        "        #set the next observation to zero\n",
        "        self.nextObservation=0\n",
        "        #Search for the close value for tommorow\n",
        "        while(self.history[self.currentObservation]['Date']==self.history[(self.currentObservation+self.nextObservation)%self.limit]['Date']):\n",
        "            #Search for the close error for today\n",
        "            self.closeValue=self.history[(self.currentObservation+self.nextObservation)%self.limit]['Close']\n",
        "            self.nextObservation+=1\n",
        "\n",
        "        #Get the open value for today \n",
        "        self.openValue = self.history[self.currentObservation]['Open']\n",
        "\n",
        "        #Calculate the reward in percentage of growing/decreasing\n",
        "        self.possibleGain = (self.closeValue - self.openValue)/self.openValue\n",
        "        #If action is a long, calculate the reward \n",
        "        if(action == 1):\n",
        "            #The reward must be subtracted by the cost of transaction\n",
        "            self.reward = self.possibleGain-self.operationCost\n",
        "        #If action is a short, calculate the reward     \n",
        "        elif(action==2):\n",
        "            self.reward = (-self.possibleGain)-self.operationCost\n",
        "        #If action is a hold, no reward     \n",
        "        else:\n",
        "            self.reward = 0\n",
        "        #Finish episode \n",
        "        self.done=True\n",
        "\n",
        "\n",
        "        #Call the callback for the episode\n",
        "        if(self.callback!=None and self.done):\n",
        "            self.callback.on_episode_end(action,self.reward,self.possibleGain)\n",
        "        \n",
        "\n",
        "        #File of the ensamble (file containing each epoch decisions at each walk) will contain the action for that \n",
        "        #day (observation, line) at each epoch (column)\n",
        "        if(self.output):\n",
        "            self.ensamble.at[self.history[self.currentObservation]['Date'],self.columnName]=action\n",
        "        \n",
        "        \n",
        "        \n",
        "        #Return the state, reward and if its done or not\n",
        "        return self.getObservation(self.history[self.currentObservation]['Date']), self.reward, self.done, {}\n",
        "        \n",
        "    #function done when the episode finishes\n",
        "    #reset will prepare the next state (feature vector) and give it to the agent\n",
        "    def reset(self):\n",
        "\n",
        "        if(self.currentObservation<self.observationWindow):\n",
        "            self.currentObservation=self.observationWindow\n",
        "\n",
        "\n",
        "        \n",
        "        self.episode+=1\n",
        "        \n",
        "        \n",
        "        #Shiftting the index for the first hour of the next day\n",
        "        self.nextObservation=0\n",
        "        while(self.history[self.currentObservation]['Date']==self.history[(self.currentObservation+self.nextObservation)%self.limit]['Date']):\n",
        "            self.nextObservation+=1\n",
        "            #check if the index exceeds the limits\n",
        "            if((self.currentObservation+self.nextObservation)>=self.limit):\n",
        "                print(\"Resetted: episode \" + str(self.episode) +\"; Index \" + str(self.currentObservation+self.nextObservation) + \" over the limit (\" + str(self.limit) + \")\" )\n",
        "            \n",
        "        #reset the values used in the step() function\n",
        "        self.done = False\n",
        "        self.reward = None\n",
        "        self.possibleGain = 0\n",
        "        self.openValue = 0\n",
        "        self.closeValue = 0\n",
        "\n",
        "        #Prepapre to get the next observation\n",
        "        self.currentObservation+=self.nextObservation\n",
        "        if(self.currentObservation>=self.limit):\n",
        "            self.currentObservation=self.observationWindow\n",
        "        \n",
        "        return self.getObservation(self.history[self.currentObservation]['Date'])\n",
        "\n",
        "\n",
        "    def getObservation(self, date):\n",
        "\n",
        "        #Get the dayly information and week information\n",
        "        #get all the data\n",
        "        # dayList=self.dayData.get(date)\n",
        "        # weekList=self.weekData.get(date)\n",
        "\n",
        "        #Get the previous 40 hours regarding each date\n",
        "        # currentData = self.history[self.currentObservation-self.observationWindow:self.currentObservation] \n",
        "\n",
        "        #The data is finally concatenated here. We concatenate Hours, days and weeks information\n",
        "        # currentData=self.history[self.currentObservation-self.observationWindow:self.currentObservation]  + self.dayData.get(date) + self.weekData.get(date)\n",
        "\n",
        "        #Calculates the close minus open \n",
        "        #The percentage of growing or decreasing is calculated as CloseMinusOpen\n",
        "        #This is the input vector\n",
        "        # closeMinusOpen=list(map(lambda x: (x[\"Close\"]-x[\"Open\"])/x[\"Open\"],self.history[self.currentObservation-self.observationWindow:self.currentObservation]  + self.dayData.get(date) + self.weekData.get(date)))\n",
        "        \n",
        "        \n",
        "        #The state is prepared by the environment, which is simply the feature vector\n",
        "        return  numpy.array(\n",
        "            [list(\n",
        "                map(\n",
        "                    lambda x: (x[\"Close\"]-x[\"Open\"])/x[\"Open\"],\n",
        "                        self.history[self.currentObservation-self.observationWindow:self.currentObservation]  + \n",
        "                        self.dayData.get(date) + \n",
        "                        self.weekData.get(date)))])\n",
        "    \n",
        "    def resetEnv(self):\n",
        "        self.currentObservation=self.observationWindow\n",
        "        #Resets the episode to 1\n",
        "        self.episode=1"
      ],
      "metadata": {
        "id": "DMHIYTs3rsJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trading"
      ],
      "metadata": {
        "id": "GwdGjA34GIBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code needs three positional parameters to be correctly executed: \\\\\n",
        "python main.py [numberOfActions, isOnlyShort, ensembleFolder]\n",
        "\n",
        "\n",
        "* To run the FULL agent you need to run: python main.py 3 0 ensembleFolder\n",
        "* To run the ONLY LONG agent you need to run: python main.py 2 0 ensembleFolder\n",
        "* To run the ONLY SHORT agent you need to run: python main.py 2 1 ensembleFolder \\\\\n",
        "where the paramenter ensembleFolder is used to set the name of the folder in which you'll get your results."
      ],
      "metadata": {
        "id": "56xe9An9nMDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeepQTrading"
      ],
      "metadata": {
        "id": "VXdjyJFQzAo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "deepQTrading.py\n",
        "'''\n",
        "#Imports the SPEnv library, which will perform the Agent actions themselves\n",
        "# from spEnv import SpEnv\n",
        "\n",
        "#Callback used to print the results at each episode\n",
        "# from callback import ValidationCallback\n",
        "\n",
        "#Keras library for the NN considered\n",
        "from keras.models import Sequential\n",
        "\n",
        "#Keras libraries for layers, activations and optimizers used\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#RL Agent \n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "\n",
        "#Mathematical operations used later\n",
        "from math import floor\n",
        "\n",
        "#Library to manipulate the dataset in a csv file\n",
        "import pandas as pd\n",
        "\n",
        "#Library used to manipulate time\n",
        "import datetime\n",
        "\n",
        "\n",
        "#Prefix of the name of the market (S&P500) files used to load the data\n",
        "MK=\"dax\"\n",
        "\n",
        "class DeepQTrading:\n",
        "    \n",
        "    #Class constructor\n",
        "    #model: Keras model considered\n",
        "    #Explorations is a vector containing (i) probability of random predictions; (ii) how many epochs will be \n",
        "    # runned by the algorithm (we run the algorithm several times-several iterations)  \n",
        "    #trainSize: size of the training set\n",
        "    #validationSize: size of the validation set\n",
        "    #testSize: size of the testing set \n",
        "    #outputFile: name of the file to print results\n",
        "    #begin: Initial date\n",
        "    #end: final date\n",
        "    #nbActions: number of decisions (0-Hold 1-Long 2-Short) \n",
        "    #nOutput is the number of walks. We are doing 5 walks.  \n",
        "    #operationCost: Price for the transaction (we set they are free)\n",
        "    def __init__(self, model, explorations, trainSize, validationSize, testSize, outputFile, begin, end, nbActions, isOnlyShort, ensembleFolderName, operationCost=0):\n",
        "        \n",
        "        self.isOnlyShort=isOnlyShort\n",
        "        self.ensembleFolderName=ensembleFolderName\n",
        "\n",
        "        \n",
        "\n",
        "        #Define the policy, explorations, actions and model as received by parameters\n",
        "        self.policy = EpsGreedyQPolicy()\n",
        "        self.explorations=explorations\n",
        "        self.nbActions=nbActions\n",
        "        self.model=model\n",
        "\n",
        "        #Define the memory\n",
        "        self.memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "        #Instantiate the agent with parameters received\n",
        "        self.agent = DQNAgent(model=self.model, policy=self.policy,  nb_actions=self.nbActions, memory=self.memory, nb_steps_warmup=200, target_model_update=1e-1,\n",
        "                                    enable_double_dqn=True,enable_dueling_network=True)\n",
        "        \n",
        "        #Compile the agent with the adam optimizer and with the mean absolute error metric\n",
        "        self.agent.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "        #Save the weights of the agents in the q.weights file\n",
        "        #Save random weights\n",
        "        self.agent.save_weights(\"q.weights\", overwrite=True)\n",
        "\n",
        "        #Define the current starting point as the initial date\n",
        "        self.currentStartingPoint = begin\n",
        "\n",
        "        #Define the training, validation and testing size as informed by the call\n",
        "        #Train: 5 years\n",
        "        #Validation: 6 months\n",
        "        #Test: 6 months\n",
        "        self.trainSize=trainSize\n",
        "        self.validationSize=validationSize\n",
        "        self.testSize=testSize\n",
        "        \n",
        "        #The walk size is simply summing up the train, validation and test sizes\n",
        "        self.walkSize=trainSize+validationSize+testSize\n",
        "        \n",
        "        #Define the ending point as the final date (January 1st of 2010)\n",
        "        self.endingPoint=end\n",
        "\n",
        "        #Read the hourly dataset\n",
        "        #We join data from different files\n",
        "        #Here hour data is read \n",
        "        self.dates= pd.read_csv('./datasets/'+MK+'Hour.csv')\n",
        "        self.sp = pd.read_csv('./datasets/'+MK+'Hour.csv')\n",
        "        #Convert the pandas format to date and time format\n",
        "        self.sp['Datetime'] = pd.to_datetime(self.sp['Date'] + ' ' + self.sp['Time'])\n",
        "        #Set an index to Datetime on the pandas loaded dataset. Registers will be indexes through these values\n",
        "        self.sp = self.sp.set_index('Datetime')\n",
        "        #Drop Time and Date from the Dataset\n",
        "        self.sp = self.sp.drop(['Time','Date'], axis=1)\n",
        "        #Just the index considering date and time will be important, because date and time will be used to define the train, \n",
        "        #validation and test for each walk\n",
        "        self.sp = self.sp.index\n",
        "\n",
        "        #Receives the operation cost, which is 0\n",
        "        #Operation cost is the cost for long and short. It is defined as zero\n",
        "        self.operationCost = operationCost\n",
        "        \n",
        "        #Call the callback for training, validation and test in order to show results for each episode \n",
        "        self.trainer=ValidationCallback()\n",
        "        self.validator=ValidationCallback()\n",
        "        self.tester=ValidationCallback()\n",
        "        self.outputFileName=outputFile\n",
        "\n",
        "    def run(self):\n",
        "        #Initiates the environments, \n",
        "        trainEnv=validEnv=testEnv=\" \"\n",
        "        \n",
        "        iteration=-1\n",
        "\n",
        "        #While we did not pass through all the dates (i.e., while all the walks were not finished)\n",
        "        #walk size is train+validation+test size\n",
        "        #currentStarting point begins with begin date\n",
        "        while(self.currentStartingPoint+self.walkSize <= self.endingPoint):\n",
        "\n",
        "            #Iteration is the current walk\n",
        "            iteration+=1\n",
        "\n",
        "            #Initiate the output file\n",
        "            self.outputFile=open(self.outputFileName+str(iteration+1)+\".csv\", \"w+\")\n",
        "            #write the first row of the csv\n",
        "            self.outputFile.write(\n",
        "                \"Iteration,\"+\n",
        "                \"trainAccuracy,\"+\n",
        "                \"trainCoverage,\"+\n",
        "                \"trainReward,\"+\n",
        "                \"trainLong%,\"+\n",
        "                \"trainShort%,\"+\n",
        "                \"trainLongAcc,\"+\n",
        "                \"trainShortAcc,\"+\n",
        "                \"trainLongPrec,\"+\n",
        "                \"trainShortPrec,\"+\n",
        "\n",
        "                \"validationAccuracy,\"+\n",
        "                \"validationCoverage,\"+\n",
        "                \"validationReward,\"+\n",
        "                \"validationLong%,\"+\n",
        "                \"validationShort%,\"+\n",
        "                \"validationLongAcc,\"+\n",
        "                \"validationShortAcc,\"+\n",
        "                \"validLongPrec,\"+\n",
        "                \"validShortPrec,\"+\n",
        "                \n",
        "                \"testAccuracy,\"+\n",
        "                \"testCoverage,\"+\n",
        "                \"testReward,\"+\n",
        "                \"testLong%,\"+\n",
        "                \"testShort%,\"+\n",
        "                \"testLongAcc,\"+\n",
        "                \"testShortAcc,\"+\n",
        "                \"testLongPrec,\"+\n",
        "                \"testShortPrec\\n\")\n",
        "\n",
        "\n",
        "            \n",
        "            #Empty the memory and agent\n",
        "            del(self.memory)\n",
        "            del(self.agent)\n",
        "\n",
        "            #Define the memory and agent\n",
        "            #Memory is Sequential\n",
        "            self.memory = SequentialMemory(limit=10000, window_length=1)\n",
        "            #Agent is initiated as passed through parameters\n",
        "            self.agent = DQNAgent(model=self.model, policy=self.policy,  nb_actions=self.nbActions, memory=self.memory, nb_steps_warmup=200, target_model_update=1e-1,\n",
        "                                    enable_double_dqn=True,enable_dueling_network=True)\n",
        "            #Compile the agent with Adam initialization\n",
        "            self.agent.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "            \n",
        "            #Load the weights saved before in a random way if it is the first time\n",
        "            self.agent.load_weights(\"q.weights\")\n",
        "            \n",
        "            ########################################TRAINING STAGE########################################################\n",
        "            \n",
        "            #The TrainMinLimit will be loaded as the initial date at the beginning, and will be updated later.\n",
        "            #If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date    \n",
        "            trainMinLimit=None\n",
        "            while(trainMinLimit is None):\n",
        "                try:\n",
        "                    trainMinLimit = self.sp.get_loc(self.currentStartingPoint)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0,0,0,0,0,1,0)\n",
        "\n",
        "            #The TrainMaxLimit will be loaded as the interval between the initial date plus the training size.\n",
        "            #If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date    \n",
        "            trainMaxLimit=None\n",
        "            while(trainMaxLimit is None):\n",
        "                try:\n",
        "                    trainMaxLimit = self.sp.get_loc(self.currentStartingPoint+self.trainSize)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0,0,0,0,0,1,0)\n",
        "            \n",
        "            ########################################VALIDATION STAGE#######################################################\n",
        "            #The ValidMinLimit will be loaded as the next element of the TrainMax limit\n",
        "            validMinLimit=trainMaxLimit+1\n",
        "\n",
        "            #The ValidMaxLimit will be loaded as the interval after the begin + train size +validation size\n",
        "            #If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date  \n",
        "            validMaxLimit=None\n",
        "            while(validMaxLimit is None):\n",
        "                try:\n",
        "                    validMaxLimit = self.sp.get_loc(self.currentStartingPoint+self.trainSize+self.validationSize)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0,0,0,0,0,1,0)\n",
        "\n",
        "            ########################################TESTING STAGE######################################################## \n",
        "            #The TestMinLimit will be loaded as the next element of ValidMaxlimit \n",
        "            testMinLimit=validMaxLimit+1\n",
        "\n",
        "            #The testMaxLimit will be loaded as the interval after the begin + train size +validation size + Testsize\n",
        "            #If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date \n",
        "            testMaxLimit=None\n",
        "            while(testMaxLimit is None):\n",
        "                try:\n",
        "                    testMaxLimit = self.sp.get_loc(self.currentStartingPoint+self.trainSize+self.validationSize+self.testSize)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0,0,0,0,0,1,0)\n",
        "\n",
        "            #Separate the Validation and testing data according to the limits found before\n",
        "            #Prepare the training and validation files for saving them later \n",
        "            ensambleValid=pd.DataFrame(index=self.dates[validMinLimit:validMaxLimit].loc[:,'Date'].drop_duplicates().tolist())\n",
        "            ensambleTest=pd.DataFrame(index=self.dates[testMinLimit:testMaxLimit].loc[:,'Date'].drop_duplicates().tolist())\n",
        "            \n",
        "            #Put the name of the index for validation and testing\n",
        "            ensambleValid.index.name='Date'\n",
        "            ensambleTest.index.name='Date'\n",
        "            \n",
        "            #Explorations are epochs considered, or how many times the agent will play the game.  \n",
        "            for eps in self.explorations:\n",
        "\n",
        "                #policy will be 0.2, so the randomness of predictions (actions) will happen with 20% of probability \n",
        "                self.policy.eps = eps[0]\n",
        "                \n",
        "                #there will be 100 iterations (epochs), or eps[1])\n",
        "                for i in range(0,eps[1]):\n",
        "                    \n",
        "                    del(trainEnv)\n",
        "\n",
        "                    #Define the training, validation and testing environments with their respective callbacks\n",
        "                    trainEnv = SpEnv(operationCost=self.operationCost,minLimit=trainMinLimit,maxLimit=trainMaxLimit,callback=self.trainer,isOnlyShort=self.isOnlyShort)\n",
        "                    del(validEnv)\n",
        "                    validEnv=SpEnv(operationCost=self.operationCost,minLimit=validMinLimit,maxLimit=validMaxLimit,callback=self.validator,isOnlyShort=self.isOnlyShort,ensamble=ensambleValid,columnName=\"iteration\"+str(i))\n",
        "                    del(testEnv)\n",
        "                    testEnv=SpEnv(operationCost=self.operationCost,minLimit=testMinLimit,maxLimit=testMaxLimit,callback=self.tester,isOnlyShort=self.isOnlyShort,ensamble=ensambleTest,columnName=\"iteration\"+str(i))\n",
        "\n",
        "                    #Reset the callback\n",
        "                    self.trainer.reset()\n",
        "                    self.validator.reset()\n",
        "                    self.tester.reset()\n",
        "\n",
        "                    #Reset the training environment\n",
        "                    trainEnv.resetEnv()\n",
        "                    #Train the agent\n",
        "                    self.agent.fit(trainEnv,nb_steps=floor(self.trainSize.days-self.trainSize.days*0.2),visualize=False,verbose=0)\n",
        "                    #Get the info from the train callback\n",
        "                    (_,trainCoverage,trainAccuracy,trainReward,trainLongPerc,trainShortPerc,trainLongAcc,trainShortAcc,trainLongPrec,trainShortPrec)=self.trainer.getInfo()\n",
        "                    #Print Callback values on the screen\n",
        "                    print(str(i) + \" TRAIN:  acc: \" + str(trainAccuracy)+ \" cov: \" + str(trainCoverage)+ \" rew: \" + str(trainReward))\n",
        "\n",
        "                    #Reset the validation environment\n",
        "                    validEnv.resetEnv()\n",
        "                    #Test the agent on validation data\n",
        "                    self.agent.test(validEnv,nb_episodes=floor(self.validationSize.days-self.validationSize.days*0.2),visualize=False,verbose=0)\n",
        "                    #Get the info from the validation callback\n",
        "                    (_,validCoverage,validAccuracy,validReward,validLongPerc,validShortPerc,validLongAcc,validShortAcc,validLongPrec,validShortPrec)=self.validator.getInfo()\n",
        "                    #Print callback values on the screen\n",
        "                    print(str(i) + \" VALID:  acc: \" + str(validAccuracy)+ \" cov: \" + str(validCoverage)+ \" rew: \" + str(validReward))\n",
        "\n",
        "                    #Reset the testing environment\n",
        "                    testEnv.resetEnv()\n",
        "                    #Test the agent on testing data\n",
        "                    self.agent.test(testEnv,nb_episodes=floor(self.validationSize.days-self.validationSize.days*0.2),visualize=False,verbose=0)\n",
        "                    #Get the info from the testing callback\n",
        "                    (_,testCoverage,testAccuracy,testReward,testLongPerc,testShortPerc,testLongAcc,testShortAcc,testLongPrec,testShortPrec)=self.tester.getInfo()\n",
        "                    #Print callback values on the screen\n",
        "                    print(str(i) + \" TEST:  acc: \" + str(testAccuracy)+ \" cov: \" + str(testCoverage)+ \" rew: \" + str(testReward))\n",
        "                    print(\" \")\n",
        "                    \n",
        "                    #write the walk data on the text file\n",
        "                    self.outputFile.write(\n",
        "                        str(i)+\",\"+\n",
        "                        str(trainAccuracy)+\",\"+\n",
        "                        str(trainCoverage)+\",\"+\n",
        "                        str(trainReward)+\",\"+\n",
        "                        str(trainLongPerc)+\",\"+\n",
        "                        str(trainShortPerc)+\",\"+\n",
        "                        str(trainLongAcc)+\",\"+\n",
        "                        str(trainShortAcc)+\",\"+\n",
        "                        str(trainLongPrec)+\",\"+\n",
        "                        str(trainShortPrec)+\",\"+\n",
        "                        \n",
        "                        str(validAccuracy)+\",\"+\n",
        "                        str(validCoverage)+\",\"+\n",
        "                        str(validReward)+\",\"+\n",
        "                        str(validLongPerc)+\",\"+\n",
        "                        str(validShortPerc)+\",\"+\n",
        "                        str(validLongAcc)+\",\"+\n",
        "                        str(validShortAcc)+\",\"+\n",
        "                        str(validLongPrec)+\",\"+\n",
        "                        str(validShortPrec)+\",\"+\n",
        "                        \n",
        "                        str(testAccuracy)+\",\"+\n",
        "                        str(testCoverage)+\",\"+\n",
        "                        str(testReward)+\",\"+\n",
        "                        str(testLongPerc)+\",\"+\n",
        "                        str(testShortPerc)+\",\"+\n",
        "                        str(testLongAcc)+\",\"+\n",
        "                        str(testShortAcc)+\",\"+\n",
        "                        str(testLongPrec)+\",\"+\n",
        "                        str(testShortPrec)+\"\\n\")\n",
        "\n",
        "            #Close the file                \n",
        "            self.outputFile.close()\n",
        "\n",
        "            #For the next walk, the current starting point will be the current starting point + the test size\n",
        "            #It means that, for the next walk, the training data will start 6 months after the training data of \n",
        "            #the previous walk   \n",
        "            self.currentStartingPoint+=self.testSize\n",
        "\n",
        "            #Write validation and Testing data into files\n",
        "            #Save the files for processing later with the ensemble considering the 100 epochs\n",
        "            ensambleValid.to_csv(\"./Output/ensemble/\"+self.ensembleFolderName+\"/walk\"+str(iteration)+\"ensemble_valid.csv\")\n",
        "            ensambleTest.to_csv(\"./Output/ensemble/\"+self.ensembleFolderName+\"/walk\"+str(iteration)+\"ensemble_test.csv\")\n",
        "\n",
        "    #Function to end the Agent\n",
        "    def end(self):\n",
        "        print(\"END\")"
      ],
      "metadata": {
        "id": "ik31bGTJxTS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main"
      ],
      "metadata": {
        "id": "hISBRm7HzF64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "main.py\n",
        "'''\n",
        "#os library is used to define the GPU to be used by the code, needed only in cerain situations (Better not to use it, use only if the main gpu is Busy)\n",
        "#import os\n",
        "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";\n",
        "\n",
        "#This is the class call for the Agent which will perform the experiment\n",
        "# from deepQTrading import DeepQTrading\n",
        "\n",
        "#Date library to manipulate time in the source code\n",
        "import datetime\n",
        "\n",
        "#Keras library to define the NN to be used\n",
        "from keras.models import Sequential\n",
        "\n",
        "#Layers used in the NN considered\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "\n",
        "#Activation Layers used in the source code\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU, ReLU\n",
        "\n",
        "#Optimizer used in the NN\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#Libraries used for the Agent considered\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "\n",
        "\n",
        "#Library used for showing the exception in the case of error \n",
        "import sys\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from keras.backend.tensorflow_backend import set_session\n",
        "#config = tf.ConfigProto()\n",
        "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "#set_session(tf.Session(config=config))\n",
        "\n",
        "\n",
        "\n",
        "#Let's capture the starting time and send it to the destination in order to tell that the experiment started \n",
        "startingTime=datetime.datetime.now()\n",
        "\n",
        "#There are three actions possible in the stock market\n",
        "#Hold(id 0): do nothing.\n",
        "#Long(id 1): It predicts that the stock market value will raise at the end of the day. \n",
        "#So, the action performed in this case is buying at the beginning of the day and sell it at the end of the day (aka long).\n",
        "#Short(id 2): It predicts that the stock market value will decrease at the end of the day.\n",
        "#So, the action that must be done is selling at the beginning of the day and buy it at the end of the day (aka short). \n",
        "\n",
        "nb_actions = 3\n",
        "isOnlyShort = 0\n",
        "ensembleFolderName = \"ensembleFolder\"\n",
        "\n",
        "#This is a simple NN considered. It is composed of:\n",
        "#One flatten layer to get 68 dimensional vectors as input\n",
        "#One dense layer with 35 neurons and LeakyRelu activation\n",
        "#One final Dense Layer with the 3 actions considered\n",
        "#the input is 20 observation days from the past, 8 observations from the past week and \n",
        "#40 observations from the past hours\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1,1,68)))\n",
        "model.add(Dense(35,activation='linear'))\n",
        "model.add(LeakyReLU(alpha=.001))\n",
        "model.add(Dense(nb_actions))\n",
        "model.add(Activation('linear'))\n",
        "\n",
        "\n",
        "#Define the DeepQTrading class with the following parameters:\n",
        "#explorations: 0.2 operations are random, and 100 epochs.\n",
        "#in this case, epochs parameter is used because the Agent acts on daily basis, so its better to repeat the experiments several\n",
        "#times so, its defined that each epoch will work on the data from training, validation and testing.\n",
        "#trainSize: the size of the train data gotten from the dataset, we are setting 5 stock market years, or 1800 days\n",
        "#validationSize: the size of the validation data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "#testSize: the size of the testing data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "#outputFile: where the results will be written\n",
        "#begin: where the walks will start from. We are defining January 1st of 2010\n",
        "#end: where the walks will finish. We are defining February 22nd of 2019\n",
        "#nOutput:number of walks\n",
        "dqt = DeepQTrading(\n",
        "    model=model,\n",
        "    explorations=[(0.2, 3)],\n",
        "    trainSize=datetime.timedelta(days=360*5),\n",
        "    validationSize=datetime.timedelta(days=30*6),\n",
        "    testSize=datetime.timedelta(days=30*6),\n",
        "    outputFile=\"./Output/csv/walks/walks\",\n",
        "    begin=datetime.datetime(2001,1,1,0,0,0,0),\n",
        "    end=datetime.datetime(2019,2,28,0,0,0,0),\n",
        "    nbActions=nb_actions,\n",
        "    isOnlyShort=isOnlyShort,\n",
        "    ensembleFolderName=ensembleFolderName\n",
        "    )\n",
        "\n",
        "dqt.run()\n",
        "\n",
        "dqt.end()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR_r2Ivdw-KN",
        "outputId": "ff4a81d6-20a0-4b7e-a5fa-951f1a894348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:109: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbd720d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbd720d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbd6e65f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbd6e65f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "./Output/csv/walks/walks1.csv\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbd6e6b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbd6e6b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbd3fc290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbd3fc290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "0 TRAIN:  acc: 0.5085836909871244 cov: 0.6472222222222223 rew: 0.42672165329658834\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "0 VALID:  acc: 0.4375 cov: 0.4444444444444444 rew: -0.0459412439842766\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "0 TEST:  acc: 0.5 cov: 0.2777777777777778 rew: 0.021415606148076714\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "1 TRAIN:  acc: 0.629950495049505 cov: 0.5611111111111111 rew: 3.2053990103932177\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "1 VALID:  acc: 0.4056603773584906 cov: 0.7361111111111112 rew: -0.09820788719873001\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "1 TEST:  acc: 0.5632183908045977 cov: 0.6041666666666666 rew: 0.1426291878337838\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "2 TRAIN:  acc: 0.6902050113895216 cov: 0.6097222222222223 rew: 4.842655218479314\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "2 VALID:  acc: 0.47692307692307695 cov: 0.4513888888888889 rew: 0.03995648167125638\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "2 TEST:  acc: 0.4927536231884058 cov: 0.4791666666666667 rew: 0.08005476772072082\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "3 TRAIN:  acc: 0.7148803329864725 cov: 0.6673611111111111 rew: 5.965434086496057\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "3 VALID:  acc: 0.384 cov: 0.8680555555555556 rew: -0.1394589564666072\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "3 TEST:  acc: 0.5327102803738317 cov: 0.7430555555555556 rew: 0.1453939658204004\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "4 TRAIN:  acc: 0.746031746031746 cov: 0.74375 rew: 6.721890087682815\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "4 VALID:  acc: 0.4791666666666667 cov: 0.6666666666666666 rew: -0.06673933476332047\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "4 TEST:  acc: 0.5979381443298969 cov: 0.6736111111111112 rew: 0.1991256889108173\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "5 TRAIN:  acc: 0.7623762376237624 cov: 0.7715277777777778 rew: 7.5341290008139215\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "5 VALID:  acc: 0.4112903225806452 cov: 0.8611111111111112 rew: -0.11100220629678936\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "5 TEST:  acc: 0.42342342342342343 cov: 0.7708333333333334 rew: -0.018856070585217002\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "6 TRAIN:  acc: 0.7747349823321554 cov: 0.7861111111111111 rew: 8.56930183582483\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "6 VALID:  acc: 0.5208333333333334 cov: 1.0 rew: -0.1242251779145201\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "6 TEST:  acc: 0.5407407407407407 cov: 0.9375 rew: 0.11458111727006638\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "7 TRAIN:  acc: 0.7871077184054284 cov: 0.81875 rew: 8.630697888613804\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "7 VALID:  acc: 0.43548387096774194 cov: 0.8611111111111112 rew: -0.06080463084476999\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "7 TEST:  acc: 0.4274193548387097 cov: 0.8611111111111112 rew: -0.11033933388638596\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "8 TRAIN:  acc: 0.7918032786885246 cov: 0.8472222222222222 rew: 8.829849854617477\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "8 VALID:  acc: 0.46511627906976744 cov: 0.8958333333333334 rew: -0.10363387448020692\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "8 TEST:  acc: 0.48031496062992124 cov: 0.8819444444444444 rew: -0.03621309148881889\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "9 TRAIN:  acc: 0.8053311793214862 cov: 0.8597222222222223 rew: 9.094649187883306\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "9 VALID:  acc: 0.45081967213114754 cov: 0.8472222222222222 rew: -0.08163034297396604\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "9 TEST:  acc: 0.484375 cov: 0.8888888888888888 rew: -0.09710258608469043\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "10 TRAIN:  acc: 0.8203497615262321 cov: 0.8736111111111111 rew: 9.789250196535571\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "10 VALID:  acc: 0.43410852713178294 cov: 0.8958333333333334 rew: -0.0848226422470667\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "10 TEST:  acc: 0.488 cov: 0.8680555555555556 rew: -0.0703467471463702\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "11 TRAIN:  acc: 0.8334655035685964 cov: 0.8756944444444444 rew: 10.159180063349435\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "11 VALID:  acc: 0.43548387096774194 cov: 0.8611111111111112 rew: -0.09396131008448837\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "11 TEST:  acc: 0.4789915966386555 cov: 0.8263888888888888 rew: -0.08129944069084082\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "12 TRAIN:  acc: 0.82265625 cov: 0.8888888888888888 rew: 9.655399785071296\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "12 VALID:  acc: 0.488 cov: 0.8680555555555556 rew: -0.017822095861078805\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "12 TEST:  acc: 0.515625 cov: 0.8888888888888888 rew: -0.037638693601692474\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "13 TRAIN:  acc: 0.8188976377952756 cov: 0.8819444444444444 rew: 9.525052579611012\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "13 VALID:  acc: 0.4621212121212121 cov: 0.9166666666666666 rew: -0.04549766090129083\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "13 TEST:  acc: 0.49612403100775193 cov: 0.8958333333333334 rew: -0.13497815138407043\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "14 TRAIN:  acc: 0.849768875192604 cov: 0.9013888888888889 rew: 10.31264293373131\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "14 VALID:  acc: 0.46099290780141844 cov: 0.9791666666666666 rew: -0.061836011715611185\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "14 TEST:  acc: 0.4782608695652174 cov: 0.9583333333333334 rew: -0.053137678543136585\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "15 TRAIN:  acc: 0.8402777777777778 cov: 0.9 rew: 10.547533419090993\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "15 VALID:  acc: 0.4405594405594406 cov: 0.9930555555555556 rew: -0.07932844159182748\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "15 TEST:  acc: 0.5070422535211268 cov: 0.9861111111111112 rew: -0.03099459415712631\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "16 TRAIN:  acc: 0.8649056603773585 cov: 0.9201388888888888 rew: 10.753624215704964\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "16 VALID:  acc: 0.42657342657342656 cov: 0.9930555555555556 rew: -0.0858733140445156\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "16 TEST:  acc: 0.5 cov: 0.9861111111111112 rew: -0.050912859393357435\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "17 TRAIN:  acc: 0.8694339622641509 cov: 0.9201388888888888 rew: 11.019510339149258\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "17 VALID:  acc: 0.4195804195804196 cov: 0.9930555555555556 rew: -0.11905590435152184\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "17 TEST:  acc: 0.5277777777777778 cov: 1.0 rew: -0.006231726426776718\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "18 TRAIN:  acc: 0.871969696969697 cov: 0.9166666666666666 rew: 10.760828586019377\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "18 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14655912717243455\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "18 TEST:  acc: 0.5208333333333334 cov: 1.0 rew: 0.001134057776277994\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "19 TRAIN:  acc: 0.8621987951807228 cov: 0.9222222222222223 rew: 10.833467809989346\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "19 VALID:  acc: 0.4397163120567376 cov: 0.9791666666666666 rew: -0.08852114589536048\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "19 TEST:  acc: 0.5142857142857142 cov: 0.9722222222222222 rew: -0.04261303046881551\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "20 TRAIN:  acc: 0.8688024408848207 cov: 0.9104166666666667 rew: 10.71635176195653\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "20 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.12454323110846689\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "20 TEST:  acc: 0.5140845070422535 cov: 0.9861111111111112 rew: -0.01674264849163018\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "21 TRAIN:  acc: 0.8538404175988069 cov: 0.93125 rew: 10.723440965648422\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "21 VALID:  acc: 0.40425531914893614 cov: 0.9791666666666666 rew: -0.12081364339324473\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "21 TEST:  acc: 0.5104895104895105 cov: 0.9930555555555556 rew: -0.015622419193197942\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "22 TRAIN:  acc: 0.8747186796699175 cov: 0.9256944444444445 rew: 11.247122055500194\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "22 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.12782104644746517\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "22 TEST:  acc: 0.5 cov: 1.0 rew: -0.13531309640318123\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "23 TRAIN:  acc: 0.8823088455772113 cov: 0.9263888888888889 rew: 10.944926168286687\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "23 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14653682808722993\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "23 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: -0.08518008522402755\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "24 TRAIN:  acc: 0.8716617210682492 cov: 0.9361111111111111 rew: 10.88540658605957\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "24 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.13714115231242946\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "24 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: -0.04647044977554882\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "25 TRAIN:  acc: 0.8786516853932584 cov: 0.9270833333333334 rew: 10.73801758953965\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "25 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.1367059265155088\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "25 TEST:  acc: 0.5 cov: 1.0 rew: -0.1302840089806283\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "26 TRAIN:  acc: 0.8783987915407855 cov: 0.9194444444444444 rew: 10.847053007433862\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "26 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.15080110687319295\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "26 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: -0.13313178848795038\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "27 TRAIN:  acc: 0.8730512249443207 cov: 0.9354166666666667 rew: 10.949201696357408\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "27 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.1448126652420752\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "27 TEST:  acc: 0.5 cov: 1.0 rew: -0.14050694019287274\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "28 TRAIN:  acc: 0.8827067669172932 cov: 0.9236111111111112 rew: 10.745979550130519\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "28 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.1448126652420752\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "28 TEST:  acc: 0.5 cov: 1.0 rew: -0.09954051987998495\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "29 TRAIN:  acc: 0.8767424798239178 cov: 0.9465277777777777 rew: 11.236914457576978\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "29 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.12207354485924164\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "29 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.18185177720132947\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "30 TRAIN:  acc: 0.8871681415929203 cov: 0.9416666666666667 rew: 11.335267910457945\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "30 VALID:  acc: 0.3819444444444444 cov: 1.0 rew: -0.1992868675868849\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "30 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.1595272620168163\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "31 TRAIN:  acc: 0.887815750371471 cov: 0.9347222222222222 rew: 10.607868560972417\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "31 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.12383713669205028\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "31 TEST:  acc: 0.5069444444444444 cov: 1.0 rew: -0.10207626725351525\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "32 TRAIN:  acc: 0.8826151560178306 cov: 0.9347222222222222 rew: 10.73795047581225\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "32 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.17831133903685997\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "32 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: -0.160974937764673\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "33 TRAIN:  acc: 0.8788774002954209 cov: 0.9402777777777778 rew: 11.09298673080238\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "33 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.16201556782292398\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "33 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.15807743505046376\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "34 TRAIN:  acc: 0.8884758364312267 cov: 0.9340277777777778 rew: 11.065312120048928\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "34 VALID:  acc: 0.3819444444444444 cov: 1.0 rew: -0.16236793182204923\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "34 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: -0.17808469320973383\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "35 TRAIN:  acc: 0.8960653303637713 cov: 0.9354166666666667 rew: 10.876357294100483\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "35 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.1509695830296639\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "35 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: -0.09147202844226614\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "36 TRAIN:  acc: 0.8788104089219331 cov: 0.9340277777777778 rew: 10.844238674115285\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "36 VALID:  acc: 0.4014084507042254 cov: 0.9861111111111112 rew: -0.13466898939870445\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "36 TEST:  acc: 0.4825174825174825 cov: 0.9930555555555556 rew: -0.14826037528907388\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "37 TRAIN:  acc: 0.889792899408284 cov: 0.9388888888888889 rew: 11.087032014196913\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "37 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.12383713669205028\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "37 TEST:  acc: 0.5 cov: 1.0 rew: -0.11361427744547538\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "38 TRAIN:  acc: 0.8907749077490775 cov: 0.9409722222222222 rew: 10.811265678007555\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "38 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.10807172692361709\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "38 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.14805130362946248\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "39 TRAIN:  acc: 0.8903177004538578 cov: 0.9180555555555555 rew: 10.907547397011282\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "39 VALID:  acc: 0.3888888888888889 cov: 1.0 rew: -0.17243433737494837\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "39 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.11571810675485227\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "40 TRAIN:  acc: 0.8978978978978979 cov: 0.925 rew: 10.654040753355655\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "40 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.1392366456957328\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "40 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.15995519895236907\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "41 TRAIN:  acc: 0.8962194217939214 cov: 0.9368055555555556 rew: 10.945177024816738\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "41 VALID:  acc: 0.4166666666666667 cov: 1.0 rew: -0.11949744346346822\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "41 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: -0.14481463963336372\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "42 TRAIN:  acc: 0.8759286775631501 cov: 0.9347222222222222 rew: 10.927678708852177\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "42 VALID:  acc: 0.4236111111111111 cov: 1.0 rew: -0.11616145369547033\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "42 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.17888046061502264\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "43 TRAIN:  acc: 0.8861423220973783 cov: 0.9270833333333334 rew: 10.859166514049825\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "43 VALID:  acc: 0.4305555555555556 cov: 1.0 rew: -0.07800616654666276\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "43 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.14934715029167583\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "44 TRAIN:  acc: 0.8930957683741648 cov: 0.9354166666666667 rew: 11.019040799011103\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "44 VALID:  acc: 0.42142857142857143 cov: 0.9722222222222222 rew: -0.10905908684108766\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "44 TEST:  acc: 0.45 cov: 0.9722222222222222 rew: -0.20312556325674194\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "45 TRAIN:  acc: 0.8859910581222057 cov: 0.9319444444444445 rew: 10.904930907013187\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "45 VALID:  acc: 0.4236111111111111 cov: 1.0 rew: -0.09309475712654812\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "45 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17647448704413185\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "46 TRAIN:  acc: 0.9014925373134328 cov: 0.9305555555555556 rew: 11.177719065668493\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "46 VALID:  acc: 0.4154929577464789 cov: 0.9861111111111112 rew: -0.09345425551798076\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "46 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17566275815059454\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "47 TRAIN:  acc: 0.8986486486486487 cov: 0.925 rew: 10.662357353567018\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "47 VALID:  acc: 0.4444444444444444 cov: 1.0 rew: -0.059447221572315974\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "47 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.13118181346078392\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "48 TRAIN:  acc: 0.8949329359165424 cov: 0.9319444444444445 rew: 10.94066635838315\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "48 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.11708052802384648\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "48 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: -0.15411454744661626\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "49 TRAIN:  acc: 0.9016516516516516 cov: 0.925 rew: 11.336907547819974\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "49 VALID:  acc: 0.4236111111111111 cov: 1.0 rew: -0.09309475712654812\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "49 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.18323610118266634\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "50 TRAIN:  acc: 0.884272997032641 cov: 0.9361111111111111 rew: 10.580232539077313\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "50 VALID:  acc: 0.4375 cov: 1.0 rew: -0.10744903441594518\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "50 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.18552905600896727\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "51 TRAIN:  acc: 0.8943028485757122 cov: 0.9263888888888889 rew: 11.020046386556448\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "51 VALID:  acc: 0.4305555555555556 cov: 1.0 rew: -0.07901974028144818\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "51 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.20512252012931734\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "52 TRAIN:  acc: 0.8839820359281437 cov: 0.9277777777777778 rew: 10.649659674051119\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "52 VALID:  acc: 0.4236111111111111 cov: 1.0 rew: -0.12027836927486608\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "52 TEST:  acc: 0.4444444444444444 cov: 1.0 rew: -0.18866567052841968\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "53 TRAIN:  acc: 0.8944237918215613 cov: 0.9340277777777778 rew: 11.173041884087542\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "53 VALID:  acc: 0.4305555555555556 cov: 1.0 rew: -0.0785497328938475\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "53 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.15100036770404773\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "54 TRAIN:  acc: 0.8896296296296297 cov: 0.9375 rew: 10.421676187312809\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "54 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.10231770993089707\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "54 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.16406901259914072\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "55 TRAIN:  acc: 0.8966542750929368 cov: 0.9340277777777778 rew: 10.722205165211497\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "55 VALID:  acc: 0.4166666666666667 cov: 1.0 rew: -0.08732928975518946\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "55 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17040747281485494\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "56 TRAIN:  acc: 0.8939955522609341 cov: 0.9368055555555556 rew: 10.919546054226245\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "56 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.10488455633516346\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "56 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.17856616742371753\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "57 TRAIN:  acc: 0.9074626865671642 cov: 0.9305555555555556 rew: 11.14597924873761\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "57 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.11219726844807966\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "57 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.1335982428666271\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "58 TRAIN:  acc: 0.9005979073243647 cov: 0.9291666666666667 rew: 10.91631820580427\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "58 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.09902253920003644\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "58 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: -0.15143883067126152\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "59 TRAIN:  acc: 0.8912564290962528 cov: 0.9451388888888889 rew: 10.927318997548662\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "59 VALID:  acc: 0.4166666666666667 cov: 1.0 rew: -0.12260081037428998\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "59 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.18940057880793484\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "60 TRAIN:  acc: 0.8746268656716418 cov: 0.9305555555555556 rew: 10.520332851573777\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "60 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14125992575281446\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "60 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.15531035347022912\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "61 TRAIN:  acc: 0.90739357729649 cov: 0.9298611111111111 rew: 11.005001713768207\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "61 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "61 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.1661447648544465\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "62 TRAIN:  acc: 0.8897168405365127 cov: 0.9319444444444445 rew: 11.01430524129963\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "62 VALID:  acc: 0.3888888888888889 cov: 1.0 rew: -0.16267885024584638\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "62 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.17856616742371753\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "63 TRAIN:  acc: 0.9041198501872659 cov: 0.9270833333333334 rew: 11.054207584448207\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "63 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "63 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.1661447648544465\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "64 TRAIN:  acc: 0.9037749814951888 cov: 0.9381944444444444 rew: 11.179072359345577\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "64 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "64 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.15531035347022912\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "65 TRAIN:  acc: 0.898355754857997 cov: 0.9291666666666667 rew: 11.045302985008867\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "65 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14357633892431487\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "65 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.15734626181857983\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "66 TRAIN:  acc: 0.8780669144981412 cov: 0.9340277777777778 rew: 10.529037569261554\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "66 VALID:  acc: 0.3888888888888889 cov: 1.0 rew: -0.16267885024584638\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "66 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.1621109352405342\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "67 TRAIN:  acc: 0.8923533778767632 cov: 0.9354166666666667 rew: 11.054258070220689\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "67 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.14261725896919727\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "67 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.1812045690326841\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "68 TRAIN:  acc: 0.8973214285714286 cov: 0.9333333333333333 rew: 11.474256092440744\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "68 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.1004446927024036\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "68 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.15531035347022912\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "69 TRAIN:  acc: 0.9015544041450777 cov: 0.9381944444444444 rew: 11.22893459454879\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "69 VALID:  acc: 0.3888888888888889 cov: 1.0 rew: -0.16267885024584638\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "69 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: -0.16168854875690167\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "70 TRAIN:  acc: 0.891449814126394 cov: 0.9340277777777778 rew: 10.544938169576486\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "70 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.15833915701726428\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "70 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: -0.15267632805963102\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "71 TRAIN:  acc: 0.8956780923994039 cov: 0.9319444444444445 rew: 10.6089879249875\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "71 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.15833915701726428\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "71 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.16971852923731953\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "72 TRAIN:  acc: 0.8967310549777118 cov: 0.9347222222222222 rew: 10.91373761871755\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "72 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.14614318532858125\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "72 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.17856616742371753\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "73 TRAIN:  acc: 0.8990276738967838 cov: 0.9284722222222223 rew: 10.699284957356774\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "73 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.14614318532858125\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "73 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17593214201311944\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "74 TRAIN:  acc: 0.9055762081784386 cov: 0.9340277777777778 rew: 11.191394372913274\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "74 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "74 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17411621209349412\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "75 TRAIN:  acc: 0.8952802359882006 cov: 0.9416666666666667 rew: 11.141297287761445\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "75 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.14614318532858125\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "75 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: -0.1739678476191536\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "76 TRAIN:  acc: 0.9026022304832714 cov: 0.9340277777777778 rew: 11.098047389999618\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "76 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.10488455633516346\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "76 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.17801346216475847\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "77 TRAIN:  acc: 0.896807720861173 cov: 0.9354166666666667 rew: 10.710251449818523\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "77 VALID:  acc: 0.4166666666666667 cov: 1.0 rew: -0.1251616288506329\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "77 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.1982634051176421\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "78 TRAIN:  acc: 0.9096296296296297 cov: 0.9375 rew: 11.58797530874286\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "78 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.13736362846723932\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "78 TEST:  acc: 0.4513888888888889 cov: 1.0 rew: -0.18638018062615366\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "79 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "79 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17453233780980518\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "80 TRAIN:  acc: 0.9038031319910514 cov: 0.93125 rew: 11.031158418203797\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "80 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.14614318532858125\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "80 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17469464462474996\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "81 TRAIN:  acc: 0.9026745913818722 cov: 0.9347222222222222 rew: 10.517740310396757\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "81 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.1447800652982897\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "81 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17469464462474996\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "82 TRAIN:  acc: 0.9056179775280899 cov: 0.9270833333333334 rew: 11.104773610122097\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "82 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "82 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.18253520302893814\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "83 TRAIN:  acc: 0.905786350148368 cov: 0.9361111111111111 rew: 11.01247702429665\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "83 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.10488455633516346\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "83 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: -0.17202892372191655\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "84 TRAIN:  acc: 0.905899925317401 cov: 0.9298611111111111 rew: 11.085122956211181\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "84 VALID:  acc: 0.3986013986013986 cov: 0.9930555555555556 rew: -0.1454616253134355\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "84 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17469464462474996\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "85 TRAIN:  acc: 0.8947761194029851 cov: 0.9305555555555556 rew: 10.602863600381202\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "85 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.13574957770681298\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "85 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.18295758951257066\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "86 TRAIN:  acc: 0.9109433962264151 cov: 0.9201388888888888 rew: 10.66006204677104\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "86 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.10352143630487191\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "86 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.17469464462474996\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "87 TRAIN:  acc: 0.8908002991772626 cov: 0.9284722222222223 rew: 10.524009898098239\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "87 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "87 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.18295758951257066\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "88 TRAIN:  acc: 0.9029850746268657 cov: 0.9305555555555556 rew: 10.978390422473263\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "88 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "88 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.17908606671360308\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "89 TRAIN:  acc: 0.9039759939984996 cov: 0.9256944444444445 rew: 10.557289680349713\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "89 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.10488455633516346\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "89 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.17908606671360308\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "90 TRAIN:  acc: 0.9186991869918699 cov: 0.9395833333333333 rew: 11.416330278237032\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "90 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "90 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: -0.16653595001588736\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "91 TRAIN:  acc: 0.9025297619047619 cov: 0.9333333333333333 rew: 11.125723814926523\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "91 VALID:  acc: 0.4166666666666667 cov: 1.0 rew: -0.1251616288506329\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "91 TEST:  acc: 0.46853146853146854 cov: 0.9930555555555556 rew: -0.17623988503273022\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "92 TRAIN:  acc: 0.9146250927988122 cov: 0.9354166666666667 rew: 11.168774591430063\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "92 VALID:  acc: 0.3888888888888889 cov: 1.0 rew: -0.16267885024584638\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "92 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.18295758951257066\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "93 TRAIN:  acc: 0.9144345238095238 cov: 0.9333333333333333 rew: 10.852767491998625\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "93 VALID:  acc: 0.3958333333333333 cov: 1.0 rew: -0.14614318532858125\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "93 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.15583025276011467\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "94 TRAIN:  acc: 0.9067164179104478 cov: 0.9305555555555556 rew: 10.687014334402042\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "94 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.1447800652982897\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "94 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.110923159114495\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "95 TRAIN:  acc: 0.9135893648449039 cov: 0.9402777777777778 rew: 11.049361834351156\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "95 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.21357583739530944\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "95 TEST:  acc: 0.5069444444444444 cov: 1.0 rew: -0.08041537763201088\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "96 TRAIN:  acc: 0.9021497405485545 cov: 0.9368055555555556 rew: 11.030129870631573\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "96 VALID:  acc: 0.4166666666666667 cov: 1.0 rew: -0.1251616288506329\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "96 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.12626907595952883\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "97 TRAIN:  acc: 0.9135618479880775 cov: 0.9319444444444445 rew: 11.44193257001268\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "97 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.14034020166552988\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "97 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.18295758951257066\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "98 TRAIN:  acc: 0.898572501878287 cov: 0.9243055555555556 rew: 10.898486225276187\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "98 VALID:  acc: 0.4027777777777778 cov: 1.0 rew: -0.14170332169582142\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "98 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.1252427205264968\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "99 TRAIN:  acc: 0.9162380602498164 cov: 0.9451388888888889 rew: 11.346737505052639\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "99 VALID:  acc: 0.4097222222222222 cov: 1.0 rew: -0.14034020166552988\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "99 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.09205876724985972\n",
            " \n",
            "./Output/csv/walks/walks2.csv\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbb794cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbb794cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbcc71ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f3dbcc71ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "0 TRAIN:  acc: 0.5 cov: 0.6430555555555556 rew: 0.24451466907227332\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "0 VALID:  acc: 0.4142857142857143 cov: 0.4861111111111111 rew: -0.0159474257060234\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "0 TEST:  acc: 0.4915254237288136 cov: 0.4097222222222222 rew: 0.055058374824557124\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "1 TRAIN:  acc: 0.6573849878934624 cov: 0.5736111111111111 rew: 3.7212397827386625\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "1 VALID:  acc: 0.5212765957446809 cov: 0.6527777777777778 rew: 0.04962756981752278\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "1 TEST:  acc: 0.6071428571428571 cov: 0.5833333333333334 rew: 0.03587467282488489\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "2 TRAIN:  acc: 0.6891025641025641 cov: 0.65 rew: 4.961309361227217\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "2 VALID:  acc: 0.5324675324675324 cov: 0.5347222222222222 rew: 0.12264472894693661\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "2 TEST:  acc: 0.6233766233766234 cov: 0.5347222222222222 rew: 0.054839420418842634\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "3 TRAIN:  acc: 0.7359437751004017 cov: 0.6916666666666667 rew: 6.2027527742072\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "3 VALID:  acc: 0.5533980582524272 cov: 0.7152777777777778 rew: 0.17379717258006758\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "3 TEST:  acc: 0.63 cov: 0.6944444444444444 rew: 0.11618043078178403\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "4 TRAIN:  acc: 0.7365491651205937 cov: 0.7486111111111111 rew: 6.702979678259138\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "4 VALID:  acc: 0.5172413793103449 cov: 0.8055555555555556 rew: 0.12821930462694217\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "4 TEST:  acc: 0.494949494949495 cov: 0.6875 rew: -0.1147745658425276\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "5 TRAIN:  acc: 0.7674841053587648 cov: 0.7645833333333333 rew: 7.47013916653213\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "5 VALID:  acc: 0.5847457627118644 cov: 0.8194444444444444 rew: 0.25723124583072066\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "5 TEST:  acc: 0.5257731958762887 cov: 0.6736111111111112 rew: -0.1272991275603892\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "6 TRAIN:  acc: 0.7680278019113814 cov: 0.7993055555555556 rew: 8.276141553539258\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "6 VALID:  acc: 0.5480769230769231 cov: 0.7222222222222222 rew: 0.1685412164094543\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "6 TEST:  acc: 0.5 cov: 0.7083333333333334 rew: -0.16717343608258778\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "7 TRAIN:  acc: 0.773037542662116 cov: 0.8138888888888889 rew: 8.39000752975804\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "7 VALID:  acc: 0.6124031007751938 cov: 0.8958333333333334 rew: 0.31458915393274\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "7 TEST:  acc: 0.5203252032520326 cov: 0.8541666666666666 rew: -0.08233329682430858\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "8 TRAIN:  acc: 0.7939444911690496 cov: 0.8256944444444444 rew: 8.552628371891673\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "8 VALID:  acc: 0.5434782608695652 cov: 0.9583333333333334 rew: 0.204851493854018\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "8 TEST:  acc: 0.48 cov: 0.8680555555555556 rew: -0.18141547746511769\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "9 TRAIN:  acc: 0.8176661264181524 cov: 0.8569444444444444 rew: 9.653697932717705\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "9 VALID:  acc: 0.5182481751824818 cov: 0.9513888888888888 rew: 0.10664057978245053\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "9 TEST:  acc: 0.49645390070921985 cov: 0.9791666666666666 rew: -0.17780104861068038\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "10 TRAIN:  acc: 0.8144087705559906 cov: 0.8868055555555555 rew: 9.508899413871987\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "10 VALID:  acc: 0.5467625899280576 cov: 0.9652777777777778 rew: 0.18053823500631583\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "10 TEST:  acc: 0.539568345323741 cov: 0.9652777777777778 rew: 0.004022959480426659\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "11 TRAIN:  acc: 0.8334636434714621 cov: 0.8881944444444444 rew: 9.905486605823647\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "11 VALID:  acc: 0.5384615384615384 cov: 0.9930555555555556 rew: 0.13284236446892175\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "11 TEST:  acc: 0.5460992907801419 cov: 0.9791666666666666 rew: -0.04719466121801531\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "12 TRAIN:  acc: 0.8285933897002306 cov: 0.9034722222222222 rew: 10.411641717657535\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "12 VALID:  acc: 0.5563380281690141 cov: 0.9861111111111112 rew: 0.1853908853516307\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "12 TEST:  acc: 0.5106382978723404 cov: 0.9791666666666666 rew: -0.09961501565950329\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "13 TRAIN:  acc: 0.8268497330282227 cov: 0.9104166666666667 rew: 9.818723979126254\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "13 VALID:  acc: 0.5328467153284672 cov: 0.9513888888888888 rew: 0.15325262499069625\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "13 TEST:  acc: 0.5390625 cov: 0.8888888888888888 rew: -0.046049411907677924\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "14 TRAIN:  acc: 0.8338414634146342 cov: 0.9111111111111111 rew: 9.750412839455745\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "14 VALID:  acc: 0.5555555555555556 cov: 1.0 rew: 0.1571769424533081\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "14 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.13290224758509653\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "15 TRAIN:  acc: 0.8462121212121212 cov: 0.9166666666666666 rew: 10.44592198469782\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "15 VALID:  acc: 0.5833333333333334 cov: 1.0 rew: 0.21824741484169283\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "15 TEST:  acc: 0.5138888888888888 cov: 1.0 rew: -0.05090348584624248\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "16 TRAIN:  acc: 0.8323353293413174 cov: 0.9277777777777778 rew: 9.944296995848681\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "16 VALID:  acc: 0.5486111111111112 cov: 1.0 rew: 0.1692862440307722\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "16 TEST:  acc: 0.5069444444444444 cov: 1.0 rew: -0.08705241942114361\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "17 TRAIN:  acc: 0.8419090231170768 cov: 0.93125 rew: 10.099128205054232\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "17 VALID:  acc: 0.5244755244755245 cov: 0.9930555555555556 rew: 0.1755196874168402\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "17 TEST:  acc: 0.4755244755244755 cov: 0.9930555555555556 rew: -0.12465282167827896\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "18 TRAIN:  acc: 0.854463615903976 cov: 0.9256944444444445 rew: 10.603772816711363\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "18 VALID:  acc: 0.528169014084507 cov: 0.9861111111111112 rew: 0.11663206673212279\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "18 TEST:  acc: 0.4714285714285714 cov: 0.9722222222222222 rew: -0.12559233407025097\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "19 TRAIN:  acc: 0.8731003039513677 cov: 0.9138888888888889 rew: 10.954766686805195\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "19 VALID:  acc: 0.5555555555555556 cov: 1.0 rew: 0.18860640309020832\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "19 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: -0.07671869698948683\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "20 TRAIN:  acc: 0.8530734632683659 cov: 0.9263888888888889 rew: 10.423115306631486\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "20 VALID:  acc: 0.5390070921985816 cov: 0.9791666666666666 rew: 0.11980892275021465\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "20 TEST:  acc: 0.4857142857142857 cov: 0.9722222222222222 rew: -0.0718041071381887\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "21 TRAIN:  acc: 0.8539156626506024 cov: 0.9222222222222223 rew: 10.703834420493907\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "21 VALID:  acc: 0.5347222222222222 cov: 1.0 rew: 0.14578334159134082\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "21 TEST:  acc: 0.4583333333333333 cov: 1.0 rew: -0.11232779467858388\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "22 TRAIN:  acc: 0.859504132231405 cov: 0.9243055555555556 rew: 10.84565065788671\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "22 VALID:  acc: 0.5486111111111112 cov: 1.0 rew: 0.15831724221170393\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "22 TEST:  acc: 0.5 cov: 1.0 rew: -0.06912807038342363\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "23 TRAIN:  acc: 0.8539493293591655 cov: 0.9319444444444445 rew: 10.271128056684395\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "23 VALID:  acc: 0.5642857142857143 cov: 0.9722222222222222 rew: 0.14538455772978168\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "23 TEST:  acc: 0.48175182481751827 cov: 0.9513888888888888 rew: -0.05999770404886927\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "24 TRAIN:  acc: 0.8708955223880597 cov: 0.9305555555555556 rew: 11.011475044914064\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "24 VALID:  acc: 0.5208333333333334 cov: 1.0 rew: 0.10353725487730558\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "24 TEST:  acc: 0.4647887323943662 cov: 0.9861111111111112 rew: -0.10821311841429042\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "25 TRAIN:  acc: 0.8660647103085026 cov: 0.9229166666666667 rew: 10.247877024535457\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "25 VALID:  acc: 0.5486111111111112 cov: 1.0 rew: 0.14275913084688005\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "25 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.06598244669118944\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "26 TRAIN:  acc: 0.8557692307692307 cov: 0.9388888888888889 rew: 10.234141978939109\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "26 VALID:  acc: 0.5208333333333334 cov: 1.0 rew: 0.1098934298289223\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "26 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: -0.07114472791575677\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "27 TRAIN:  acc: 0.8582202111613876 cov: 0.9208333333333333 rew: 10.511448199073584\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "27 VALID:  acc: 0.5277777777777778 cov: 1.0 rew: 0.12380780920036\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "27 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: 0.004740269123930143\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "28 TRAIN:  acc: 0.8584136397331357 cov: 0.9368055555555556 rew: 10.38296758276299\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "28 VALID:  acc: 0.5625 cov: 1.0 rew: 0.12371936722497048\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "28 TEST:  acc: 0.5069444444444444 cov: 1.0 rew: -0.057795161790286015\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "29 TRAIN:  acc: 0.8664179104477612 cov: 0.9305555555555556 rew: 10.532475919315594\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "29 VALID:  acc: 0.5555555555555556 cov: 1.0 rew: 0.1571733467359173\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "29 TEST:  acc: 0.5138888888888888 cov: 1.0 rew: -0.007697279914101273\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "30 TRAIN:  acc: 0.888560885608856 cov: 0.9409722222222222 rew: 11.188981086357645\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "30 VALID:  acc: 0.5277777777777778 cov: 1.0 rew: 0.07598441443289156\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "30 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.014579586311198411\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "31 TRAIN:  acc: 0.8845007451564829 cov: 0.9319444444444445 rew: 10.700083265836982\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "31 VALID:  acc: 0.5208333333333334 cov: 1.0 rew: 0.10818680195773075\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "31 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: 0.036274854840883705\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "32 TRAIN:  acc: 0.8873239436619719 cov: 0.9368055555555556 rew: 11.137736440816987\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "32 VALID:  acc: 0.5555555555555556 cov: 1.0 rew: 0.14517949608949246\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "32 TEST:  acc: 0.5138888888888888 cov: 1.0 rew: -0.004197905334602672\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "33 TRAIN:  acc: 0.8669172932330828 cov: 0.9236111111111112 rew: 10.68526829219691\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "33 VALID:  acc: 0.4861111111111111 cov: 1.0 rew: 0.05806512955941266\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "33 TEST:  acc: 0.4652777777777778 cov: 1.0 rew: -0.012986821527377476\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "34 TRAIN:  acc: 0.8734270910436713 cov: 0.9381944444444444 rew: 10.91128695479542\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "34 VALID:  acc: 0.5416666666666666 cov: 1.0 rew: 0.11405348466320789\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "34 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: 0.015599977211577146\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "35 TRAIN:  acc: 0.8832335329341318 cov: 0.9277777777777778 rew: 10.550932084075171\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "35 VALID:  acc: 0.5486111111111112 cov: 1.0 rew: 0.12982140796469804\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "35 TEST:  acc: 0.5069444444444444 cov: 1.0 rew: -0.01723017822035991\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "36 TRAIN:  acc: 0.8554396423248882 cov: 0.9319444444444445 rew: 10.028611095028834\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "36 VALID:  acc: 0.5416666666666666 cov: 1.0 rew: 0.07472343954646939\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "36 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: 0.018534591573681848\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "37 TRAIN:  acc: 0.8831845238095238 cov: 0.9333333333333333 rew: 10.728720126391782\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "37 VALID:  acc: 0.5625 cov: 1.0 rew: 0.09313692661803921\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "37 TEST:  acc: 0.4791666666666667 cov: 1.0 rew: -0.08349143372867227\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "38 TRAIN:  acc: 0.8698578908002992 cov: 0.9284722222222223 rew: 10.366894921831241\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "38 VALID:  acc: 0.5277777777777778 cov: 1.0 rew: 0.05200707832232433\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "38 TEST:  acc: 0.5 cov: 1.0 rew: -0.05076844539610889\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "39 TRAIN:  acc: 0.894074074074074 cov: 0.9375 rew: 10.630126965666753\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "39 VALID:  acc: 0.5277777777777778 cov: 1.0 rew: 0.07384266172970749\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "39 TEST:  acc: 0.5277777777777778 cov: 1.0 rew: -0.004828277836465887\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "40 TRAIN:  acc: 0.8763040238450075 cov: 0.9319444444444445 rew: 10.211727197529992\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "40 VALID:  acc: 0.5208333333333334 cov: 1.0 rew: 0.03823608292926161\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "40 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: -0.05051390678515116\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "41 TRAIN:  acc: 0.8846441947565543 cov: 0.9270833333333334 rew: 10.81551930015753\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "41 VALID:  acc: 0.5069444444444444 cov: 1.0 rew: 0.0003985294961305272\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "41 TEST:  acc: 0.5 cov: 1.0 rew: 0.04676883948036205\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "42 TRAIN:  acc: 0.8690476190476191 cov: 0.9333333333333333 rew: 10.622895976131296\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "42 VALID:  acc: 0.5416666666666666 cov: 1.0 rew: 0.05129432303193439\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "42 TEST:  acc: 0.4930555555555556 cov: 1.0 rew: 0.03737849977732374\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "43 TRAIN:  acc: 0.8864824495892457 cov: 0.9298611111111111 rew: 10.904846192286257\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "43 VALID:  acc: 0.5347222222222222 cov: 1.0 rew: 0.06157843066477674\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "43 TEST:  acc: 0.5208333333333334 cov: 1.0 rew: 0.11023814520581346\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "44 TRAIN:  acc: 0.8922509225092251 cov: 0.9409722222222222 rew: 11.064148514334436\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "44 VALID:  acc: 0.5347222222222222 cov: 1.0 rew: 0.09319363896457863\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "44 TEST:  acc: 0.5069444444444444 cov: 1.0 rew: -0.04241044731908715\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "45 TRAIN:  acc: 0.8821349147516679 cov: 0.9368055555555556 rew: 10.61381143340905\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "45 VALID:  acc: 0.5208333333333334 cov: 1.0 rew: 0.00831552705040996\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "45 TEST:  acc: 0.4722222222222222 cov: 1.0 rew: -0.0058245426938797525\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "46 TRAIN:  acc: 0.8889722430607652 cov: 0.9256944444444445 rew: 11.139745858564856\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "46 VALID:  acc: 0.5277777777777778 cov: 1.0 rew: 0.0698551393932016\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "46 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: 0.043761249329940244\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "47 TRAIN:  acc: 0.8896396396396397 cov: 0.925 rew: 10.400180540062712\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "47 VALID:  acc: 0.5277777777777778 cov: 1.0 rew: 0.06405003596194372\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "47 TEST:  acc: 0.5138888888888888 cov: 1.0 rew: 0.10347549502249877\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "48 TRAIN:  acc: 0.8871449925261584 cov: 0.9291666666666667 rew: 10.777071828594561\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "48 VALID:  acc: 0.5486111111111112 cov: 1.0 rew: 0.06259736150140098\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "48 TEST:  acc: 0.5277777777777778 cov: 1.0 rew: -0.03361214360581115\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "49 TRAIN:  acc: 0.8845867460908414 cov: 0.9326388888888889 rew: 10.893786746042325\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "49 VALID:  acc: 0.4930555555555556 cov: 1.0 rew: -0.04276263941068578\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "49 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: 0.043761249329940244\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "50 TRAIN:  acc: 0.8786516853932584 cov: 0.9270833333333334 rew: 11.052507042629601\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "50 VALID:  acc: 0.5138888888888888 cov: 1.0 rew: -0.0015710095285200662\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "50 TEST:  acc: 0.528169014084507 cov: 0.9861111111111112 rew: 0.0877133362204642\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "51 TRAIN:  acc: 0.8853073463268366 cov: 0.9263888888888889 rew: 10.555047790707262\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "51 VALID:  acc: 0.5208333333333334 cov: 1.0 rew: 0.07274998004641531\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "51 TEST:  acc: 0.4861111111111111 cov: 1.0 rew: 0.0356234266251027\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "52 TRAIN:  acc: 0.8896396396396397 cov: 0.925 rew: 10.844870192496927\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "52 VALID:  acc: 0.5277777777777778 cov: 1.0 rew: 0.050025039128513145\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "52 TEST:  acc: 0.5416666666666666 cov: 1.0 rew: 0.10612979499089048\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "53 TRAIN:  acc: 0.8993993993993994 cov: 0.925 rew: 10.973497121163605\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "53 VALID:  acc: 0.5486111111111112 cov: 1.0 rew: 0.09482005520021985\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "53 TEST:  acc: 0.5486111111111112 cov: 1.0 rew: 0.07595322778790888\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "54 TRAIN:  acc: 0.8662182361733931 cov: 0.9291666666666667 rew: 10.688206802509216\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "54 VALID:  acc: 0.4861111111111111 cov: 1.0 rew: -0.035967750072566834\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "54 TEST:  acc: 0.5138888888888888 cov: 1.0 rew: 0.05695421931479769\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "55 TRAIN:  acc: 0.8775964391691394 cov: 0.9361111111111111 rew: 10.771384720604546\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "55 VALID:  acc: 0.5625 cov: 1.0 rew: 0.14641610385725315\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "55 TEST:  acc: 0.5347222222222222 cov: 1.0 rew: -0.00035807972010475954\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "56 TRAIN:  acc: 0.8773234200743495 cov: 0.9340277777777778 rew: 10.930351793456236\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "56 VALID:  acc: 0.5138888888888888 cov: 1.0 rew: 0.029294791623096374\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "56 TEST:  acc: 0.5208333333333334 cov: 1.0 rew: 0.08484100650384836\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "57 TRAIN:  acc: 0.8845867460908414 cov: 0.9326388888888889 rew: 10.403917134214842\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "57 VALID:  acc: 0.5 cov: 1.0 rew: 0.027791870032112566\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "57 TEST:  acc: 0.5 cov: 1.0 rew: 0.021809321129884103\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble"
      ],
      "metadata": {
        "id": "W9uq_5aeNtky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ensemble.py"
      ],
      "metadata": {
        "id": "caK_5gKwNv4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def full_ensemble(df):\n",
        "    m1 = df.eq(1).all(axis=1)\n",
        "\n",
        "    m2 = df.eq(2).all(axis=1)\n",
        "\n",
        "    local_df = df.copy()\n",
        "    local_df['ensemble'] = np.select([m1, m2], [1, 2], 0)\n",
        "\n",
        "    local_df = local_df.drop(local_df.columns.difference(['ensemble']), axis=1)\n",
        "\n",
        "    return local_df\n",
        "\n",
        "def perc_ensemble(df, thr = 0.7):\n",
        "    c1 = (df.eq(1).sum(1) / df.shape[1]).gt(thr)\n",
        "    c2 = (df.eq(2).sum(1) / df.shape[1]).gt(thr)\n",
        "    return pd.DataFrame(np.select([c1, c2], [1, 2], 0), index=df.index, columns=['ensemble'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ensemble(numWalks,perc,type,numDel):\n",
        "    dollSum=0\n",
        "    rewSum=0\n",
        "    posSum=0\n",
        "    negSum=0\n",
        "    covSum=0\n",
        "    numSum=0\n",
        "\n",
        "    values=[]\n",
        "    #output=open(\"daxValidDel9th60.csv\",\"w+\")\n",
        "    #output.write(\"Iteration,Reward%,#Wins,#Losses,Euro,Coverage,Accuracy\\n\")\n",
        "    columns = [\"Iteration\",\"Reward%\",\"#Wins\",\"#Losses\",\"Dollars\",\"Coverage\",\"Accuracy\"]\n",
        "    dax=pd.read_csv(\"./datasets/sp500Day.csv\",index_col='Date')\n",
        "    for j in range(0,numWalks):\n",
        "\n",
        "        df=pd.read_csv(\"./Output/ensemble/walk\"+str(j)+\"ensemble_\"+type+\".csv\",index_col='Date')\n",
        "\n",
        "\n",
        "\n",
        "        for deleted in range(1,numDel):\n",
        "            del df['iteration'+str(deleted)]\n",
        "        \n",
        "        if perc==0:\n",
        "            df=full_ensemble(df)\n",
        "        else:\n",
        "            df=perc_ensemble(df,perc)\n",
        "\n",
        "        num=0\n",
        "        rew=0\n",
        "        pos=0\n",
        "        neg=0\n",
        "        doll=0\n",
        "        cov=0\n",
        "        for date, i in df.iterrows():\n",
        "            num+=1\n",
        "\n",
        "            if date in dax.index:\n",
        "                if (i['ensemble']==1):\n",
        "                    pos+= 1 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                    \n",
        "                    neg+= 0 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                    rew+=(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                    doll+=(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "                    cov+=1\n",
        "                elif (i['ensemble']==2):\n",
        "                    \n",
        "                    neg+= 0 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                    pos+= 1 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                    rew+=-(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                    cov+=1\n",
        "                    doll+=-(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "        \n",
        "        values.append([str(round(j,2)),str(round(rew,2)),str(round(pos,2)),str(round(neg,2)),str(round(doll,2)),str(round(cov/num,2)),(str(round(pos/cov,2)) if (cov>0) else \"\")])\n",
        "        \n",
        "        dollSum+=doll\n",
        "        rewSum+=rew\n",
        "        posSum+=pos\n",
        "        negSum+=neg\n",
        "        covSum+=cov\n",
        "        numSum+=num\n",
        "\n",
        "\n",
        "    values.append([\"sum\",str(round(rewSum,2)),str(round(posSum,2)),str(round(negSum,2)),str(round(dollSum,2)),str(round(covSum/numSum,2)),(str(round(posSum/covSum,2)) if (covSum>0) else \"\")])\n",
        "    return values,columns\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(csvname=\"\"):\n",
        "    \n",
        "    output=open(\"resultsSPFinal.csv\",\"w+\")\n",
        "    output.write(\"Iteration,Reward%,#Wins,#Losses,Euro,Coverage,Accuracy\\n\")\n",
        "    df=pd.read_csv(csvname)\n",
        "    dax=pd.read_csv(\"./datasets/sp500Day.csv\",index_col='Date')\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df['date'] = df['date'].dt.strftime('%m/%d/%Y')\n",
        "    df.set_index('date', inplace=True)\n",
        "    print(df)\n",
        "    num=0\n",
        "    rew=0\n",
        "    pos=0\n",
        "    neg=0\n",
        "    doll=0\n",
        "    cov=0\n",
        "    for date, i in df.iterrows():\n",
        "        num+=1\n",
        "\n",
        "        if date in dax.index:\n",
        "            if (i['ensemble']==1):\n",
        "                pos+= 1 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                \n",
        "                neg+= 0 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                rew+=(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                doll+=(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "                cov+=1\n",
        "            elif (i['ensemble']==-1):\n",
        "                \n",
        "                neg+= 0 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                pos+= 1 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                rew+=-(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                cov+=1\n",
        "                doll+=-(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "    \n",
        "    output.write(str(0)+ \",\" + str(round(rew,2))+ \",\" + str(round(pos,2))+ \",\" + str(round(neg,2))+ \",\" + str(round(doll,2))+ \",\" + str(round(cov/num,2))+ \",\" +(str(round(pos/cov,2)) if (cov>0) else \"\") + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#evaluate(\".\\Output\\results\\finalEnsembleSP500.csv\")"
      ],
      "metadata": {
        "id": "zsn9nF3xNvM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## splitEnsemble.py"
      ],
      "metadata": {
        "id": "UrSHwjUzODQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "long = [[],[]]\n",
        "short = [[],[]]\n",
        "\n",
        "longs=pd.read_csv(\"./Output/results/spLong.csv\")\n",
        "shorts=pd.read_csv(\"./Output/results/spShort.csv\")\n",
        "\n",
        "long[0]= longs.ix[:,\"Date\"].tolist()\n",
        "long[1]= longs.ix[:,\"ensemble\"].tolist()\n",
        "short[0] = shorts.ix[:,\"Date\"].tolist()\n",
        "short[1] = shorts.ix[:,\"ensemble\"].tolist()\n",
        "\n",
        "output = open(\"finalEnsemble.csv\", \"w+\")\n",
        "output.write(\"date,ensemble\\n\")\n",
        "\n",
        "for i in range(0,len(long[0])):\n",
        "    if(long[0][i]==short[0][i]):\n",
        "        output.write(str(long[0][i]) + \",\" + str(long[1][i]+short[1][i]) + \"\\n\")"
      ],
      "metadata": {
        "id": "HXI85Q4GOMF4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}