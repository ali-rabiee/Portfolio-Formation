{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-rabiee/Portfolio-Formation/blob/DQN/Mahdi_deep_q_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_weG2085js1I"
      },
      "source": [
        "# Requirements & Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO48s139j1ux",
        "outputId": "25acc2e7-d083-4e3f-bd7b-5108405322a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Collecting keras-rl\n",
            "  Downloading keras-rl-0.4.2.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.7/dist-packages (from keras-rl) (2.8.0)\n",
            "Building wheels for collected packages: keras-rl\n",
            "  Building wheel for keras-rl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-rl: filename=keras_rl-0.4.2-py3-none-any.whl size=48378 sha256=3b057bceda49f96d9a9a5393cbe86275471d67d9be785d8d1be64b744ccbb426\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/23/e9/278c2e59c322236e2bfdf7c792c16f0b4dec24816d27a3f1e4\n",
            "Successfully built keras-rl\n",
            "Installing collected packages: keras-rl\n",
            "Successfully installed keras-rl-0.4.2\n",
            "Collecting tensorflow==1.15\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 25 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.21.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=520756034cd46d2298a84f004fc4f021375743b6eff682d5c4bc4f27c140efe7\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: keras-rl in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.7/dist-packages (from keras-rl) (2.8.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting rl\n",
            "  Downloading rl-3.0.zip (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rl) (57.4.0)\n",
            "Building wheels for collected packages: rl\n",
            "  Building wheel for rl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rl: filename=rl-3.0-cp37-cp37m-linux_x86_64.whl size=219753 sha256=740570c9a07252f55958594b7ebbae38af1482dd0398237cd11249ad7914f66f\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/6e/5d/db42865fbf739cb1a7f650cb4e4b18067856d00f4de10c87b7\n",
            "Successfully built rl\n",
            "Installing collected packages: rl\n",
            "Successfully installed rl-3.0\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 814 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.21.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.44.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->keras-rl2) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow->keras-rl2) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow->keras-rl2) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow->keras-rl2) (3.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow->keras-rl2) (1.5.2)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n",
            "Collecting Callbacks\n",
            "  Downloading callbacks-0.3.0.tar.gz (9.4 kB)\n",
            "Building wheels for collected packages: Callbacks\n",
            "  Building wheel for Callbacks (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Callbacks: filename=callbacks-0.3.0-py3-none-any.whl size=5676 sha256=57842e10c31e167102bca3fdced98138aec5a7f9d814d90697fcbc5d221bf5b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/fe/60/5ff958b7d8dd524e2e12e7a75047e3518ef3ea098b9313d6eb\n",
            "Successfully built Callbacks\n",
            "Installing collected packages: Callbacks\n",
            "Successfully installed Callbacks-0.3.0\n",
            "Requirement already satisfied: callbacks in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement rl.callbacks (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for rl.callbacks\u001b[0m\n",
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.9.0.dev20220324-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (509.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 509.8 MB 30 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.14.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.44.0)\n",
            "Collecting tb-nightly~=2.9.0.a\n",
            "  Downloading tb_nightly-2.9.0a20220323-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 34.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (21.3)\n",
            "Collecting tf-estimator-nightly~=2.9.0.dev\n",
            "  Downloading tf_estimator_nightly-2.9.0.dev2022032508-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.21.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (13.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Collecting keras-nightly~=2.9.0.dev\n",
            "  Downloading keras_nightly-2.9.0.dev2022032507-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (57.4.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.9.0.a->tf-nightly) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.9.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.9.0.a->tf-nightly) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.9.0.a->tf-nightly) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.9.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.9.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.9.0.a->tf-nightly) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tf-nightly) (3.0.7)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, keras-nightly, flatbuffers, tf-nightly\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "Successfully installed flatbuffers-1.12 keras-nightly-2.9.0.dev2022032507 tb-nightly-2.9.0a20220323 tf-estimator-nightly-2.9.0.dev2022032508 tf-nightly-2.9.0.dev20220324\n"
          ]
        }
      ],
      "source": [
        "!pip3 install Keras\n",
        "!pip3 install keras-rl\n",
        "!pip install tensorflow==1.15\n",
        "!pip install keras\n",
        "!pip install keras-rl\n",
        "!pip install gym\n",
        "!pip install pandas\n",
        "!pip install rl\n",
        "!pip install keras-rl2\n",
        "!pip install Callbacks \n",
        "!pip install callbacks\n",
        "!pip install rl.callbacks\n",
        "!pip install tf-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive Connection"
      ],
      "metadata": {
        "id": "4pEH2djqcrQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "os.chdir('drive/My Drive/Colab Notebooks/DQN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKy9ZcaPcvD9",
        "outputId": "0305362b-9fd3-469c-efb8-0bd131a93180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlSMQU35o0K8"
      },
      "source": [
        "# Enviroment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9vXtGVO_ddA"
      },
      "source": [
        "## MergedDataStructure"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the data structure we use to instantiate the multi-resolution feature vector. "
      ],
      "metadata": {
        "id": "MLqo8F7U_H4W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suBLM3zNo285"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "MergedDataStructure.py\n",
        "'''\n",
        "# Library used to manipulate the CSV Dataset\n",
        "# organize the dataset for the Enviroment\n",
        "import pandas\n",
        "\n",
        "# Library used to manipulate dates\n",
        "import datetime\n",
        "\n",
        "class MergedDataStructure():\n",
        "\n",
        "    def __init__(self, delta=4, filename=\"sp500Week.csv\"):\n",
        "        self.delta = delta\n",
        "\n",
        "        # Read the CSV\n",
        "        timeserie = pandas.read_csv(filename)\n",
        "        \n",
        "        # Transform each column into a list\n",
        "        Date = timeserie.loc[:, 'Date'].tolist()\n",
        "        Time = timeserie.loc[:, 'Time'].tolist()\n",
        "        Open = timeserie.loc[:, 'Open'].tolist()\n",
        "        High = timeserie.loc[:, 'High'].tolist()\n",
        "        Low = timeserie.loc[:, 'Low'].tolist()\n",
        "        Close = timeserie.loc[:, 'Close'].tolist()\n",
        "\n",
        "        # Create empty list and dictionary\n",
        "        self.list=[]\n",
        "        self.dict={}\n",
        "\n",
        "        # The limit is the number of dates\n",
        "        limit = len(Date)\n",
        "\n",
        "        # Just converting pandas data to a list\n",
        "        # lets pick up the csv data and put them in the list (self.list) \n",
        "        for i in range(0, limit-1):\n",
        "            self.list.append({'Date' : Date[i], 'Time' : Time[i], 'Open': Open[i], 'High': High[i], 'Low': Low[i], 'Close': Close[i]})\n",
        "            \n",
        "            # Fill the gaps with days that do not exist \n",
        "            dateList = [datetime.datetime.strptime(Date[i+1], \"%m/%d/%Y\") - datetime.timedelta(days=x) for x in range(0, ( datetime.datetime.strptime(Date[i+1], \"%m/%d/%Y\")- datetime.datetime.strptime(Date[i], \"%m/%d/%Y\") ).days )]\n",
        "            \n",
        "            for date in dateList:\n",
        "                dateString = date.strftime(\"%m/%d/%Y\")\n",
        "                # Contains dates and indexes for the list self.list\n",
        "                self.dict[dateString] = i\n",
        "\n",
        "    def get(self, date):\n",
        "        # Converts the date to string\n",
        "        dateString = str(date)\n",
        "        # given the date, you get an interval(delta) of past days or weeks\n",
        "        return self.list[self.dict[dateString]-(self.delta):self.dict[dateString]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weekData = MergedDataStructure(delta=3, filename='datasets/daxWeek.csv')"
      ],
      "metadata": {
        "id": "0fJqBtbkVZFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pandas.read_csv(\"datasets/daxWeek.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iwEU_zACV77f",
        "outputId": "84a177ac-e635-414b-dd75-eed8cefe562d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Date   Time     Open     High      Low    Close\n",
              "0    01/10/2000  00:00   7793.5   7815.5   7043.5   7435.5\n",
              "1    01/17/2000  00:00   7535.5   7931.5   7434.0   7834.5\n",
              "2    01/24/2000  00:00   7868.5   7943.5   7552.5   7621.0\n",
              "3    01/31/2000  00:00   7665.5   7850.0   7439.5   7700.5\n",
              "4    02/07/2000  00:00   7634.5   8079.5   7439.5   8008.5\n",
              "..          ...    ...      ...      ...      ...      ...\n",
              "992  02/07/2019  00:00  11252.5  11403.5  11013.0  11322.0\n",
              "993  02/14/2019  00:00  11310.5  11316.0  10875.0  11197.0\n",
              "994  02/21/2019  00:00  11200.5  11500.0  11030.0  11437.0\n",
              "995  02/28/2019  00:00  11432.0  11574.0  11404.0  11505.0\n",
              "996  03/07/2019  00:00  11515.0  11697.0  11415.5  11587.0\n",
              "\n",
              "[997 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3b73b63-7844-4581-84c6-f99554a66dd8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01/10/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7793.5</td>\n",
              "      <td>7815.5</td>\n",
              "      <td>7043.5</td>\n",
              "      <td>7435.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01/17/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7535.5</td>\n",
              "      <td>7931.5</td>\n",
              "      <td>7434.0</td>\n",
              "      <td>7834.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01/24/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7868.5</td>\n",
              "      <td>7943.5</td>\n",
              "      <td>7552.5</td>\n",
              "      <td>7621.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01/31/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7665.5</td>\n",
              "      <td>7850.0</td>\n",
              "      <td>7439.5</td>\n",
              "      <td>7700.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02/07/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7634.5</td>\n",
              "      <td>8079.5</td>\n",
              "      <td>7439.5</td>\n",
              "      <td>8008.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>02/07/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11252.5</td>\n",
              "      <td>11403.5</td>\n",
              "      <td>11013.0</td>\n",
              "      <td>11322.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>02/14/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11310.5</td>\n",
              "      <td>11316.0</td>\n",
              "      <td>10875.0</td>\n",
              "      <td>11197.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>02/21/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11200.5</td>\n",
              "      <td>11500.0</td>\n",
              "      <td>11030.0</td>\n",
              "      <td>11437.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>02/28/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11432.0</td>\n",
              "      <td>11574.0</td>\n",
              "      <td>11404.0</td>\n",
              "      <td>11505.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>03/07/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11515.0</td>\n",
              "      <td>11697.0</td>\n",
              "      <td>11415.5</td>\n",
              "      <td>11587.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>997 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3b73b63-7844-4581-84c6-f99554a66dd8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3b73b63-7844-4581-84c6-f99554a66dd8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3b73b63-7844-4581-84c6-f99554a66dd8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weekData.get(\"12/27/2018\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWRf1G7sJvuh",
        "outputId": "f09d6c4e-69ff-4044-d49a-9209302ab641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Close': 11412.5,\n",
              "  'Date': '11/29/2018',\n",
              "  'High': 11449.0,\n",
              "  'Low': 11096.0,\n",
              "  'Open': 11258.5,\n",
              "  'Time': '00:00'},\n",
              " {'Close': 11201.0,\n",
              "  'Date': '12/06/2018',\n",
              "  'High': 11575.5,\n",
              "  'Low': 10764.0,\n",
              "  'Open': 11401.0,\n",
              "  'Time': '00:00'},\n",
              " {'Close': 10935.5,\n",
              "  'Date': '12/13/2018',\n",
              "  'High': 11097.5,\n",
              "  'Low': 10590.5,\n",
              "  'Open': 11048.0,\n",
              "  'Time': '00:00'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kv-fhwc_grp"
      },
      "source": [
        "## Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a module used to log and trace the results."
      ],
      "metadata": {
        "id": "agjS4IwlCnz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVfzIUkPpQh6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Callback.py\n",
        "'''\n",
        "\n",
        "# Callbacks are functions used to give a feedback about each epoch calculated metrics\n",
        "from rl.callbacks import Callback\n",
        "\n",
        "class ValidationCallback(Callback):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initially, the metrics are zero\n",
        "        # actions: hold:0, long:1, short:2\n",
        "        self.episodes = 0 # number of episode\n",
        "        self.rewardSum = 0 # sum of the rewards \n",
        "        self.accuracy = 0 # increments if the action is not hold and the reward is positive\n",
        "        self.coverage = 0 # increments if the action is not hold \n",
        "        self.short = 0 # increments if the action is short\n",
        "        self.long = 0 # increments if the action is long\n",
        "        self.shortAcc = 0 # increments if the action is short and the reward is positive\n",
        "        self.longAcc = 0 # increments if the action is long and the reward is positive\n",
        "        self.longPrec = 0 # increments if the market rises and the action is long\n",
        "        self.shortPrec = 0 # increments if the market falls and the action is short\n",
        "        self.marketRise = 0 # increments if the market rises\n",
        "        self.marketFall = 0 # increments if the market falls\n",
        "\n",
        "    def reset(self):\n",
        "        # The metrics are also zero when the epoch ends\n",
        "        self.episodes = 0 \n",
        "        self.rewardSum = 0 \n",
        "        self.accuracy = 0\n",
        "        self.coverage = 0\n",
        "        self.short = 0\n",
        "        self.long = 0\n",
        "        self.shortAcc = 0\n",
        "        self.longAcc = 0\n",
        "        self.longPrec = 0\n",
        "        self.shortPrec = 0\n",
        "        self.marketRise = 0\n",
        "        self.marketFall = 0\n",
        "        \n",
        "    # all information is given by the environment: action, reward and market\n",
        "    # Then, when the episode ends, metrics are calculated\n",
        "    def on_episode_end(self, action, reward, market): # market = reward - transaction cost\n",
        "        \n",
        "        # After the episode ends, increments the episodes \n",
        "        self.episodes+=1\n",
        "\n",
        "        # Increments the reward\n",
        "        self.rewardSum+=reward\n",
        "\n",
        "        # If the action is not a hold, there is coverage because the agent decided \n",
        "        self.coverage+=1 if (action != 0) else 0\n",
        "\n",
        "        # increments the accuracy if the reward is positive (we have a hit)\n",
        "        self.accuracy+=1 if (reward >= 0 and action != 0) else 0\n",
        "        \n",
        "        # Increments the counter for short if the action is a short (id 2)\n",
        "        self.short +=1 if(action == 2) else 0\n",
        "        \n",
        "        # Increments the counter for long if the action is a long (id 1)\n",
        "        self.long +=1 if(action == 1) else 0\n",
        "        \n",
        "        # We will also calculate the accuracy for a given action. Here, it increments\n",
        "        # the accuracy for short if the action is short and the reward is positive\n",
        "        self.shortAcc +=1 if(action == 2 and reward >=0) else 0\n",
        "        \n",
        "        # Increments the accuracy for long if the action is long and the reward is positive\n",
        "        self.longAcc +=1 if(action == 1 and reward >=0) else 0\n",
        "        \n",
        "        # If the market increases, increments the marketRise variable. If the prediction is 1 (long), increments the precision for long\n",
        "        if(market > 0): # market = close - open\n",
        "            self.marketRise+=1\n",
        "            self.longPrec+=1 if(action == 1) else 0\n",
        "\n",
        "        # If market decreases, increments the marketFall. If the prediction is 2 (short), increments the precision for short   \n",
        "        elif(market < 0):\n",
        "            self.marketFall+=1\n",
        "            self.shortPrec+=1 if(action == 2) else 0\n",
        "\n",
        "    # Function to show the metrics of the episode  \n",
        "    def getInfo(self):\n",
        "        # Start setting them to zero\n",
        "        acc = 0\n",
        "        cov = 0\n",
        "        short = 0\n",
        "        long = 0\n",
        "        longAcc = 0\n",
        "        shortAcc = 0\n",
        "        longPrec = 0\n",
        "        shortPrec = 0\n",
        "        \n",
        "        # If there is coverage, we will calculate the accuracy only related to when decisions were made. \n",
        "        # In other words, we dont calculate accuracy for hold operations\n",
        "        if self.coverage > 0:\n",
        "            acc = self.accuracy / self.coverage\n",
        "        \n",
        "        # Now, we calculate the mean coverage, short and long operations from the episodes\n",
        "        if self.episodes > 0:\n",
        "            cov = self.coverage / self.episodes\n",
        "            short = self.short / self.episodes\n",
        "            long = self.long / self.episodes\n",
        "\n",
        "        # Calculate the mean accuracy for short operations. \n",
        "        # That is, the number of total short correctly predicted (self.shortAcc) \n",
        "        # divided by the total of shorts predicted (self.short)\n",
        "        if self.short > 0:\n",
        "            shortAcc = self.shortAcc / self.short\n",
        "        \n",
        "        # Calculate the mean accuracy for long operations. \n",
        "        # That is, the number of total short correctly predicted (long.shortAcc) \n",
        "        # divided by the total of longs predicted (long.short) \n",
        "        if self.long > 0:\n",
        "            longAcc = self.longAcc / self.long\n",
        "\n",
        "        if self.marketRise > 0:\n",
        "            longPrec = self.longPrec / self.marketRise\n",
        "\n",
        "        if self.marketFall > 0:\n",
        "            shortPrec = self.shortPrec / self.marketFall\n",
        "\n",
        "        # Returns the metrics to the user    \n",
        "        return self.episodes, cov, acc, self.rewardSum, long, short, longAcc, shortAcc, longPrec, shortPrec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwYvhtPN_ldD"
      },
      "source": [
        "## spEnv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMHIYTs3rsJG"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "spEnv.py\n",
        "'''\n",
        "# Environment used for spenv \n",
        "# gym is the library of videogames used by reinforcement learning\n",
        "import gym\n",
        "from gym import spaces\n",
        "# Numpy is the library to deal with matrices\n",
        "import numpy\n",
        "# Pandas is the library used to deal with the CSV dataset\n",
        "import pandas\n",
        "# datetime is the library used to manipulate time and date\n",
        "from datetime import datetime\n",
        "\n",
        "# This is the prefix of the files that will be opened. It is related to the s&p500 stock market datasets\n",
        "MK = \"dax\"\n",
        "\n",
        "\n",
        "class SpEnv(gym.Env):\n",
        "    # Just for the gym library. In a continuous environment, you can do infinite decisions. \n",
        "    # We dont want this because we have just three possible actions.\n",
        "    continuous = False\n",
        "\n",
        "    # Observation window is the time window regarding the \"hourly\" dataset \n",
        "    # ensemble variable tells to save or not the decisions at each walk\n",
        "    def __init__(self, minLimit=None, maxLimit=None, operationCost=0, observationWindow=40, ensamble=None, callback=None, isOnlyShort=False, columnName=\"iteration-1\"):\n",
        "        # Declare the episode as the first episode\n",
        "        self.episode = 1\n",
        "\n",
        "        self.isOnlyShort = isOnlyShort\n",
        "        \n",
        "        # Open the time series as the hourly dataset of S&P500\n",
        "        # the input feature vector is composed of data from hours, weeks and days\n",
        "        # 20 from days, 8 from weeks and 40 hours, ending with 68 dimensional feature vectors\n",
        "        hourData = pandas.read_csv('datasets/'+MK+'Hour.csv')[minLimit:maxLimit] # opening the dataset\n",
        "        \n",
        "        # Converts each column to a list\n",
        "        Date = hourData.loc[:, 'Date'].tolist()\n",
        "        Time = hourData.loc[:, 'Time'].tolist()\n",
        "        Open = hourData.loc[:, 'Open'].tolist()\n",
        "        High = hourData.loc[:, 'High'].tolist()\n",
        "        Low = hourData.loc[:, 'Low'].tolist()\n",
        "        Close = hourData.loc[:, 'Close'].tolist()\n",
        "        \n",
        "        # Open the weekly and daily data as a merged data structure\n",
        "        # Get 20 dimensional vectors (close-open) considering 20 past days and 8 dimensional vectors (close-open) \n",
        "        # considering 8 weeks\n",
        "        self.weekData = MergedDataStructure(delta=8, filename='datasets/'+MK+\"Week.csv\")# this DS allows me to obtain previous historical data with different resolution\n",
        "        self.dayData = MergedDataStructure(delta=20, filename='datasets/'+MK+\"Day.csv\")#  with low computational complexity\n",
        "        \n",
        "        # Load the data\n",
        "        self.output = False # it will be True if we decide to save the decisions in each epoch & date or self.ensamble is not None\n",
        "\n",
        "        # ensamble is the table of validation and testing\n",
        "        # If it is none, you will not save csvs of validation and testing    \n",
        "        if(ensamble is not None): # managing the ensamble output (maybe in the wrong way)\n",
        "            self.output = True\n",
        "            self.ensamble = ensamble\n",
        "            self.columnName = columnName\n",
        "            # self.ensemble is a big table (before file writing) containing observations as lines and epochs as columns\n",
        "            # each column will contain a decision for each epoch at each date. It is saved later.\n",
        "            # We read this table later in order to make ensemble decisions at each epoch\n",
        "            self.ensamble[self.columnName] = 0\n",
        "\n",
        "        # Declare low and high as vectors with -inf values \n",
        "        # low and high are the minimun and maximum accepted values in feature vector\n",
        "        self.low = numpy.array([-numpy.inf])\n",
        "        self.high = numpy.array([+numpy.inf])\n",
        "\n",
        "        # Define the space of actions as 3\n",
        "        # the action space is just 0, 1, 2 which means hold, long, short\n",
        "        self.action_space = spaces.Discrete(3) \n",
        "        \n",
        "        # low and high are the minimun and maximum accepted values for this problem\n",
        "        # We don't know what are the minimum and maximum values of Close-Open, so we put these values\n",
        "        self.observation_space = spaces.Box(self.low, self.high, dtype=numpy.float32)\n",
        "\n",
        "        # Set observationWindow = 40 (40 hours)\n",
        "        # Observation window is the time window regarding the \"hourly\" dataset\n",
        "        self.observationWindow = observationWindow\n",
        "        \n",
        "        # Set the current observation as 40\n",
        "        self.currentObservation = observationWindow\n",
        "        # The operation cost is defined as \n",
        "        self.operationCost = operationCost\n",
        "        # Defines that the environment is not done yet\n",
        "        self.done = False\n",
        "        # The limit is the number of open values in the dataset (could be any other value): it shows the number of data\n",
        "        self.limit = len(Open)\n",
        "        # organizing the hour dataset as a list of dictionaries \n",
        "        # The history begins empty\n",
        "        self.history = []\n",
        "        for i in range(0, self.limit): \n",
        "            self.history.append({'Date' : Date[i],'Time' : Time[i], 'Open': Open[i], 'High': High[i], 'Low': Low[i], 'Close': Close[i]})\n",
        "        \n",
        "        # Next observation starts\n",
        "        self.nextObservation = 0\n",
        "        \n",
        "        # self.history contains all the hour data. Here we search for the next day \n",
        "        while(self.history[self.currentObservation]['Date']==self.history[(self.currentObservation+self.nextObservation)%self.limit]['Date']):\n",
        "            self.nextObservation += 1\n",
        "        \n",
        "        # Initiates the values to be returned by the environment\n",
        "        self.reward = None\n",
        "        self.possibleGain = 0\n",
        "        self.openValue = 0\n",
        "        self.closeValue = 0\n",
        "        self.callback = callback\n",
        "\n",
        "\n",
        "    # This is the action that is done in the environment. \n",
        "    # Receives the action and returns the state, the reward and if its done \n",
        "    def step(self, action):\n",
        "        #Initiates the reward, weeklist and daylist\n",
        "        self.reward = 0\n",
        "        \n",
        "\n",
        "        ##UNCOMMENT NEXT LINE FOR ONLY SHORT AGENT\n",
        "        if(self.isOnlyShort):\n",
        "            action *= 2   # ??????????????????\n",
        "\n",
        "\n",
        "        # Set the next observation to zero\n",
        "        self.nextObservation = 0\n",
        "        # Search for the close value for tommorow\n",
        "        while(self.history[self.currentObservation]['Date']==self.history[(self.currentObservation+self.nextObservation)%self.limit]['Date']):\n",
        "            # Search for the close error for today\n",
        "            self.closeValue = self.history[(self.currentObservation+self.nextObservation)%self.limit]['Close']\n",
        "            self.nextObservation += 1\n",
        "\n",
        "        # Get the open value for today \n",
        "        self.openValue = self.history[self.currentObservation]['Open']\n",
        "\n",
        "        '''\n",
        "        Reward\n",
        "        '''\n",
        "        # Calculate the reward in percentage of growing/decreasing\n",
        "        self.possibleGain = (self.closeValue - self.openValue) / self.openValue\n",
        "        # If action is a long, calculate the reward \n",
        "        if(action == 1):\n",
        "            # The reward must be subtracted by the cost of transaction\n",
        "            self.reward = self.possibleGain - self.operationCost\n",
        "        # If action is a short, calculate the reward     \n",
        "        elif(action==2):\n",
        "            self.reward = (-self.possibleGain)-self.operationCost\n",
        "        # If action is a hold, no reward     \n",
        "        else:\n",
        "            self.reward = 0\n",
        "\n",
        "\n",
        "        # Finish episode \n",
        "        self.done = True\n",
        "\n",
        "\n",
        "        # Call the callback for the episode\n",
        "        if(self.callback != None and self.done):\n",
        "            self.callback.on_episode_end(action, self.reward, self.possibleGain)\n",
        "        \n",
        "\n",
        "        # File of the ensamble (file containing each epoch decisions at each walk) will contain the action for that \n",
        "        # day (observation, line) at each epoch (column)\n",
        "        if(self.output):\n",
        "            self.ensamble.at[self.history[self.currentObservation]['Date'], self.columnName] = action\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Return the state, reward and if its done or not\n",
        "        return self.getObservation(self.history[self.currentObservation]['Date']), self.reward, self.done, {}\n",
        "        \n",
        "    #function done when the episode finishes\n",
        "    #reset will prepare the next state (feature vector) and give it to the agent\n",
        "    def reset(self):\n",
        "\n",
        "        if(self.currentObservation < self.observationWindow):\n",
        "            self.currentObservation = self.observationWindow\n",
        "\n",
        "\n",
        "        \n",
        "        self.episode+=1\n",
        "        \n",
        "        \n",
        "        # Shiftting the index for the first hour of the next day\n",
        "        self.nextObservation=0\n",
        "        while(self.history[self.currentObservation]['Date']==self.history[(self.currentObservation+self.nextObservation)%self.limit]['Date']):\n",
        "            self.nextObservation+=1\n",
        "            # check if the index exceeds the limits\n",
        "            if((self.currentObservation+self.nextObservation)>=self.limit):\n",
        "                print(\"Resetted: episode \" + str(self.episode) +\"; Index \" + str(self.currentObservation+self.nextObservation) + \" over the limit (\" + str(self.limit) + \")\" )\n",
        "            \n",
        "        # reset the values used in the step() function\n",
        "        self.done = False\n",
        "        self.reward = None\n",
        "        self.possibleGain = 0\n",
        "        self.openValue = 0\n",
        "        self.closeValue = 0\n",
        "\n",
        "        #Prepapre to get the next observation\n",
        "        self.currentObservation+=self.nextObservation\n",
        "        if(self.currentObservation>=self.limit):\n",
        "            self.currentObservation=self.observationWindow\n",
        "        \n",
        "        return self.getObservation(self.history[self.currentObservation]['Date'])\n",
        "\n",
        "\n",
        "    def getObservation(self, date):\n",
        "\n",
        "        # Get the daily information and week information\n",
        "        # get all the data\n",
        "        dayList = self.dayData.get(date)\n",
        "        weekList = self.weekData.get(date)\n",
        "\n",
        "        # Get the previous 40 hours regarding each date\n",
        "        currentData = self.history[self.currentObservation-self.observationWindow:self.currentObservation] \n",
        "\n",
        "        # The data is finally concatenated here. We concatenate Hours, days and weeks information\n",
        "        feature_vector = currentData + dayList + weekList\n",
        "\n",
        "        # Calculates the close minus open \n",
        "        # The percentage of growing or decreasing is calculated as CloseMinusOpen\n",
        "        # This is the input vector\n",
        "        # closeMinusOpen=list(map(lambda x: (x[\"Close\"]-x[\"Open\"])/x[\"Open\"],self.history[self.currentObservation-self.observationWindow:self.currentObservation]  + self.dayData.get(date) + self.weekData.get(date)))\n",
        "        \n",
        "        # The state is prepared by the environment, which is simply the feature vector\n",
        "        return  numpy.array([list(map(lambda x: (x[\"Close\"]-x[\"Open\"])/x[\"Open\"], feature_vector))])\n",
        "    \n",
        "    def resetEnv(self):\n",
        "        self.currentObservation = self.observationWindow\n",
        "        # Resets the episode to 1\n",
        "        self.episode = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwdGjA34GIBc"
      },
      "source": [
        "# main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56xe9An9nMDH"
      },
      "source": [
        "The code needs three positional parameters to be correctly executed: \\\\\n",
        "python main.py [numberOfActions, isOnlyShort, ensembleFolder]\n",
        "\n",
        "\n",
        "* To run the FULL agent you need to run: python main.py 3 0 ensembleFolder\n",
        "* To run the ONLY LONG agent you need to run: python main.py 2 0 ensembleFolder\n",
        "* To run the ONLY SHORT agent you need to run: python main.py 2 1 ensembleFolder \\\\\n",
        "where the paramenter ensembleFolder is used to set the name of the folder in which you'll get your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXdjyJFQzAo2"
      },
      "source": [
        "## DeepQTrading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik31bGTJxTS4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "deepQTrading.py\n",
        "'''\n",
        "# Imports the SPEnv library, which will perform the Agent actions themselves\n",
        "# from spEnv import SpEnv\n",
        "\n",
        "# Callback used to print the results at each episode\n",
        "# from callback import ValidationCallback\n",
        "\n",
        "# Keras library for the NN considered\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Keras libraries for layers, activations and optimizers used\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# RL Agent \n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "\n",
        "# Mathematical operations used later\n",
        "from math import floor\n",
        "\n",
        "# Library to manipulate the dataset in a csv file\n",
        "import pandas as pd\n",
        "\n",
        "# Library used to manipulate time\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Prefix of the name of the market (S&P500) files used to load the data\n",
        "MK=\"dax\"\n",
        "\n",
        "class DeepQTrading:\n",
        "    '''\n",
        "    Class constructor\n",
        "    model: Keras model considered\n",
        "    Explorations is a vector containing (i) probability of random predictions; (ii) how many epochs will be \n",
        "    runned by the algorithm (we run the algorithm several times-several iterations)  \n",
        "    trainSize: size of the training set\n",
        "    validationSize: size of the validation set\n",
        "    testSize: size of the testing set \n",
        "    outputFile: name of the file to print results\n",
        "    begin: Initial date\n",
        "    end: final date\n",
        "    nbActions: number of decisions (0-Hold 1-Long 2-Short) \n",
        "    nOutput is the number of walks. We are doing 5 walks.  \n",
        "    operationCost: Price for the transaction (we set they are free)\n",
        "    '''\n",
        "    def __init__(self, model, explorations, trainSize, validationSize, testSize, outputFile, begin, end, nbActions, isOnlyShort, ensembleFolderName, operationCost=0):\n",
        "        \n",
        "        self.isOnlyShort = isOnlyShort\n",
        "        self.ensembleFolderName = ensembleFolderName\n",
        "\n",
        "        # Define the policy, explorations, actions and model as received by parameters\n",
        "        self.policy = EpsGreedyQPolicy()\n",
        "        self.explorations = explorations\n",
        "        self.nbActions = nbActions\n",
        "        self.model = model\n",
        "\n",
        "        # Define the memory\n",
        "        self.memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "        # Instantiate the agent with parameters received\n",
        "        self.agent = DQNAgent(model=self.model, policy=self.policy,  nb_actions=self.nbActions, memory=self.memory, nb_steps_warmup=200, target_model_update=1e-1,\n",
        "                                    enable_double_dqn=True, enable_dueling_network=True)\n",
        "        \n",
        "        # Compile the agent with the adam optimizer and with the mean absolute error metric\n",
        "        self.agent.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "        # Save the weights of the agents in the q.weights file\n",
        "        # Save random weights\n",
        "        self.agent.save_weights(\"q.weights\", overwrite=True)\n",
        "\n",
        "        # Define the current starting point as the initial date\n",
        "        self.currentStartingPoint = begin\n",
        "\n",
        "        # Define the training, validation and testing size as informed by the call\n",
        "        # Train: 5 years\n",
        "        # Validation: 6 months\n",
        "        # Test: 6 months\n",
        "        self.trainSize = trainSize\n",
        "        self.validationSize = validationSize\n",
        "        self.testSize = testSize\n",
        "        \n",
        "        # The walk size is simply summing up the train, validation and test sizes\n",
        "        self.walkSize = trainSize + validationSize + testSize\n",
        "        \n",
        "        # Define the ending point as the final date (January 1st of 2010)\n",
        "        self.endingPoint = end\n",
        "\n",
        "        # Read the hourly dataset\n",
        "        # We join data from different files\n",
        "        # Here hour data is read \n",
        "        self.dates = pd.read_csv('datasets/'+MK+'Hour.csv')\n",
        "        self.sp = pd.read_csv('datasets/'+MK+'Hour.csv')\n",
        "        # Convert the pandas format to date and time format\n",
        "        self.sp['Datetime'] = pd.to_datetime(self.sp['Date'] + ' ' + self.sp['Time'])\n",
        "        # Set an index to Datetime on the pandas loaded dataset. Registers will be indexes through these values\n",
        "        self.sp = self.sp.set_index('Datetime')\n",
        "        # Drop Time and Date from the Dataset\n",
        "        self.sp = self.sp.drop(['Time','Date'], axis=1)\n",
        "        # Just the index considering date and time will be important, because date and time will be used to define the train, \n",
        "        # validation and test for each walk\n",
        "        self.sp = self.sp.index\n",
        "\n",
        "        # Receives the operation cost, which is 0\n",
        "        # Operation cost is the cost for long and short. It is defined as zero\n",
        "        self.operationCost = operationCost\n",
        "        \n",
        "        # Call the callback for training, validation and test in order to show results for each episode \n",
        "        self.trainer = ValidationCallback()\n",
        "        self.validator = ValidationCallback()\n",
        "        self.tester = ValidationCallback()\n",
        "        self.outputFileName = outputFile\n",
        "\n",
        "    def run(self):\n",
        "        # Initiates the environments\n",
        "        trainEnv = validEnv = testEnv = \" \"\n",
        "        iteration = -1\n",
        "\n",
        "        # While we did not pass through all the dates (i.e., while all the walks were not finished)\n",
        "        # walk size is train+validation+test size\n",
        "        # currentStarting point begins with begin date\n",
        "        while(self.currentStartingPoint + self.walkSize <= self.endingPoint):\n",
        "\n",
        "            # Iteration is the current walk\n",
        "            iteration+=1\n",
        "\n",
        "            # Initiate the output file\n",
        "            self.outputFile = open(self.outputFileName+str(iteration+1)+\".csv\", \"w+\")\n",
        "            # write the first row of the csv\n",
        "            self.outputFile.write(\n",
        "                \"Iteration,\"+\n",
        "                \"trainAccuracy,\"+\n",
        "                \"trainCoverage,\"+\n",
        "                \"trainReward,\"+\n",
        "                \"trainLong%,\"+\n",
        "                \"trainShort%,\"+\n",
        "                \"trainLongAcc,\"+\n",
        "                \"trainShortAcc,\"+\n",
        "                \"trainLongPrec,\"+\n",
        "                \"trainShortPrec,\"+\n",
        "\n",
        "                \"validationAccuracy,\"+\n",
        "                \"validationCoverage,\"+\n",
        "                \"validationReward,\"+\n",
        "                \"validationLong%,\"+\n",
        "                \"validationShort%,\"+\n",
        "                \"validationLongAcc,\"+\n",
        "                \"validationShortAcc,\"+\n",
        "                \"validLongPrec,\"+\n",
        "                \"validShortPrec,\"+\n",
        "                \n",
        "                \"testAccuracy,\"+\n",
        "                \"testCoverage,\"+\n",
        "                \"testReward,\"+\n",
        "                \"testLong%,\"+\n",
        "                \"testShort%,\"+\n",
        "                \"testLongAcc,\"+\n",
        "                \"testShortAcc,\"+\n",
        "                \"testLongPrec,\"+\n",
        "                \"testShortPrec\\n\")\n",
        "\n",
        "\n",
        "            \n",
        "            # Empty the memory and agent\n",
        "            del(self.memory)\n",
        "            del(self.agent)\n",
        "\n",
        "            # Define the memory and agent\n",
        "            # Memory is Sequential\n",
        "            self.memory = SequentialMemory(limit=10000, window_length=1)\n",
        "            # Agent is initiated as passed through parameters\n",
        "            self.agent = DQNAgent(model=self.model, policy=self.policy,  nb_actions=self.nbActions, memory=self.memory, nb_steps_warmup=200, target_model_update=1e-1,\n",
        "                                    enable_double_dqn=True,enable_dueling_network=True)\n",
        "            # Compile the agent with Adam initialization\n",
        "            self.agent.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "            \n",
        "            # Load the weights saved before in a random way if it is the first time\n",
        "            self.agent.load_weights(\"q.weights\")\n",
        "            \n",
        "            ########################################TRAINING STAGE########################################################\n",
        "            \n",
        "            # The TrainMinLimit will be loaded as the initial date at the beginning, and will be updated later.\n",
        "            # If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date    \n",
        "            trainMinLimit = None\n",
        "            while(trainMinLimit is None):\n",
        "                try:\n",
        "                    trainMinLimit = self.sp.get_loc(self.currentStartingPoint)\n",
        "                except:\n",
        "                    # datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0, 0, 0, 0, 0, 1, 0)\n",
        "\n",
        "            # The TrainMaxLimit will be loaded as the interval between the initial date plus the training size.\n",
        "            # If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date    \n",
        "            trainMaxLimit=None\n",
        "            while(trainMaxLimit is None):\n",
        "                try:\n",
        "                    trainMaxLimit = self.sp.get_loc(self.currentStartingPoint + self.trainSize)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0, 0, 0, 0, 0, 1, 0)\n",
        "            \n",
        "            ########################################VALIDATION STAGE#######################################################\n",
        "            # The ValidMinLimit will be loaded as the next element of the TrainMax limit\n",
        "            validMinLimit = trainMaxLimit+1\n",
        "\n",
        "            # The ValidMaxLimit will be loaded as the interval after the begin + train size +validation size\n",
        "            # If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date  \n",
        "            validMaxLimit = None\n",
        "            while(validMaxLimit is None):\n",
        "                try:\n",
        "                    validMaxLimit = self.sp.get_loc(self.currentStartingPoint + self.trainSize + self.validationSize)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0, 0, 0, 0, 0, 1, 0)\n",
        "\n",
        "            ########################################TESTING STAGE######################################################## \n",
        "            # The TestMinLimit will be loaded as the next element of ValidMaxlimit \n",
        "            testMinLimit = validMaxLimit+1\n",
        "\n",
        "            # The testMaxLimit will be loaded as the interval after the begin + train size +validation size + Testsize\n",
        "            # If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date \n",
        "            testMaxLimit = None\n",
        "            while(testMaxLimit is None):\n",
        "                try:\n",
        "                    testMaxLimit = self.sp.get_loc(self.currentStartingPoint + self.trainSize + self.validationSize + self.testSize)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0, 0, 0, 0, 0, 1, 0)\n",
        "\n",
        "            # Separate the Validation and testing data according to the limits found before\n",
        "            # Prepare the training and validation files for saving them later \n",
        "            ensambleValid = pd.DataFrame(index=self.dates[validMinLimit:validMaxLimit].loc[:,'Date'].drop_duplicates().tolist())\n",
        "            ensambleTest = pd.DataFrame(index=self.dates[testMinLimit:testMaxLimit].loc[:,'Date'].drop_duplicates().tolist())\n",
        "            \n",
        "            # Put the name of the index for validation and testing\n",
        "            ensambleValid.index.name = 'Date'\n",
        "            ensambleTest.index.name = 'Date'\n",
        "            \n",
        "            # Explorations are epochs considered, or how many times the agent will play the game.  \n",
        "            for eps in self.explorations:\n",
        "\n",
        "                # policy will be 0.2, so the randomness of predictions (actions) will happen with 20% of probability \n",
        "                self.policy.eps = eps[0]\n",
        "                \n",
        "                # there will be 100 iterations (epochs), or eps[1])\n",
        "                for i in range(0, eps[1]):\n",
        "                    \n",
        "                    del(trainEnv)\n",
        "\n",
        "                    # Define the training, validation and testing environments with their respective callbacks\n",
        "                    trainEnv = SpEnv(operationCost=self.operationCost,minLimit=trainMinLimit,maxLimit=trainMaxLimit,callback=self.trainer,isOnlyShort=self.isOnlyShort)\n",
        "                    del(validEnv)\n",
        "                    validEnv = SpEnv(operationCost=self.operationCost,minLimit=validMinLimit,maxLimit=validMaxLimit,callback=self.validator,isOnlyShort=self.isOnlyShort,ensamble=ensambleValid,columnName=\"iteration\"+str(i))\n",
        "                    del(testEnv)\n",
        "                    testEnv = SpEnv(operationCost=self.operationCost,minLimit=testMinLimit,maxLimit=testMaxLimit,callback=self.tester,isOnlyShort=self.isOnlyShort,ensamble=ensambleTest,columnName=\"iteration\"+str(i))\n",
        "\n",
        "                    # Reset the callback\n",
        "                    self.trainer.reset()\n",
        "                    self.validator.reset()\n",
        "                    self.tester.reset()\n",
        "\n",
        "                    # Reset the training environment\n",
        "                    trainEnv.resetEnv()\n",
        "                    # Train the agent\n",
        "                    self.agent.fit(trainEnv, nb_steps=floor(self.trainSize.days-self.trainSize.days*0.2),visualize=False,verbose=0)\n",
        "                    # Get the info from the train callback\n",
        "                    (_,trainCoverage,trainAccuracy,trainReward,trainLongPerc,trainShortPerc,trainLongAcc,trainShortAcc,trainLongPrec,trainShortPrec)=self.trainer.getInfo()\n",
        "                    # Print Callback values on the screen\n",
        "                    print(str(i) + \" TRAIN:  acc: \" + str(trainAccuracy)+ \" cov: \" + str(trainCoverage)+ \" rew: \" + str(trainReward))\n",
        "\n",
        "                    # Reset the validation environment\n",
        "                    validEnv.resetEnv()\n",
        "                    # Test the agent on validation data\n",
        "                    self.agent.test(validEnv,nb_episodes=floor(self.validationSize.days-self.validationSize.days*0.2),visualize=False,verbose=0)\n",
        "                    # Get the info from the validation callback\n",
        "                    (_,validCoverage,validAccuracy,validReward,validLongPerc,validShortPerc,validLongAcc,validShortAcc,validLongPrec,validShortPrec)=self.validator.getInfo()\n",
        "                    # Print callback values on the screen\n",
        "                    print(str(i) + \" VALID:  acc: \" + str(validAccuracy)+ \" cov: \" + str(validCoverage)+ \" rew: \" + str(validReward))\n",
        "\n",
        "                    # Reset the testing environment\n",
        "                    testEnv.resetEnv()\n",
        "                    # Test the agent on testing data\n",
        "                    self.agent.test(testEnv,nb_episodes=floor(self.validationSize.days-self.validationSize.days*0.2),visualize=False,verbose=0)\n",
        "                    # Get the info from the testing callback\n",
        "                    (_,testCoverage,testAccuracy,testReward,testLongPerc,testShortPerc,testLongAcc,testShortAcc,testLongPrec,testShortPrec)=self.tester.getInfo()\n",
        "                    # Print callback values on the screen\n",
        "                    print(str(i) + \" TEST:  acc: \" + str(testAccuracy)+ \" cov: \" + str(testCoverage)+ \" rew: \" + str(testReward))\n",
        "                    print(\" \")\n",
        "                    \n",
        "                    # write the walk data on the text file\n",
        "                    self.outputFile.write(\n",
        "                        str(i)+\",\"+\n",
        "                        str(trainAccuracy)+\",\"+\n",
        "                        str(trainCoverage)+\",\"+\n",
        "                        str(trainReward)+\",\"+\n",
        "                        str(trainLongPerc)+\",\"+\n",
        "                        str(trainShortPerc)+\",\"+\n",
        "                        str(trainLongAcc)+\",\"+\n",
        "                        str(trainShortAcc)+\",\"+\n",
        "                        str(trainLongPrec)+\",\"+\n",
        "                        str(trainShortPrec)+\",\"+\n",
        "                        \n",
        "                        str(validAccuracy)+\",\"+\n",
        "                        str(validCoverage)+\",\"+\n",
        "                        str(validReward)+\",\"+\n",
        "                        str(validLongPerc)+\",\"+\n",
        "                        str(validShortPerc)+\",\"+\n",
        "                        str(validLongAcc)+\",\"+\n",
        "                        str(validShortAcc)+\",\"+\n",
        "                        str(validLongPrec)+\",\"+\n",
        "                        str(validShortPrec)+\",\"+\n",
        "                        \n",
        "                        str(testAccuracy)+\",\"+\n",
        "                        str(testCoverage)+\",\"+\n",
        "                        str(testReward)+\",\"+\n",
        "                        str(testLongPerc)+\",\"+\n",
        "                        str(testShortPerc)+\",\"+\n",
        "                        str(testLongAcc)+\",\"+\n",
        "                        str(testShortAcc)+\",\"+\n",
        "                        str(testLongPrec)+\",\"+\n",
        "                        str(testShortPrec)+\"\\n\")\n",
        "\n",
        "            # Close the file                \n",
        "            self.outputFile.close()\n",
        "\n",
        "            # For the next walk, the current starting point will be the current starting point + the test size\n",
        "            # It means that, for the next walk, the training data will start 6 months after the training data of \n",
        "            # the previous walk   \n",
        "            self.currentStartingPoint += self.testSize\n",
        "\n",
        "            # Write validation and Testing data into files\n",
        "            # Save the files for processing later with the ensemble considering the 100 epochs\n",
        "            ensambleValid.to_csv(\"Output/ensemble/\"+self.ensembleFolderName+\"/walk\"+str(iteration)+\"ensemble_valid.csv\")\n",
        "            ensambleTest.to_csv(\"Output/ensemble/\"+self.ensembleFolderName+\"/walk\"+str(iteration)+\"ensemble_test.csv\")\n",
        "\n",
        "    # Function to end the Agent\n",
        "    def end(self):\n",
        "        print(\"END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hISBRm7HzF64"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR_r2Ivdw-KN",
        "outputId": "6ad20ef6-d4b1-4f99-b164-cb0645b9e5a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function mean_q at 0x7f909622a5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function mean_q at 0x7f909622a5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f90958d3830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f90958d3830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f909587ccb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f909587ccb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f909587cb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f909587cb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f90915a33b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f90915a33b0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "0 TRAIN:  acc: 0.5283540802213001 cov: 0.5020833333333333 rew: 0.30771229378723275\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "0 VALID:  acc: 0.3333333333333333 cov: 0.2708333333333333 rew: -0.0781776832080168\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "0 TEST:  acc: 0.5681818181818182 cov: 0.3055555555555556 rew: 0.09481986303493471\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "1 TRAIN:  acc: 0.6338418862690708 cov: 0.5006944444444444 rew: 2.7777997369581775\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "1 VALID:  acc: 0.39655172413793105 cov: 0.8055555555555556 rew: -0.1375728695013169\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "1 TEST:  acc: 0.44 cov: 0.6944444444444444 rew: 0.01385462406702162\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "2 TRAIN:  acc: 0.6815578465063001 cov: 0.60625 rew: 4.095192494011858\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "2 VALID:  acc: 0.39285714285714285 cov: 0.5833333333333334 rew: -0.21211334077679453\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "2 TEST:  acc: 0.48717948717948717 cov: 0.5416666666666666 rew: 0.08965617308000409\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f90915a3290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f90915a3290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f697cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f697cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "0 TRAIN:  acc: 0.5374449339207048 cov: 0.47291666666666665 rew: 0.1100159781250749\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "0 VALID:  acc: 0.6511627906976745 cov: 0.5972222222222222 rew: 0.16114135326237636\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "0 TEST:  acc: 0.5670103092783505 cov: 0.6736111111111112 rew: 0.022431295229328074\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "1 TRAIN:  acc: 0.6308100929614874 cov: 0.5229166666666667 rew: 2.4632139699621654\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "1 VALID:  acc: 0.5526315789473685 cov: 0.5277777777777778 rew: -0.008029412910761848\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "1 TEST:  acc: 0.6266666666666667 cov: 0.5208333333333334 rew: 0.09827278499441543\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "2 TRAIN:  acc: 0.6887019230769231 cov: 0.5777777777777777 rew: 4.003776116490573\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "2 VALID:  acc: 0.578125 cov: 0.4444444444444444 rew: 0.0024155725744772986\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "2 TEST:  acc: 0.4383561643835616 cov: 0.5069444444444444 rew: -0.04546647427767958\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f697830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f697830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f3b69e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f3b69e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1240; Index 15541 over the limit (15541)\n",
            "0 TRAIN:  acc: 0.4984423676012461 cov: 0.44583333333333336 rew: 0.4081523053114341\n",
            "Resetted: episode 121; Index 1806 over the limit (1806)\n",
            "0 VALID:  acc: 0.4788732394366197 cov: 0.4930555555555556 rew: -0.06443573161421863\n",
            "Resetted: episode 128; Index 1933 over the limit (1933)\n",
            "0 TEST:  acc: 0.4696969696969697 cov: 0.4583333333333333 rew: -0.11683810583910426\n",
            " \n",
            "Resetted: episode 1240; Index 15541 over the limit (15541)\n",
            "1 TRAIN:  acc: 0.6212710765239948 cov: 0.5354166666666667 rew: 2.908643313886625\n",
            "Resetted: episode 121; Index 1806 over the limit (1806)\n",
            "1 VALID:  acc: 0.5054945054945055 cov: 0.6319444444444444 rew: -0.031445123201811476\n",
            "Resetted: episode 128; Index 1933 over the limit (1933)\n",
            "1 TEST:  acc: 0.45454545454545453 cov: 0.6875 rew: -0.1670918753465779\n",
            " \n",
            "Resetted: episode 1240; Index 15541 over the limit (15541)\n",
            "2 TRAIN:  acc: 0.6813063063063063 cov: 0.6166666666666667 rew: 4.595219786394529\n",
            "Resetted: episode 121; Index 1806 over the limit (1806)\n",
            "2 VALID:  acc: 0.4835164835164835 cov: 0.6319444444444444 rew: -0.020504541018316697\n",
            "Resetted: episode 128; Index 1933 over the limit (1933)\n",
            "2 TEST:  acc: 0.45544554455445546 cov: 0.7013888888888888 rew: -0.1046014598836159\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f3b68c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f3b68c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f0b3c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f0b3c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1236; Index 15851 over the limit (15851)\n",
            "0 TRAIN:  acc: 0.5375552282768777 cov: 0.47152777777777777 rew: 0.647083759789722\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "0 VALID:  acc: 0.5692307692307692 cov: 0.4513888888888889 rew: 0.07562540059355952\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "0 TEST:  acc: 0.44776119402985076 cov: 0.4652777777777778 rew: -0.16863234456373363\n",
            " \n",
            "Resetted: episode 1236; Index 15851 over the limit (15851)\n",
            "1 TRAIN:  acc: 0.6165680473372781 cov: 0.5868055555555556 rew: 3.6197589388959193\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "1 VALID:  acc: 0.5652173913043478 cov: 0.4791666666666667 rew: 0.11480259488769097\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "1 TEST:  acc: 0.53125 cov: 0.4444444444444444 rew: 0.1181091856851345\n",
            " \n",
            "Resetted: episode 1236; Index 15851 over the limit (15851)\n",
            "2 TRAIN:  acc: 0.676923076923077 cov: 0.6319444444444444 rew: 4.861683258449856\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "2 VALID:  acc: 0.5222222222222223 cov: 0.625 rew: 0.04340231859184425\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "2 TEST:  acc: 0.5137614678899083 cov: 0.7569444444444444 rew: 0.20234215618575696\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f0b3b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908f0b3b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908eda9b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908eda9b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1241; Index 16314 over the limit (16314)\n",
            "0 TRAIN:  acc: 0.5100574712643678 cov: 0.48333333333333334 rew: -0.2154822164511839\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "0 VALID:  acc: 0.5098039215686274 cov: 0.3541666666666667 rew: 0.011130507694641011\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "0 TEST:  acc: 0.574468085106383 cov: 0.3263888888888889 rew: 0.34428563527245815\n",
            " \n",
            "Resetted: episode 1241; Index 16314 over the limit (16314)\n",
            "1 TRAIN:  acc: 0.6260978670012547 cov: 0.5534722222222223 rew: 2.1131103717967963\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "1 VALID:  acc: 0.5444444444444444 cov: 0.625 rew: 0.09643798902793088\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "1 TEST:  acc: 0.5189873417721519 cov: 0.5486111111111112 rew: -0.10096890937131778\n",
            " \n",
            "Resetted: episode 1241; Index 16314 over the limit (16314)\n",
            "2 TRAIN:  acc: 0.6973094170403588 cov: 0.6194444444444445 rew: 3.750253647190221\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "2 VALID:  acc: 0.5178571428571429 cov: 0.7777777777777778 rew: 0.12011442957784246\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "2 TEST:  acc: 0.58 cov: 0.6944444444444444 rew: 0.32266627626757816\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908eda9a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908eda9a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908eac2a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908eac2a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1236; Index 16605 over the limit (16605)\n",
            "0 TRAIN:  acc: 0.5118219749652295 cov: 0.49930555555555556 rew: 0.04045416025773508\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "0 VALID:  acc: 0.5294117647058824 cov: 0.5902777777777778 rew: 0.19433932107626406\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "0 TEST:  acc: 0.41025641025641024 cov: 0.5416666666666666 rew: -0.3576624573388333\n",
            " \n",
            "Resetted: episode 1236; Index 16605 over the limit (16605)\n",
            "1 TRAIN:  acc: 0.6737235367372354 cov: 0.5576388888888889 rew: 2.0927704800856777\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "1 VALID:  acc: 0.5154639175257731 cov: 0.6736111111111112 rew: 0.3752229587693739\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "1 TEST:  acc: 0.4948453608247423 cov: 0.6736111111111112 rew: 0.0010950379654881184\n",
            " \n",
            "Resetted: episode 1236; Index 16605 over the limit (16605)\n",
            "2 TRAIN:  acc: 0.6823406478578893 cov: 0.6645833333333333 rew: 3.209492789992344\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "2 VALID:  acc: 0.5306122448979592 cov: 0.6805555555555556 rew: 0.11576231300337399\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "2 TEST:  acc: 0.5274725274725275 cov: 0.6319444444444444 rew: 0.02084433625702014\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908eac2950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908eac2950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e7a8dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e7a8dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1239; Index 17027 over the limit (17027)\n",
            "0 TRAIN:  acc: 0.5017502917152858 cov: 0.5951388888888889 rew: -0.34917230984930603\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "0 VALID:  acc: 0.38333333333333336 cov: 0.4166666666666667 rew: -0.22996836140532062\n",
            "Resetted: episode 129; Index 1944 over the limit (1944)\n",
            "0 TEST:  acc: 0.5517241379310345 cov: 0.6041666666666666 rew: -0.013195439539443113\n",
            " \n",
            "Resetted: episode 1239; Index 17027 over the limit (17027)\n",
            "1 TRAIN:  acc: 0.6028537455410226 cov: 0.5840277777777778 rew: 1.6095979019142432\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "1 VALID:  acc: 0.4909090909090909 cov: 0.3819444444444444 rew: -0.19206758442407285\n",
            "Resetted: episode 129; Index 1944 over the limit (1944)\n",
            "1 TEST:  acc: 0.410958904109589 cov: 0.5069444444444444 rew: -0.20388761871503333\n",
            " \n",
            "Resetted: episode 1239; Index 17027 over the limit (17027)\n",
            "2 TRAIN:  acc: 0.7151095732410612 cov: 0.6020833333333333 rew: 3.5268806729399467\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "2 VALID:  acc: 0.373134328358209 cov: 0.4652777777777778 rew: -0.3670548508976197\n",
            "Resetted: episode 129; Index 1944 over the limit (1944)\n",
            "2 TEST:  acc: 0.5164835164835165 cov: 0.6319444444444444 rew: -0.06368453548487052\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e7a8cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e7a8cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e4aee60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e4aee60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1239; Index 17389 over the limit (17389)\n",
            "0 TRAIN:  acc: 0.520997375328084 cov: 0.5291666666666667 rew: -0.152160036678407\n",
            "Resetted: episode 128; Index 1915 over the limit (1915)\n",
            "0 VALID:  acc: 0.546875 cov: 0.4444444444444444 rew: 0.04953603147575822\n",
            "Resetted: episode 123; Index 1842 over the limit (1842)\n",
            "0 TEST:  acc: 0.47540983606557374 cov: 0.4236111111111111 rew: -0.12634588051707332\n",
            " \n",
            "Resetted: episode 1239; Index 17389 over the limit (17389)\n",
            "1 TRAIN:  acc: 0.5961038961038961 cov: 0.5347222222222222 rew: 1.6792071991861304\n",
            "Resetted: episode 128; Index 1915 over the limit (1915)\n",
            "1 VALID:  acc: 0.5405405405405406 cov: 0.5138888888888888 rew: 0.22958159786221335\n",
            "Resetted: episode 123; Index 1842 over the limit (1842)\n",
            "1 TEST:  acc: 0.48 cov: 0.5208333333333334 rew: 0.00024095960104380566\n",
            " \n",
            "Resetted: episode 1239; Index 17389 over the limit (17389)\n",
            "2 TRAIN:  acc: 0.6189889025893958 cov: 0.5631944444444444 rew: 2.2384153602774366\n",
            "Resetted: episode 128; Index 1915 over the limit (1915)\n",
            "2 VALID:  acc: 0.5 cov: 0.5694444444444444 rew: 0.13594903971229305\n",
            "Resetted: episode 123; Index 1842 over the limit (1842)\n",
            "2 TEST:  acc: 0.4835164835164835 cov: 0.6319444444444444 rew: 0.003014871830463689\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e4aed40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e4aed40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e1a8ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e1a8ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1243; Index 17823 over the limit (17823)\n",
            "0 TRAIN:  acc: 0.5310435931307794 cov: 0.5256944444444445 rew: 0.20657773505269975\n",
            "Resetted: episode 122; Index 1813 over the limit (1813)\n",
            "0 VALID:  acc: 0.3898305084745763 cov: 0.4097222222222222 rew: -0.12395691517202667\n",
            "Resetted: episode 129; Index 1948 over the limit (1948)\n",
            "0 TEST:  acc: 0.5303030303030303 cov: 0.4583333333333333 rew: -0.09451740493406945\n",
            " \n",
            "Resetted: episode 1243; Index 17823 over the limit (17823)\n",
            "1 TRAIN:  acc: 0.5841708542713567 cov: 0.5527777777777778 rew: 1.7161827555287927\n",
            "Resetted: episode 122; Index 1813 over the limit (1813)\n",
            "1 VALID:  acc: 0.4588235294117647 cov: 0.5902777777777778 rew: -0.08744340498686631\n",
            "Resetted: episode 129; Index 1948 over the limit (1948)\n",
            "1 TEST:  acc: 0.4634146341463415 cov: 0.5694444444444444 rew: -0.035536931366575555\n",
            " \n",
            "Resetted: episode 1243; Index 17823 over the limit (17823)\n",
            "2 TRAIN:  acc: 0.6219239373601789 cov: 0.6208333333333333 rew: 2.8868483332544206\n",
            "Resetted: episode 122; Index 1813 over the limit (1813)\n",
            "2 VALID:  acc: 0.3707865168539326 cov: 0.6180555555555556 rew: -0.2673680977339836\n",
            "Resetted: episode 129; Index 1948 over the limit (1948)\n",
            "2 TEST:  acc: 0.5232558139534884 cov: 0.5972222222222222 rew: -0.01578163305690117\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e868ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908e868ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908de3b200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908de3b200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1243; Index 18185 over the limit (18185)\n",
            "0 TRAIN:  acc: 0.5093582887700535 cov: 0.5194444444444445 rew: -0.6858007586855067\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "0 VALID:  acc: 0.5245901639344263 cov: 0.4236111111111111 rew: 0.12976496439825444\n",
            "Resetted: episode 125; Index 1879 over the limit (1879)\n",
            "0 TEST:  acc: 0.5157894736842106 cov: 0.6597222222222222 rew: -0.026143166716833588\n",
            " \n",
            "Resetted: episode 1243; Index 18185 over the limit (18185)\n",
            "1 TRAIN:  acc: 0.6182519280205655 cov: 0.5402777777777777 rew: 1.540783880882957\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "1 VALID:  acc: 0.5454545454545454 cov: 0.3055555555555556 rew: 0.06503448098250812\n",
            "Resetted: episode 125; Index 1879 over the limit (1879)\n",
            "1 TEST:  acc: 0.47058823529411764 cov: 0.3541666666666667 rew: -0.05217099282550351\n",
            " \n",
            "Resetted: episode 1243; Index 18185 over the limit (18185)\n",
            "2 TRAIN:  acc: 0.6459143968871596 cov: 0.5354166666666667 rew: 2.641818479137906\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "2 VALID:  acc: 0.6 cov: 0.4513888888888889 rew: 0.15406970089293254\n",
            "Resetted: episode 125; Index 1879 over the limit (1879)\n",
            "2 TEST:  acc: 0.5185185185185185 cov: 0.5625 rew: 0.004991171739103656\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908de3b050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908de3b050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f9090d77f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f9090d77f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1248; Index 18586 over the limit (18586)\n",
            "0 TRAIN:  acc: 0.5135135135135135 cov: 0.6166666666666667 rew: -0.036533986891152\n",
            "Resetted: episode 124; Index 1850 over the limit (1850)\n",
            "0 VALID:  acc: 0.5151515151515151 cov: 0.4583333333333333 rew: 0.06667447743144488\n",
            "Resetted: episode 129; Index 1946 over the limit (1946)\n",
            "0 TEST:  acc: 0.5072463768115942 cov: 0.4791666666666667 rew: 0.10793353571313197\n",
            " \n",
            "Resetted: episode 1248; Index 18586 over the limit (18586)\n",
            "1 TRAIN:  acc: 0.6274752475247525 cov: 0.5611111111111111 rew: 2.4458616789002967\n",
            "Resetted: episode 124; Index 1850 over the limit (1850)\n",
            "1 VALID:  acc: 0.5066666666666667 cov: 0.5208333333333334 rew: -0.026087359107389463\n",
            "Resetted: episode 129; Index 1946 over the limit (1946)\n",
            "1 TEST:  acc: 0.46153846153846156 cov: 0.5416666666666666 rew: 0.027744529922421546\n",
            " \n",
            "Resetted: episode 1248; Index 18586 over the limit (18586)\n",
            "2 TRAIN:  acc: 0.6708428246013668 cov: 0.6097222222222223 rew: 3.567844987471546\n",
            "Resetted: episode 124; Index 1850 over the limit (1850)\n",
            "2 VALID:  acc: 0.5714285714285714 cov: 0.4375 rew: 0.0434662843834636\n",
            "Resetted: episode 129; Index 1946 over the limit (1946)\n",
            "2 TEST:  acc: 0.5212765957446809 cov: 0.6527777777777778 rew: 0.08153069076950809\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f9090d77b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f9090d77b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d823680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d823680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1250; Index 18734 over the limit (18734)\n",
            "0 TRAIN:  acc: 0.5137254901960784 cov: 0.53125 rew: 0.11786059272838384\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "0 VALID:  acc: 0.5490196078431373 cov: 0.3541666666666667 rew: 0.14474553111924826\n",
            "Resetted: episode 124; Index 1866 over the limit (1866)\n",
            "0 TEST:  acc: 0.6216216216216216 cov: 0.2569444444444444 rew: 0.02618840447711297\n",
            " \n",
            "Resetted: episode 1250; Index 18734 over the limit (18734)\n",
            "1 TRAIN:  acc: 0.6258596973865199 cov: 0.5048611111111111 rew: 2.1509593894280403\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "1 VALID:  acc: 0.5 cov: 0.4861111111111111 rew: -0.015052826321670112\n",
            "Resetted: episode 124; Index 1866 over the limit (1866)\n",
            "1 TEST:  acc: 0.5 cov: 0.5277777777777778 rew: 0.03467720192023395\n",
            " \n",
            "Resetted: episode 1250; Index 18734 over the limit (18734)\n",
            "2 TRAIN:  acc: 0.6459554513481829 cov: 0.5923611111111111 rew: 3.0561148830936467\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "2 VALID:  acc: 0.5903614457831325 cov: 0.5763888888888888 rew: 0.20329392876203556\n",
            "Resetted: episode 124; Index 1866 over the limit (1866)\n",
            "2 TEST:  acc: 0.5 cov: 0.5694444444444444 rew: 0.13086536137840388\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d823560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d823560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d57e7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d57e7a0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1253; Index 18758 over the limit (18758)\n",
            "0 TRAIN:  acc: 0.5195369030390738 cov: 0.4798611111111111 rew: 0.35684057703375355\n",
            "Resetted: episode 122; Index 1836 over the limit (1836)\n",
            "0 VALID:  acc: 0.5402298850574713 cov: 0.6041666666666666 rew: 0.022677263299450506\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "0 TEST:  acc: 0.5428571428571428 cov: 0.4861111111111111 rew: -0.12377102802010845\n",
            " \n",
            "Resetted: episode 1253; Index 18758 over the limit (18758)\n",
            "1 TRAIN:  acc: 0.6076732673267327 cov: 0.5611111111111111 rew: 2.3589535503858485\n",
            "Resetted: episode 122; Index 1836 over the limit (1836)\n",
            "1 VALID:  acc: 0.4935064935064935 cov: 0.5347222222222222 rew: 0.024664910713003526\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "1 TEST:  acc: 0.48333333333333334 cov: 0.4166666666666667 rew: -0.0977107901699979\n",
            " \n",
            "Resetted: episode 1253; Index 18758 over the limit (18758)\n",
            "2 TRAIN:  acc: 0.6782511210762332 cov: 0.6194444444444445 rew: 5.037575998793533\n",
            "Resetted: episode 122; Index 1836 over the limit (1836)\n",
            "2 VALID:  acc: 0.5368421052631579 cov: 0.6597222222222222 rew: -0.012491698245483334\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "2 TEST:  acc: 0.6129032258064516 cov: 0.6458333333333334 rew: 0.2804437544508255\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d57e680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d57e680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d27b5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d27b5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1254; Index 18758 over the limit (18758)\n",
            "0 TRAIN:  acc: 0.4928774928774929 cov: 0.4875 rew: 0.12149471920710306\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "0 VALID:  acc: 0.5254237288135594 cov: 0.4097222222222222 rew: 0.02341464299176799\n",
            "Resetted: episode 121; Index 1821 over the limit (1821)\n",
            "0 TEST:  acc: 0.5423728813559322 cov: 0.4097222222222222 rew: -0.01902825377294522\n",
            " \n",
            "Resetted: episode 1254; Index 18758 over the limit (18758)\n",
            "1 TRAIN:  acc: 0.6134020618556701 cov: 0.5388888888888889 rew: 2.6509859548057775\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "1 VALID:  acc: 0.5324675324675324 cov: 0.5347222222222222 rew: 0.0563878447188015\n",
            "Resetted: episode 121; Index 1821 over the limit (1821)\n",
            "1 TEST:  acc: 0.4943820224719101 cov: 0.6180555555555556 rew: -0.02398018707646863\n",
            " \n",
            "Resetted: episode 1254; Index 18758 over the limit (18758)\n",
            "2 TRAIN:  acc: 0.6902050113895216 cov: 0.6097222222222223 rew: 4.649632087781394\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "2 VALID:  acc: 0.5806451612903226 cov: 0.6458333333333334 rew: 0.17974028779091106\n",
            "Resetted: episode 121; Index 1821 over the limit (1821)\n",
            "2 TEST:  acc: 0.5353535353535354 cov: 0.6875 rew: 0.03166342220043488\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d27b440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d27b440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908cfed9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908cfed9e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1256; Index 18803 over the limit (18803)\n",
            "0 TRAIN:  acc: 0.4853146853146853 cov: 0.4965277777777778 rew: -0.0534255577061921\n",
            "Resetted: episode 119; Index 1791 over the limit (1791)\n",
            "0 VALID:  acc: 0.38636363636363635 cov: 0.3055555555555556 rew: -0.046818096783812685\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "0 TEST:  acc: 0.45714285714285713 cov: 0.24305555555555555 rew: -0.07414245809042438\n",
            " \n",
            "Resetted: episode 1256; Index 18803 over the limit (18803)\n",
            "1 TRAIN:  acc: 0.595360824742268 cov: 0.5388888888888889 rew: 3.095175381057168\n",
            "Resetted: episode 119; Index 1791 over the limit (1791)\n",
            "1 VALID:  acc: 0.5108695652173914 cov: 0.6388888888888888 rew: -0.053948628337900616\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "1 TEST:  acc: 0.51 cov: 0.6944444444444444 rew: -0.07167406047260304\n",
            " \n",
            "Resetted: episode 1256; Index 18803 over the limit (18803)\n",
            "2 TRAIN:  acc: 0.6673936750272628 cov: 0.6368055555555555 rew: 5.144914828069176\n",
            "Resetted: episode 119; Index 1791 over the limit (1791)\n",
            "2 VALID:  acc: 0.4636363636363636 cov: 0.7638888888888888 rew: -0.05782218349076183\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "2 TEST:  acc: 0.5365853658536586 cov: 0.8541666666666666 rew: 0.0026306244691514484\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908cfed830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908cfed830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908cce2950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908cce2950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1254; Index 18761 over the limit (18761)\n",
            "0 TRAIN:  acc: 0.5311258278145695 cov: 0.5243055555555556 rew: 0.7724819756338099\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "0 VALID:  acc: 0.46987951807228917 cov: 0.5763888888888888 rew: -0.04920840046549664\n",
            "Resetted: episode 121; Index 1829 over the limit (1829)\n",
            "0 TEST:  acc: 0.41975308641975306 cov: 0.5625 rew: -0.1831426623674023\n",
            " \n",
            "Resetted: episode 1254; Index 18761 over the limit (18761)\n",
            "1 TRAIN:  acc: 0.6054590570719603 cov: 0.5597222222222222 rew: 3.419068686154871\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "1 VALID:  acc: 0.4861111111111111 cov: 0.5 rew: -0.08063372325983849\n",
            "Resetted: episode 121; Index 1829 over the limit (1829)\n",
            "1 TEST:  acc: 0.40789473684210525 cov: 0.5277777777777778 rew: -0.1335135911190078\n",
            " \n",
            "Resetted: episode 1254; Index 18761 over the limit (18761)\n",
            "2 TRAIN:  acc: 0.6811428571428572 cov: 0.6076388888888888 rew: 5.778043862680298\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "2 VALID:  acc: 0.5462962962962963 cov: 0.75 rew: -0.09530898839368344\n",
            "Resetted: episode 121; Index 1829 over the limit (1829)\n",
            "2 TEST:  acc: 0.48623853211009177 cov: 0.7569444444444444 rew: 0.05496097880610293\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908cce2830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908cce2830> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908ca67d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908ca67d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1253; Index 18769 over the limit (18769)\n",
            "0 TRAIN:  acc: 0.5264452644526445 cov: 0.5645833333333333 rew: 0.5358703578599752\n",
            "Resetted: episode 119; Index 1799 over the limit (1799)\n",
            "0 VALID:  acc: 0.5081967213114754 cov: 0.4236111111111111 rew: -0.016796331348254624\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "0 TEST:  acc: 0.6 cov: 0.2777777777777778 rew: 0.046014427274029455\n",
            " \n",
            "Resetted: episode 1253; Index 18769 over the limit (18769)\n",
            "1 TRAIN:  acc: 0.6477132262051916 cov: 0.5618055555555556 rew: 3.6417002776085265\n",
            "Resetted: episode 119; Index 1799 over the limit (1799)\n",
            "1 VALID:  acc: 0.5257731958762887 cov: 0.6736111111111112 rew: 0.09469611378631075\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "1 TEST:  acc: 0.5698924731182796 cov: 0.6458333333333334 rew: 0.03194857396097056\n",
            " \n",
            "Resetted: episode 1253; Index 18769 over the limit (18769)\n",
            "2 TRAIN:  acc: 0.6918976545842217 cov: 0.6513888888888889 rew: 5.107033491066739\n",
            "Resetted: episode 119; Index 1799 over the limit (1799)\n",
            "2 VALID:  acc: 0.48623853211009177 cov: 0.7569444444444444 rew: -0.08464865895669678\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "2 TEST:  acc: 0.5818181818181818 cov: 0.7638888888888888 rew: -0.032914807961489136\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908ca67c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908ca67c20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c752e60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c752e60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1254; Index 18778 over the limit (18778)\n",
            "0 TRAIN:  acc: 0.5247641509433962 cov: 0.5888888888888889 rew: 0.9026351876495678\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "0 VALID:  acc: 0.46534653465346537 cov: 0.7013888888888888 rew: -0.001755284015331514\n",
            "Resetted: episode 121; Index 1828 over the limit (1828)\n",
            "0 TEST:  acc: 0.5238095238095238 cov: 0.5833333333333334 rew: 0.03422005241427701\n",
            " \n",
            "Resetted: episode 1254; Index 18778 over the limit (18778)\n",
            "1 TRAIN:  acc: 0.6167664670658682 cov: 0.5798611111111112 rew: 2.6636072751508024\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "1 VALID:  acc: 0.4842105263157895 cov: 0.6597222222222222 rew: -0.01265761157275328\n",
            "Resetted: episode 121; Index 1828 over the limit (1828)\n",
            "1 TEST:  acc: 0.4457831325301205 cov: 0.5763888888888888 rew: -0.005154367288718438\n",
            " \n",
            "Resetted: episode 1254; Index 18778 over the limit (18778)\n",
            "2 TRAIN:  acc: 0.6814159292035398 cov: 0.6277777777777778 rew: 4.634405293748962\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "2 VALID:  acc: 0.4270833333333333 cov: 0.6666666666666666 rew: -0.05673131293362339\n",
            "Resetted: episode 121; Index 1828 over the limit (1828)\n",
            "2 TEST:  acc: 0.47674418604651164 cov: 0.5972222222222222 rew: -0.03493314536751134\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c752d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c752d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c498cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c498cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1253; Index 18767 over the limit (18767)\n",
            "0 TRAIN:  acc: 0.48753462603878117 cov: 0.5013888888888889 rew: 0.0809750016124729\n",
            "Resetted: episode 118; Index 1783 over the limit (1783)\n",
            "0 VALID:  acc: 0.5531914893617021 cov: 0.3263888888888889 rew: 0.03498672624482229\n",
            "Resetted: episode 128; Index 1932 over the limit (1932)\n",
            "0 TEST:  acc: 0.6379310344827587 cov: 0.4027777777777778 rew: 0.07154949915618439\n",
            " \n",
            "Resetted: episode 1253; Index 18767 over the limit (18767)\n",
            "1 TRAIN:  acc: 0.6568501920614597 cov: 0.5423611111111111 rew: 2.59198520178167\n",
            "Resetted: episode 118; Index 1783 over the limit (1783)\n",
            "1 VALID:  acc: 0.47058823529411764 cov: 0.4722222222222222 rew: -0.003225692481006629\n",
            "Resetted: episode 128; Index 1932 over the limit (1932)\n",
            "1 TEST:  acc: 0.4158415841584158 cov: 0.7013888888888888 rew: -0.15425510901841574\n",
            " \n",
            "Resetted: episode 1253; Index 18767 over the limit (18767)\n",
            "2 TRAIN:  acc: 0.6619411123227917 cov: 0.6368055555555555 rew: 3.8362437909441343\n",
            "Resetted: episode 118; Index 1783 over the limit (1783)\n",
            "2 VALID:  acc: 0.4642857142857143 cov: 0.5833333333333334 rew: -0.015947407222591452\n",
            "Resetted: episode 128; Index 1932 over the limit (1932)\n",
            "2 TEST:  acc: 0.4421052631578947 cov: 0.6597222222222222 rew: -0.09102704364336706\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c498b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c498b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c1bd050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c1bd050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1250; Index 18737 over the limit (18737)\n",
            "0 TRAIN:  acc: 0.5214646464646465 cov: 0.55 rew: 0.2920422526730309\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "0 VALID:  acc: 0.5166666666666667 cov: 0.4166666666666667 rew: -0.027699798519698747\n",
            "Resetted: episode 122; Index 1844 over the limit (1844)\n",
            "0 TEST:  acc: 0.4444444444444444 cov: 0.4375 rew: -0.30479085475488615\n",
            " \n",
            "Resetted: episode 1250; Index 18737 over the limit (18737)\n",
            "1 TRAIN:  acc: 0.6221945137157108 cov: 0.5569444444444445 rew: 2.146316555331137\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "1 VALID:  acc: 0.5 cov: 0.5833333333333334 rew: -0.020826219725198478\n",
            "Resetted: episode 122; Index 1844 over the limit (1844)\n",
            "1 TEST:  acc: 0.3698630136986301 cov: 0.5069444444444444 rew: -0.46824008643684106\n",
            " \n",
            "Resetted: episode 1250; Index 18737 over the limit (18737)\n",
            "2 TRAIN:  acc: 0.6956521739130435 cov: 0.6229166666666667 rew: 4.229605173816143\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "2 VALID:  acc: 0.5465116279069767 cov: 0.5972222222222222 rew: -0.04562430005625392\n",
            "Resetted: episode 122; Index 1844 over the limit (1844)\n",
            "2 TEST:  acc: 0.41304347826086957 cov: 0.6388888888888888 rew: -0.4218067757368196\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c1eaf80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908c1eaf80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908bf26ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908bf26ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1250; Index 18736 over the limit (18736)\n",
            "0 TRAIN:  acc: 0.5492102065613609 cov: 0.5715277777777777 rew: 1.0808667579996298\n",
            "Resetted: episode 120; Index 1814 over the limit (1814)\n",
            "0 VALID:  acc: 0.4626865671641791 cov: 0.4652777777777778 rew: -0.23789128910973584\n",
            "Resetted: episode 128; Index 1936 over the limit (1936)\n",
            "0 TEST:  acc: 0.5595238095238095 cov: 0.5833333333333334 rew: 0.0606211858572684\n",
            " \n",
            "Resetted: episode 1250; Index 18736 over the limit (18736)\n",
            "1 TRAIN:  acc: 0.6466257668711657 cov: 0.5659722222222222 rew: 2.6272696343471202\n",
            "Resetted: episode 120; Index 1814 over the limit (1814)\n",
            "1 VALID:  acc: 0.4722222222222222 cov: 0.5 rew: -0.272328825299105\n",
            "Resetted: episode 128; Index 1936 over the limit (1936)\n",
            "1 TEST:  acc: 0.5232558139534884 cov: 0.5972222222222222 rew: 0.06499755035778831\n",
            " \n",
            "Resetted: episode 1250; Index 18736 over the limit (18736)\n",
            "2 TRAIN:  acc: 0.6928879310344828 cov: 0.6444444444444445 rew: 4.782773164626475\n",
            "Resetted: episode 120; Index 1814 over the limit (1814)\n",
            "2 VALID:  acc: 0.49038461538461536 cov: 0.7222222222222222 rew: -0.18165979361754936\n",
            "Resetted: episode 128; Index 1936 over the limit (1936)\n",
            "2 TEST:  acc: 0.5203252032520326 cov: 0.8541666666666666 rew: 0.034743583188913255\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908bf26dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908bf26dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908bbe5320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908bbe5320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1247; Index 18699 over the limit (18699)\n",
            "0 TRAIN:  acc: 0.5405405405405406 cov: 0.5909722222222222 rew: 0.7545835194774785\n",
            "Resetted: episode 126; Index 1906 over the limit (1906)\n",
            "0 VALID:  acc: 0.5949367088607594 cov: 0.5486111111111112 rew: 0.11182808099587836\n",
            "Resetted: episode 125; Index 1889 over the limit (1889)\n",
            "0 TEST:  acc: 0.4948453608247423 cov: 0.6736111111111112 rew: 0.05801908083271211\n",
            " \n",
            "Resetted: episode 1247; Index 18699 over the limit (18699)\n",
            "1 TRAIN:  acc: 0.6804374240583232 cov: 0.5715277777777777 rew: 3.8174154514398966\n",
            "Resetted: episode 126; Index 1906 over the limit (1906)\n",
            "1 VALID:  acc: 0.5632183908045977 cov: 0.6041666666666666 rew: 0.144013480938252\n",
            "Resetted: episode 125; Index 1889 over the limit (1889)\n",
            "1 TEST:  acc: 0.56 cov: 0.6944444444444444 rew: 0.14819516702233207\n",
            " \n",
            "Resetted: episode 1247; Index 18699 over the limit (18699)\n",
            "2 TRAIN:  acc: 0.7260428410372041 cov: 0.6159722222222223 rew: 5.350774008419043\n",
            "Resetted: episode 126; Index 1906 over the limit (1906)\n",
            "2 VALID:  acc: 0.6551724137931034 cov: 0.4027777777777778 rew: 0.19998395824494594\n",
            "Resetted: episode 125; Index 1889 over the limit (1889)\n",
            "2 TEST:  acc: 0.5774647887323944 cov: 0.4930555555555556 rew: 0.13419435671917654\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908bbe5200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908bbe5200> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d769f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d769f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1246; Index 18688 over the limit (18688)\n",
            "0 TRAIN:  acc: 0.5397796817625459 cov: 0.5673611111111111 rew: 0.4189544421327434\n",
            "Resetted: episode 123; Index 1859 over the limit (1859)\n",
            "0 VALID:  acc: 0.5625 cov: 0.5555555555555556 rew: 0.0723575061610111\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "0 TEST:  acc: 0.6883116883116883 cov: 0.5347222222222222 rew: 0.13232644171664237\n",
            " \n",
            "Resetted: episode 1246; Index 18688 over the limit (18688)\n",
            "1 TRAIN:  acc: 0.6402366863905326 cov: 0.5868055555555556 rew: 2.28159074592487\n",
            "Resetted: episode 123; Index 1859 over the limit (1859)\n",
            "1 VALID:  acc: 0.55 cov: 0.6944444444444444 rew: 0.02633182157822389\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "1 TEST:  acc: 0.42857142857142855 cov: 0.6805555555555556 rew: -0.06774345650431525\n",
            " \n",
            "Resetted: episode 1246; Index 18688 over the limit (18688)\n",
            "2 TRAIN:  acc: 0.7072905331882481 cov: 0.6381944444444444 rew: 3.7737771018208655\n",
            "Resetted: episode 123; Index 1859 over the limit (1859)\n",
            "2 VALID:  acc: 0.5106382978723404 cov: 0.6527777777777778 rew: 0.12079475215445722\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "2 TEST:  acc: 0.46511627906976744 cov: 0.5972222222222222 rew: -0.018210450158597884\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d769ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908d769ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908b67b560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908b67b560> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1247; Index 18711 over the limit (18711)\n",
            "0 TRAIN:  acc: 0.515970515970516 cov: 0.5652777777777778 rew: 0.19859600572841044\n",
            "Resetted: episode 124; Index 1874 over the limit (1874)\n",
            "0 VALID:  acc: 0.4897959183673469 cov: 0.6805555555555556 rew: 0.1084242000171731\n",
            "Resetted: episode 123; Index 1854 over the limit (1854)\n",
            "0 TEST:  acc: 0.4523809523809524 cov: 0.5833333333333334 rew: 0.05368571447205622\n",
            " \n",
            "Resetted: episode 1247; Index 18711 over the limit (18711)\n",
            "1 TRAIN:  acc: 0.6551724137931034 cov: 0.5638888888888889 rew: 2.4027749166360777\n",
            "Resetted: episode 124; Index 1874 over the limit (1874)\n",
            "1 VALID:  acc: 0.4574468085106383 cov: 0.6527777777777778 rew: 0.030482805574675913\n",
            "Resetted: episode 123; Index 1854 over the limit (1854)\n",
            "1 TEST:  acc: 0.5357142857142857 cov: 0.5833333333333334 rew: 0.08035762054312875\n",
            " \n",
            "Resetted: episode 1247; Index 18711 over the limit (18711)\n",
            "2 TRAIN:  acc: 0.6966551326412919 cov: 0.6020833333333333 rew: 3.2583316948257783\n",
            "Resetted: episode 124; Index 1874 over the limit (1874)\n",
            "2 VALID:  acc: 0.4411764705882353 cov: 0.4722222222222222 rew: 0.0035449579014633363\n",
            "Resetted: episode 123; Index 1854 over the limit (1854)\n",
            "2 TEST:  acc: 0.5714285714285714 cov: 0.5347222222222222 rew: 0.04691688759293568\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908b67b440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908b67b440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908b3b8680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f908b3b8680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1244; Index 18666 over the limit (18666)\n",
            "0 TRAIN:  acc: 0.5550239234449761 cov: 0.5805555555555556 rew: 0.6900008012771004\n",
            "Resetted: episode 120; Index 1809 over the limit (1809)\n",
            "0 VALID:  acc: 0.5862068965517241 cov: 0.4027777777777778 rew: 0.13680651465783197\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "0 TEST:  acc: 0.44776119402985076 cov: 0.4652777777777778 rew: -0.046610405282400305\n",
            " \n",
            "Resetted: episode 1244; Index 18666 over the limit (18666)\n",
            "1 TRAIN:  acc: 0.6387878787878788 cov: 0.5729166666666666 rew: 2.3328622724890677\n",
            "Resetted: episode 120; Index 1809 over the limit (1809)\n",
            "1 VALID:  acc: 0.5185185185185185 cov: 0.75 rew: 0.06559641080474116\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "1 TEST:  acc: 0.425531914893617 cov: 0.6527777777777778 rew: -0.08442872704096806\n",
            " \n",
            "Resetted: episode 1244; Index 18666 over the limit (18666)\n",
            "2 TRAIN:  acc: 0.6879120879120879 cov: 0.6319444444444444 rew: 3.305017445699505\n",
            "Resetted: episode 120; Index 1809 over the limit (1809)\n",
            "2 VALID:  acc: 0.5862068965517241 cov: 0.8055555555555556 rew: 0.21891156905146333\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "2 TEST:  acc: 0.4491525423728814 cov: 0.8194444444444444 rew: 0.034925246267797236\n",
            " \n",
            "END\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "main.py\n",
        "'''\n",
        "#os library is used to define the GPU to be used by the code, needed only in cerain situations (Better not to use it, use only if the main gpu is Busy)\n",
        "#import os\n",
        "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";\n",
        "\n",
        "#This is the class call for the Agent which will perform the experiment\n",
        "# from deepQTrading import DeepQTrading\n",
        "\n",
        "#Date library to manipulate time in the source code\n",
        "import datetime\n",
        "\n",
        "#Keras library to define the NN to be used\n",
        "from keras.models import Sequential\n",
        "\n",
        "#Layers used in the NN considered\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "\n",
        "#Activation Layers used in the source code\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU, ReLU\n",
        "\n",
        "#Optimizer used in the NN\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#Libraries used for the Agent considered\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "\n",
        "\n",
        "#Library used for showing the exception in the case of error \n",
        "import sys\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from keras.backend.tensorflow_backend import set_session\n",
        "#config = tf.ConfigProto()\n",
        "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "#set_session(tf.Session(config=config))\n",
        "\n",
        "\n",
        "\n",
        "#Let's capture the starting time and send it to the destination in order to tell that the experiment started \n",
        "startingTime=datetime.datetime.now()\n",
        "\n",
        "#There are three actions possible in the stock market\n",
        "#Hold(id 0): do nothing.\n",
        "#Long(id 1): It predicts that the stock market value will raise at the end of the day. \n",
        "#So, the action performed in this case is buying at the beginning of the day and sell it at the end of the day (aka long).\n",
        "#Short(id 2): It predicts that the stock market value will decrease at the end of the day.\n",
        "#So, the action that must be done is selling at the beginning of the day and buy it at the end of the day (aka short). \n",
        "\n",
        "nb_actions = 3\n",
        "isOnlyShort = 0\n",
        "ensembleFolderName = \"ensembleFolder\"\n",
        "\n",
        "#This is a simple NN considered. It is composed of:\n",
        "#One flatten layer to get 68 dimensional vectors as input\n",
        "#One dense layer with 35 neurons and LeakyRelu activation\n",
        "#One final Dense Layer with the 3 actions considered\n",
        "#the input is 20 observation days from the past, 8 observations from the past week and \n",
        "#40 observations from the past hours\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1,1,68)))\n",
        "model.add(Dense(35,activation='linear'))\n",
        "model.add(LeakyReLU(alpha=.001))\n",
        "model.add(Dense(nb_actions))\n",
        "model.add(Activation('linear'))\n",
        "\n",
        "\n",
        "#Define the DeepQTrading class with the following parameters:\n",
        "#explorations: 0.2 operations are random, and 100 epochs.\n",
        "#in this case, epochs parameter is used because the Agent acts on daily basis, so its better to repeat the experiments several\n",
        "#times so, its defined that each epoch will work on the data from training, validation and testing.\n",
        "#trainSize: the size of the train data gotten from the dataset, we are setting 5 stock market years, or 1800 days\n",
        "#validationSize: the size of the validation data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "#testSize: the size of the testing data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "#outputFile: where the results will be written\n",
        "#begin: where the walks will start from. We are defining January 1st of 2010\n",
        "#end: where the walks will finish. We are defining February 22nd of 2019\n",
        "#nOutput:number of walks\n",
        "dqt = DeepQTrading(\n",
        "    model=model,\n",
        "    explorations=[(0.2, 3)],\n",
        "    trainSize=datetime.timedelta(days=360*5),\n",
        "    validationSize=datetime.timedelta(days=30*6),\n",
        "    testSize=datetime.timedelta(days=30*6),\n",
        "    outputFile=\"Output/csv/walks/walks\",\n",
        "    begin=datetime.datetime(2001,1,1,0,0,0,0),\n",
        "    end=datetime.datetime(2019,2,28,0,0,0,0),\n",
        "    nbActions=nb_actions,\n",
        "    isOnlyShort=isOnlyShort,\n",
        "    ensembleFolderName=ensembleFolderName\n",
        "    )\n",
        "\n",
        "dqt.run()\n",
        "\n",
        "dqt.end()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble"
      ],
      "metadata": {
        "id": "2wj4ga3jyjiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ensemble"
      ],
      "metadata": {
        "id": "UPhKn84a0m2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ensemble.py\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "def full_ensemble(df):\n",
        "    m1 = df.eq(1).all(axis=1)\n",
        "    m2 = df.eq(2).all(axis=1)\n",
        "    local_df = df.copy()\n",
        "    local_df['ensemble'] = np.select([m1, m2], [1, 2], 0)\n",
        "    local_df = local_df.drop(local_df.columns.difference(['ensemble']), axis=1)\n",
        "    return local_df\n",
        "\n",
        "\n",
        "def perc_ensemble(df, thr = 0.7):\n",
        "    c1 = (df.eq(1).sum(1) / df.shape[1]).gt(thr)\n",
        "    c2 = (df.eq(2).sum(1) / df.shape[1]).gt(thr)\n",
        "    return pd.DataFrame(np.select([c1, c2], [1, 2], 0), index=df.index, columns=['ensemble'])\n",
        "\n",
        "\n",
        "def ensemble(numWalks, perc, type, numDel):\n",
        "    dollSum=0\n",
        "    rewSum=0\n",
        "    posSum=0\n",
        "    negSum=0\n",
        "    covSum=0\n",
        "    numSum=0\n",
        "\n",
        "    values=[]\n",
        "    # output=open(\"daxValidDel9th60.csv\",\"w+\")\n",
        "    # output.write(\"Iteration,Reward%,#Wins,#Losses,Euro,Coverage,Accuracy\\n\")\n",
        "    columns = [\"Iteration\",\"Reward%\",\"#Wins\",\"#Losses\",\"Dollars\",\"Coverage\",\"Accuracy\"]\n",
        "    dax=pd.read_csv(\"datasets/sp500Day.csv\",index_col='Date')\n",
        "    for j in range(0, numWalks):\n",
        "\n",
        "        df=pd.read_csv(\"Output/ensemble/ensembleFolder/walk\"+str(j)+\"ensemble_\"+type+\".csv\",index_col='Date')\n",
        "\n",
        "        for deleted in range(1, numDel):\n",
        "            del df['iteration'+str(deleted)]\n",
        "        \n",
        "        if perc==0:\n",
        "            df=full_ensemble(df)\n",
        "        else:\n",
        "            df=perc_ensemble(df,perc)\n",
        "\n",
        "        num=0\n",
        "        rew=0\n",
        "        pos=0\n",
        "        neg=0\n",
        "        doll=0\n",
        "        cov=0\n",
        "        for date, i in df.iterrows():\n",
        "            num+=1\n",
        "\n",
        "            if date in dax.index:\n",
        "                if (i['ensemble']==1):\n",
        "                    pos+= 1 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                    \n",
        "                    neg+= 0 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                    rew+=(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                    doll+=(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "                    cov+=1\n",
        "                elif (i['ensemble']==2):\n",
        "                    \n",
        "                    neg+= 0 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                    pos+= 1 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                    rew+=-(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                    cov+=1\n",
        "                    doll+=-(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "        \n",
        "        values.append([str(round(j,2)),str(round(rew,2)),str(round(pos,2)),str(round(neg,2)),str(round(doll,2)),str(round(cov/num,2)),(str(round(pos/cov,2)) if (cov>0) else \"\")])\n",
        "        \n",
        "        dollSum+=doll\n",
        "        rewSum+=rew\n",
        "        posSum+=pos\n",
        "        negSum+=neg\n",
        "        covSum+=cov\n",
        "        numSum+=num\n",
        "\n",
        "\n",
        "    values.append([\"sum\",str(round(rewSum,2)),str(round(posSum,2)),str(round(negSum,2)),str(round(dollSum,2)),str(round(covSum/numSum,2)),(str(round(posSum/covSum,2)) if (covSum>0) else \"\")])\n",
        "    return values, columns\n",
        "\n",
        "\n",
        "def evaluate(csvname=\"\"):\n",
        "    \n",
        "    output=open(\"resultsSPFinal.csv\",\"w+\")\n",
        "    output.write(\"Iteration,Reward%,#Wins,#Losses,Euro,Coverage,Accuracy\\n\")\n",
        "    df=pd.read_csv(csvname)\n",
        "    dax=pd.read_csv(\"datasets/sp500Day.csv\",index_col='Date')\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df['date'] = df['date'].dt.strftime('%m/%d/%Y')\n",
        "    df.set_index('date', inplace=True)\n",
        "    print(df)\n",
        "    num=0\n",
        "    rew=0\n",
        "    pos=0\n",
        "    neg=0\n",
        "    doll=0\n",
        "    cov=0\n",
        "    for date, i in df.iterrows():\n",
        "        num+=1\n",
        "\n",
        "        if date in dax.index:\n",
        "            if (i['ensemble']==1):\n",
        "                pos+= 1 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                \n",
        "                neg+= 0 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                rew+=(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                doll+=(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "                cov+=1\n",
        "            elif (i['ensemble']==-1):\n",
        "                \n",
        "                neg+= 0 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                pos+= 1 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                rew+=-(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                cov+=1\n",
        "                doll+=-(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "    \n",
        "    output.write(str(0)+ \",\" + str(round(rew,2))+ \",\" + str(round(pos,2))+ \",\" + str(round(neg,2))+ \",\" + str(round(doll,2))+ \",\" + str(round(cov/num,2))+ \",\" +(str(round(pos/cov,2)) if (cov>0) else \"\") + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "output_dataset = ensemble(numWalks=25, perc=0, type=\"valid\", numDel=2)\n",
        "output_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E5pWH7rykvW",
        "outputId": "3556df25-5010-47f5-96f8-4ade598d6a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['0', '-0.05', '5', '24', '-3250.0', '0.24', '0.17'],\n",
              "  ['1', '0.02', '19', '14', '1125.0', '0.26', '0.58'],\n",
              "  ['2', '-0.01', '21', '22', '-425.0', '0.35', '0.49'],\n",
              "  ['3', '-0.03', '19', '19', '-2450.0', '0.29', '0.5'],\n",
              "  ['4', '-0.14', '14', '21', '-9162.5', '0.29', '0.4'],\n",
              "  ['5', '0.01', '21', '19', '1450.0', '0.31', '0.53'],\n",
              "  ['6', '-0.11', '9', '15', '-4712.5', '0.2', '0.38'],\n",
              "  ['7', '0.06', '21', '17', '3112.5', '0.29', '0.55'],\n",
              "  ['8', '-0.09', '10', '20', '-5125.0', '0.24', '0.33'],\n",
              "  ['9', '0.06', '20', '11', '3287.5', '0.24', '0.65'],\n",
              "  ['10', '-0.05', '13', '13', '-3312.5', '0.21', '0.5'],\n",
              "  ['11', '0.19', '22', '11', '11537.5', '0.26', '0.67'],\n",
              "  ['12', '-0.04', '19', '21', '-2662.5', '0.33', '0.47'],\n",
              "  ['13', '0.0', '17', '17', '462.5', '0.27', '0.5'],\n",
              "  ['14', '-0.03', '9', '17', '-1987.5', '0.22', '0.35'],\n",
              "  ['15', '-0.07', '18', '25', '-5525.0', '0.34', '0.42'],\n",
              "  ['16', '0.02', '20', '15', '1875.0', '0.29', '0.57'],\n",
              "  ['17', '0.01', '28', '25', '1175.0', '0.42', '0.53'],\n",
              "  ['18', '-0.01', '16', '11', '-1087.5', '0.23', '0.59'],\n",
              "  ['19', '0.0', '16', '15', '87.5', '0.24', '0.52'],\n",
              "  ['20', '-0.09', '17', '23', '-8787.5', '0.33', '0.42'],\n",
              "  ['21', '0.01', '15', '20', '1525.0', '0.28', '0.43'],\n",
              "  ['22', '0.02', '14', '13', '2225.0', '0.22', '0.52'],\n",
              "  ['23', '-0.0', '17', '23', '-62.5', '0.32', '0.42'],\n",
              "  ['24', '0.04', '9', '9', '5900.0', '0.15', '0.5'],\n",
              "  ['sum', '-0.26', '409', '440', '-14787.5', '0.27', '0.48']],\n",
              " ['Iteration',\n",
              "  'Reward%',\n",
              "  '#Wins',\n",
              "  '#Losses',\n",
              "  'Dollars',\n",
              "  'Coverage',\n",
              "  'Accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "'''\n",
        "note: If you use 'b' for the mode, you will get a TypeError under Python3. \n",
        "You can just use 'w' for Python 3\n",
        "'''\n",
        "\n",
        "with open(\"finalEnsembleSP500.csv\",'w') as out:\n",
        "    csv_out=csv.writer(out)\n",
        "    csv_out.writerow(['Iteration', 'Reward%', '#Wins', '#Losses', 'Dollars', \n",
        "                      'Coverage', 'Accuracy'])\n",
        "    for row in output_dataset:\n",
        "        csv_out.writerow(row)\n",
        "\n",
        "    # You can also do csv_out.writerows(data) instead of the for loop"
      ],
      "metadata": {
        "id": "FHrGqa9mwRuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.read_csv('finalEnsembleSP500.csv')\n",
        "x.columns"
      ],
      "metadata": {
        "id": "YQJNLqvnzv19",
        "outputId": "d899fce2-40d5-483c-f583-d1a2dd82c0f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Iteration', 'Reward%', '#Wins', '#Losses', 'Dollars', 'Coverage',\n",
              "       'Accuracy'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\"finalEnsembleSP500.csv\")\n",
        "# output_dataset = output_dataset.to_csv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "Vg52qmVF50Dk",
        "outputId": "40cf7f74-7d7a-439b-ea9e-ddf346998973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-79ddb87fda35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finalEnsembleSP500.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# output_dataset = output_dataset.to_csv()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-805c009f5037>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(csvname)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mdax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/sp500Day.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%m/%d/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## splitEnsemble"
      ],
      "metadata": {
        "id": "vqWUd5Z-0sk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "splitEnsemble.py\n",
        "'''\n",
        "\n",
        "long = [[],[]]\n",
        "short = [[],[]]\n",
        "\n",
        "longs=pd.read_csv(\"Output/results/spLong.csv\")\n",
        "shorts=pd.read_csv(\"Output/results/spShort.csv\")\n",
        "\n",
        "long[0]= longs.loc[:,\"Date\"].tolist()\n",
        "long[1]= longs.loc[:,\"ensemble\"].tolist()\n",
        "short[0] = shorts.loc[:,\"Date\"].tolist()\n",
        "short[1] = shorts.loc[:,\"ensemble\"].tolist()\n",
        "\n",
        "output = open(\"finalEnsemble.csv\", \"w+\")\n",
        "output.write(\"date,ensemble\\n\")\n",
        "\n",
        "for i in range(0,len(long[0])):\n",
        "    if(long[0][i]==short[0][i]):\n",
        "        output.write(str(long[0][i]) + \",\" + str(long[1][i]+short[1][i]) + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "TTgineAvyyRZ",
        "outputId": "c56cd039-db89-4de2-c936-07ae86ffe961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0df78ea6ed9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlongs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output/results/spLong.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mshorts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output/results/spShort.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Output/results/spLong.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n4FZrA4czCg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of deep-q-trading.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}