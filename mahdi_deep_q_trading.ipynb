{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-rabiee/Portfolio-Formation/blob/DQN/mahdi_deep_q_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_weG2085js1I"
      },
      "source": [
        "# Requirements & Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO48s139j1ux"
      },
      "outputs": [],
      "source": [
        "!pip3 install Keras\n",
        "!pip3 install keras-rl\n",
        "!pip install tensorflow==1.15\n",
        "!pip install keras\n",
        "!pip install keras-rl\n",
        "!pip install gym\n",
        "!pip install pandas\n",
        "!pip install rl\n",
        "!pip install keras-rl2\n",
        "!pip install Callbacks \n",
        "!pip install callbacks\n",
        "!pip install rl.callbacks\n",
        "!pip install tf-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive Connection"
      ],
      "metadata": {
        "id": "4pEH2djqcrQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "os.chdir('drive/My Drive/Colab Notebooks/DQN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKy9ZcaPcvD9",
        "outputId": "c8988f20-5e93-4c73-e72f-3cfe02302e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlSMQU35o0K8"
      },
      "source": [
        "# Enviroment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9vXtGVO_ddA"
      },
      "source": [
        "## MergedDataStructure"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the data structure we use to instantiate the multi-resolution feature vector. "
      ],
      "metadata": {
        "id": "MLqo8F7U_H4W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suBLM3zNo285"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "MergedDataStructure.py\n",
        "'''\n",
        "# Library used to manipulate the CSV Dataset\n",
        "# organize the dataset for the Enviroment\n",
        "import pandas\n",
        "\n",
        "# Library used to manipulate dates\n",
        "import datetime\n",
        "\n",
        "class MergedDataStructure():\n",
        "\n",
        "    def __init__(self, delta=4, filename=\"sp500Week.csv\"):\n",
        "        self.delta = delta\n",
        "\n",
        "        # Read the CSV\n",
        "        timeserie = pandas.read_csv(filename)\n",
        "        \n",
        "        # Transform each column into a list\n",
        "        Date = timeserie.loc[:, 'Date'].tolist()\n",
        "        Time = timeserie.loc[:, 'Time'].tolist()\n",
        "        Open = timeserie.loc[:, 'Open'].tolist()\n",
        "        High = timeserie.loc[:, 'High'].tolist()\n",
        "        Low = timeserie.loc[:, 'Low'].tolist()\n",
        "        Close = timeserie.loc[:, 'Close'].tolist()\n",
        "\n",
        "        # Create empty list and dictionary\n",
        "        self.list=[]\n",
        "        self.dict={}\n",
        "\n",
        "        # The limit is the number of dates\n",
        "        limit = len(Date)\n",
        "\n",
        "        # Just converting pandas data to a list\n",
        "        # lets pick up the csv data and put them in the list (self.list) \n",
        "        for i in range(0, limit-1):\n",
        "            self.list.append({'Date' : Date[i], 'Time' : Time[i], 'Open': Open[i], 'High': High[i], 'Low': Low[i], 'Close': Close[i]})\n",
        "            \n",
        "            # Fill the gaps with days that do not exist \n",
        "            dateList = [datetime.datetime.strptime(Date[i+1], \"%m/%d/%Y\") - datetime.timedelta(days=x) for x in range(0, ( datetime.datetime.strptime(Date[i+1], \"%m/%d/%Y\")- datetime.datetime.strptime(Date[i], \"%m/%d/%Y\") ).days )]\n",
        "            \n",
        "            for date in dateList:\n",
        "                dateString = date.strftime(\"%m/%d/%Y\")\n",
        "                # Contains dates and indexes for the list self.list\n",
        "                self.dict[dateString] = i\n",
        "\n",
        "    def get(self, date):\n",
        "        # Converts the date to string\n",
        "        dateString = str(date)\n",
        "        # given the date, you get an interval(delta) of past days or weeks\n",
        "        return self.list[self.dict[dateString]-(self.delta):self.dict[dateString]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weekData = MergedDataStructure(delta=3, filename='datasets/daxWeek.csv')"
      ],
      "metadata": {
        "id": "0fJqBtbkVZFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pandas.read_csv(\"datasets/daxWeek.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iwEU_zACV77f",
        "outputId": "34e02cdb-5ac3-4184-d2c0-45e6503907e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bcecc727-4512-40ee-9be1-37f624b21942\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01/10/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7793.5</td>\n",
              "      <td>7815.5</td>\n",
              "      <td>7043.5</td>\n",
              "      <td>7435.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01/17/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7535.5</td>\n",
              "      <td>7931.5</td>\n",
              "      <td>7434.0</td>\n",
              "      <td>7834.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01/24/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7868.5</td>\n",
              "      <td>7943.5</td>\n",
              "      <td>7552.5</td>\n",
              "      <td>7621.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01/31/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7665.5</td>\n",
              "      <td>7850.0</td>\n",
              "      <td>7439.5</td>\n",
              "      <td>7700.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02/07/2000</td>\n",
              "      <td>00:00</td>\n",
              "      <td>7634.5</td>\n",
              "      <td>8079.5</td>\n",
              "      <td>7439.5</td>\n",
              "      <td>8008.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>02/07/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11252.5</td>\n",
              "      <td>11403.5</td>\n",
              "      <td>11013.0</td>\n",
              "      <td>11322.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>02/14/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11310.5</td>\n",
              "      <td>11316.0</td>\n",
              "      <td>10875.0</td>\n",
              "      <td>11197.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>02/21/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11200.5</td>\n",
              "      <td>11500.0</td>\n",
              "      <td>11030.0</td>\n",
              "      <td>11437.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>02/28/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11432.0</td>\n",
              "      <td>11574.0</td>\n",
              "      <td>11404.0</td>\n",
              "      <td>11505.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>03/07/2019</td>\n",
              "      <td>00:00</td>\n",
              "      <td>11515.0</td>\n",
              "      <td>11697.0</td>\n",
              "      <td>11415.5</td>\n",
              "      <td>11587.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>997 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcecc727-4512-40ee-9be1-37f624b21942')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bcecc727-4512-40ee-9be1-37f624b21942 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bcecc727-4512-40ee-9be1-37f624b21942');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Date   Time     Open     High      Low    Close\n",
              "0    01/10/2000  00:00   7793.5   7815.5   7043.5   7435.5\n",
              "1    01/17/2000  00:00   7535.5   7931.5   7434.0   7834.5\n",
              "2    01/24/2000  00:00   7868.5   7943.5   7552.5   7621.0\n",
              "3    01/31/2000  00:00   7665.5   7850.0   7439.5   7700.5\n",
              "4    02/07/2000  00:00   7634.5   8079.5   7439.5   8008.5\n",
              "..          ...    ...      ...      ...      ...      ...\n",
              "992  02/07/2019  00:00  11252.5  11403.5  11013.0  11322.0\n",
              "993  02/14/2019  00:00  11310.5  11316.0  10875.0  11197.0\n",
              "994  02/21/2019  00:00  11200.5  11500.0  11030.0  11437.0\n",
              "995  02/28/2019  00:00  11432.0  11574.0  11404.0  11505.0\n",
              "996  03/07/2019  00:00  11515.0  11697.0  11415.5  11587.0\n",
              "\n",
              "[997 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weekData.get(\"12/27/2018\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWRf1G7sJvuh",
        "outputId": "872405aa-3eef-4c8b-8ca8-60882d920953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Close': 11412.5,\n",
              "  'Date': '11/29/2018',\n",
              "  'High': 11449.0,\n",
              "  'Low': 11096.0,\n",
              "  'Open': 11258.5,\n",
              "  'Time': '00:00'},\n",
              " {'Close': 11201.0,\n",
              "  'Date': '12/06/2018',\n",
              "  'High': 11575.5,\n",
              "  'Low': 10764.0,\n",
              "  'Open': 11401.0,\n",
              "  'Time': '00:00'},\n",
              " {'Close': 10935.5,\n",
              "  'Date': '12/13/2018',\n",
              "  'High': 11097.5,\n",
              "  'Low': 10590.5,\n",
              "  'Open': 11048.0,\n",
              "  'Time': '00:00'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kv-fhwc_grp"
      },
      "source": [
        "## Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a module used to log and trace the results."
      ],
      "metadata": {
        "id": "agjS4IwlCnz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVfzIUkPpQh6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Callback.py\n",
        "'''\n",
        "\n",
        "# Callbacks are functions used to give a feedback about each epoch calculated metrics\n",
        "from rl.callbacks import Callback\n",
        "\n",
        "class ValidationCallback(Callback):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initially, the metrics are zero\n",
        "        # actions: hold:0, long:1, short:2\n",
        "        self.episodes = 0 # number of episode\n",
        "        self.rewardSum = 0 # sum of the rewards \n",
        "        self.accuracy = 0 # increments if the action is not hold and the reward is positive\n",
        "        self.coverage = 0 # increments if the action is not hold \n",
        "        self.short = 0 # increments if the action is short\n",
        "        self.long = 0 # increments if the action is long\n",
        "        self.shortAcc = 0 # increments if the action is short and the reward is positive\n",
        "        self.longAcc = 0 # increments if the action is long and the reward is positive\n",
        "        self.longPrec = 0 # increments if the market rises and the action is long\n",
        "        self.shortPrec = 0 # increments if the market falls and the action is short\n",
        "        self.marketRise = 0 # increments if the market rises\n",
        "        self.marketFall = 0 # increments if the market falls\n",
        "\n",
        "    def reset(self):\n",
        "        # The metrics are also zero when the epoch ends\n",
        "        self.episodes = 0 \n",
        "        self.rewardSum = 0 \n",
        "        self.accuracy = 0\n",
        "        self.coverage = 0\n",
        "        self.short = 0\n",
        "        self.long = 0\n",
        "        self.shortAcc = 0\n",
        "        self.longAcc = 0\n",
        "        self.longPrec = 0\n",
        "        self.shortPrec = 0\n",
        "        self.marketRise = 0\n",
        "        self.marketFall = 0\n",
        "        \n",
        "    # all information is given by the environment: action, reward and market\n",
        "    # Then, when the episode ends, metrics are calculated\n",
        "    def on_episode_end(self, action, reward, market): # market = reward - transaction cost\n",
        "        \n",
        "        # After the episode ends, increments the episodes \n",
        "        self.episodes+=1\n",
        "\n",
        "        # Increments the reward\n",
        "        self.rewardSum+=reward\n",
        "\n",
        "        # If the action is not a hold, there is coverage because the agent decided \n",
        "        self.coverage+=1 if (action != 0) else 0\n",
        "\n",
        "        # increments the accuracy if the reward is positive (we have a hit)\n",
        "        self.accuracy+=1 if (reward >= 0 and action != 0) else 0\n",
        "        \n",
        "        # Increments the counter for short if the action is a short (id 2)\n",
        "        self.short +=1 if(action == 2) else 0\n",
        "        \n",
        "        # Increments the counter for long if the action is a long (id 1)\n",
        "        self.long +=1 if(action == 1) else 0\n",
        "        \n",
        "        # We will also calculate the accuracy for a given action. Here, it increments\n",
        "        # the accuracy for short if the action is short and the reward is positive\n",
        "        self.shortAcc +=1 if(action == 2 and reward >=0) else 0\n",
        "        \n",
        "        # Increments the accuracy for long if the action is long and the reward is positive\n",
        "        self.longAcc +=1 if(action == 1 and reward >=0) else 0\n",
        "        \n",
        "        # If the market increases, increments the marketRise variable. If the prediction is 1 (long), increments the precision for long\n",
        "        if(market > 0): # market = close - open\n",
        "            self.marketRise+=1\n",
        "            self.longPrec+=1 if(action == 1) else 0\n",
        "\n",
        "        # If market decreases, increments the marketFall. If the prediction is 2 (short), increments the precision for short   \n",
        "        elif(market < 0):\n",
        "            self.marketFall+=1\n",
        "            self.shortPrec+=1 if(action == 2) else 0\n",
        "\n",
        "    # Function to show the metrics of the episode  \n",
        "    def getInfo(self):\n",
        "        # Start setting them to zero\n",
        "        acc = 0\n",
        "        cov = 0\n",
        "        short = 0\n",
        "        long = 0\n",
        "        longAcc = 0\n",
        "        shortAcc = 0\n",
        "        longPrec = 0\n",
        "        shortPrec = 0\n",
        "        \n",
        "        # If there is coverage, we will calculate the accuracy only related to when decisions were made. \n",
        "        # In other words, we dont calculate accuracy for hold operations\n",
        "        if self.coverage > 0:\n",
        "            acc = self.accuracy / self.coverage\n",
        "        \n",
        "        # Now, we calculate the mean coverage, short and long operations from the episodes\n",
        "        if self.episodes > 0:\n",
        "            cov = self.coverage / self.episodes\n",
        "            short = self.short / self.episodes\n",
        "            long = self.long / self.episodes\n",
        "\n",
        "        # Calculate the mean accuracy for short operations. \n",
        "        # That is, the number of total short correctly predicted (self.shortAcc) \n",
        "        # divided by the total of shorts predicted (self.short)\n",
        "        if self.short > 0:\n",
        "            shortAcc = self.shortAcc / self.short\n",
        "        \n",
        "        # Calculate the mean accuracy for long operations. \n",
        "        # That is, the number of total short correctly predicted (long.shortAcc) \n",
        "        # divided by the total of longs predicted (long.short) \n",
        "        if self.long > 0:\n",
        "            longAcc = self.longAcc / self.long\n",
        "\n",
        "        if self.marketRise > 0:\n",
        "            longPrec = self.longPrec / self.marketRise\n",
        "\n",
        "        if self.marketFall > 0:\n",
        "            shortPrec = self.shortPrec / self.marketFall\n",
        "\n",
        "        # Returns the metrics to the user    \n",
        "        return self.episodes, cov, acc, self.rewardSum, long, short, longAcc, shortAcc, longPrec, shortPrec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwYvhtPN_ldD"
      },
      "source": [
        "## spEnv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMHIYTs3rsJG"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "spEnv.py\n",
        "'''\n",
        "# Environment used for spenv \n",
        "# gym is the library of videogames used by reinforcement learning\n",
        "import gym\n",
        "from gym import spaces\n",
        "# Numpy is the library to deal with matrices\n",
        "import numpy\n",
        "# Pandas is the library used to deal with the CSV dataset\n",
        "import pandas\n",
        "# datetime is the library used to manipulate time and date\n",
        "from datetime import datetime\n",
        "\n",
        "# This is the prefix of the files that will be opened. It is related to the s&p500 stock market datasets\n",
        "MK = \"dax\"\n",
        "\n",
        "\n",
        "class SpEnv(gym.Env):\n",
        "    # Just for the gym library. In a continuous environment, you can do infinite decisions. \n",
        "    # We dont want this because we have just three possible actions.\n",
        "    continuous = False\n",
        "\n",
        "    # Observation window is the time window regarding the \"hourly\" dataset \n",
        "    # ensemble variable tells to save or not the decisions at each walk\n",
        "    def __init__(self, minLimit=None, maxLimit=None, operationCost=0, observationWindow=40, ensamble=None, callback=None, isOnlyShort=False, columnName=\"iteration-1\"):\n",
        "        # Declare the episode as the first episode\n",
        "        self.episode = 1\n",
        "\n",
        "        self.isOnlyShort = isOnlyShort\n",
        "        \n",
        "        # Open the time series as the hourly dataset of S&P500\n",
        "        # the input feature vector is composed of data from hours, weeks and days\n",
        "        # 20 from days, 8 from weeks and 40 hours, ending with 68 dimensional feature vectors\n",
        "        hourData = pandas.read_csv('datasets/'+MK+'Hour.csv')[minLimit:maxLimit] # opening the dataset\n",
        "        \n",
        "        # Converts each column to a list\n",
        "        Date = hourData.loc[:, 'Date'].tolist()\n",
        "        Time = hourData.loc[:, 'Time'].tolist()\n",
        "        Open = hourData.loc[:, 'Open'].tolist()\n",
        "        High = hourData.loc[:, 'High'].tolist()\n",
        "        Low = hourData.loc[:, 'Low'].tolist()\n",
        "        Close = hourData.loc[:, 'Close'].tolist()\n",
        "        \n",
        "        # Open the weekly and daily data as a merged data structure\n",
        "        # Get 20 dimensional vectors (close-open) considering 20 past days and 8 dimensional vectors (close-open) \n",
        "        # considering 8 weeks\n",
        "        self.weekData = MergedDataStructure(delta=8, filename='datasets/'+MK+\"Week.csv\")# this DS allows me to obtain previous historical data with different resolution\n",
        "        self.dayData = MergedDataStructure(delta=20, filename='datasets/'+MK+\"Day.csv\")#  with low computational complexity\n",
        "        \n",
        "        # Load the data\n",
        "        self.output = False # it will be True if we decide to save the decisions in each epoch & date or self.ensamble is not None\n",
        "\n",
        "        # ensamble is the table of validation and testing\n",
        "        # If it is none, you will not save csvs of validation and testing    \n",
        "        if(ensamble is not None): # managing the ensamble output (maybe in the wrong way)\n",
        "            self.output = True\n",
        "            self.ensamble = ensamble\n",
        "            self.columnName = columnName\n",
        "            # self.ensemble is a big table (before file writing) containing observations as lines and epochs as columns\n",
        "            # each column will contain a decision for each epoch at each date. It is saved later.\n",
        "            # We read this table later in order to make ensemble decisions at each epoch\n",
        "            self.ensamble[self.columnName] = 0\n",
        "\n",
        "        # Declare low and high as vectors with -inf values \n",
        "        # low and high are the minimun and maximum accepted values in feature vector\n",
        "        self.low = numpy.array([-numpy.inf])\n",
        "        self.high = numpy.array([+numpy.inf])\n",
        "\n",
        "        # Define the space of actions as 3\n",
        "        # the action space is just 0, 1, 2 which means hold, long, short\n",
        "        self.action_space = spaces.Discrete(3) \n",
        "        \n",
        "        # low and high are the minimun and maximum accepted values for this problem\n",
        "        # We don't know what are the minimum and maximum values of Close-Open, so we put these values\n",
        "        self.observation_space = spaces.Box(self.low, self.high, dtype=numpy.float32)\n",
        "\n",
        "        # Set observationWindow = 40 (40 hours)\n",
        "        # Observation window is the time window regarding the \"hourly\" dataset\n",
        "        self.observationWindow = observationWindow\n",
        "        \n",
        "        # Set the current observation as 40\n",
        "        self.currentObservation = observationWindow\n",
        "        # The operation cost is defined as \n",
        "        self.operationCost = operationCost\n",
        "        # Defines that the environment is not done yet\n",
        "        self.done = False\n",
        "        # The limit is the number of open values in the dataset (could be any other value): it shows the number of data\n",
        "        self.limit = len(Open)\n",
        "        # organizing the hour dataset as a list of dictionaries \n",
        "        # The history begins empty\n",
        "        self.history = []\n",
        "        for i in range(0, self.limit): \n",
        "            self.history.append({'Date' : Date[i],'Time' : Time[i], 'Open': Open[i], 'High': High[i], 'Low': Low[i], 'Close': Close[i]})\n",
        "        \n",
        "        # Next observation starts\n",
        "        self.nextObservation = 0\n",
        "        \n",
        "        # self.history contains all the hour data. Here we search for the next day \n",
        "        while(self.history[self.currentObservation]['Date']==self.history[(self.currentObservation+self.nextObservation)%self.limit]['Date']):\n",
        "            self.nextObservation += 1\n",
        "        \n",
        "        # Initiates the values to be returned by the environment\n",
        "        self.reward = None\n",
        "        self.possibleGain = 0\n",
        "        self.openValue = 0\n",
        "        self.closeValue = 0\n",
        "        self.callback = callback\n",
        "\n",
        "\n",
        "    # This is the action that is done in the environment. \n",
        "    # Receives the action and returns the state, the reward and if its done \n",
        "    def step(self, action):\n",
        "        #Initiates the reward, weeklist and daylist\n",
        "        self.reward = 0\n",
        "        \n",
        "\n",
        "        ##UNCOMMENT NEXT LINE FOR ONLY SHORT AGENT\n",
        "        if(self.isOnlyShort):\n",
        "            action *= 2   # ??????????????????\n",
        "\n",
        "\n",
        "        # Set the next observation to zero\n",
        "        self.nextObservation = 0\n",
        "        # Search for the close value for tommorow\n",
        "        while(self.history[self.currentObservation]['Date']==self.history[(self.currentObservation+self.nextObservation)%self.limit]['Date']):\n",
        "            # Search for the close error for today\n",
        "            self.closeValue = self.history[(self.currentObservation+self.nextObservation)%self.limit]['Close']\n",
        "            self.nextObservation += 1\n",
        "\n",
        "        # Get the open value for today \n",
        "        self.openValue = self.history[self.currentObservation]['Open']\n",
        "\n",
        "        '''\n",
        "        Reward\n",
        "        '''\n",
        "        # Calculate the reward in percentage of growing/decreasing\n",
        "        self.possibleGain = (self.closeValue - self.openValue) / self.openValue\n",
        "        # If action is a long, calculate the reward \n",
        "        if(action == 1):\n",
        "            # The reward must be subtracted by the cost of transaction\n",
        "            self.reward = self.possibleGain - self.operationCost\n",
        "        # If action is a short, calculate the reward     \n",
        "        elif(action==2):\n",
        "            self.reward = (-self.possibleGain)-self.operationCost\n",
        "        # If action is a hold, no reward     \n",
        "        else:\n",
        "            self.reward = 0\n",
        "\n",
        "\n",
        "        # Finish episode \n",
        "        self.done = True\n",
        "\n",
        "\n",
        "        # Call the callback for the episode\n",
        "        if(self.callback != None and self.done):\n",
        "            self.callback.on_episode_end(action, self.reward, self.possibleGain)\n",
        "        \n",
        "\n",
        "        # File of the ensamble (file containing each epoch decisions at each walk) will contain the action for that \n",
        "        # day (observation, line) at each epoch (column)\n",
        "        if(self.output):\n",
        "            self.ensamble.at[self.history[self.currentObservation]['Date'], self.columnName] = action\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Return the state, reward and if its done or not\n",
        "        return self.getObservation(self.history[self.currentObservation]['Date']), self.reward, self.done, {}\n",
        "        \n",
        "    #function done when the episode finishes\n",
        "    #reset will prepare the next state (feature vector) and give it to the agent\n",
        "    def reset(self):\n",
        "\n",
        "        if(self.currentObservation < self.observationWindow):\n",
        "            self.currentObservation = self.observationWindow\n",
        "\n",
        "\n",
        "        \n",
        "        self.episode+=1\n",
        "        \n",
        "        \n",
        "        # Shiftting the index for the first hour of the next day\n",
        "        self.nextObservation=0\n",
        "        while(self.history[self.currentObservation]['Date']==self.history[(self.currentObservation+self.nextObservation)%self.limit]['Date']):\n",
        "            self.nextObservation+=1\n",
        "            # check if the index exceeds the limits\n",
        "            if((self.currentObservation+self.nextObservation)>=self.limit):\n",
        "                print(\"Resetted: episode \" + str(self.episode) +\"; Index \" + str(self.currentObservation+self.nextObservation) + \" over the limit (\" + str(self.limit) + \")\" )\n",
        "            \n",
        "        # reset the values used in the step() function\n",
        "        self.done = False\n",
        "        self.reward = None\n",
        "        self.possibleGain = 0\n",
        "        self.openValue = 0\n",
        "        self.closeValue = 0\n",
        "\n",
        "        #Prepapre to get the next observation\n",
        "        self.currentObservation+=self.nextObservation\n",
        "        if(self.currentObservation>=self.limit):\n",
        "            self.currentObservation=self.observationWindow\n",
        "        \n",
        "        return self.getObservation(self.history[self.currentObservation]['Date'])\n",
        "\n",
        "\n",
        "    def getObservation(self, date):\n",
        "\n",
        "        # Get the daily information and week information\n",
        "        # get all the data\n",
        "        dayList = self.dayData.get(date)\n",
        "        weekList = self.weekData.get(date)\n",
        "\n",
        "        # Get the previous 40 hours regarding each date\n",
        "        currentData = self.history[self.currentObservation-self.observationWindow:self.currentObservation] \n",
        "\n",
        "        # The data is finally concatenated here. We concatenate Hours, days and weeks information\n",
        "        feature_vector = currentData + dayList + weekList\n",
        "\n",
        "        # Calculates the close minus open \n",
        "        # The percentage of growing or decreasing is calculated as CloseMinusOpen\n",
        "        # This is the input vector\n",
        "        # closeMinusOpen=list(map(lambda x: (x[\"Close\"]-x[\"Open\"])/x[\"Open\"],self.history[self.currentObservation-self.observationWindow:self.currentObservation]  + self.dayData.get(date) + self.weekData.get(date)))\n",
        "        \n",
        "        # The state is prepared by the environment, which is simply the feature vector\n",
        "        return  numpy.array([list(map(lambda x: (x[\"Close\"]-x[\"Open\"])/x[\"Open\"], feature_vector))])\n",
        "    \n",
        "    def resetEnv(self):\n",
        "        self.currentObservation = self.observationWindow\n",
        "        # Resets the episode to 1\n",
        "        self.episode = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwdGjA34GIBc"
      },
      "source": [
        "# main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56xe9An9nMDH"
      },
      "source": [
        "The code needs three positional parameters to be correctly executed: \\\\\n",
        "python main.py [numberOfActions, isOnlyShort, ensembleFolder]\n",
        "\n",
        "\n",
        "* To run the FULL agent you need to run: python main.py 3 0 ensembleFolder\n",
        "* To run the ONLY LONG agent you need to run: python main.py 2 0 ensembleFolder\n",
        "* To run the ONLY SHORT agent you need to run: python main.py 2 1 ensembleFolder \\\\\n",
        "where the paramenter ensembleFolder is used to set the name of the folder in which you'll get your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXdjyJFQzAo2"
      },
      "source": [
        "## DeepQTrading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik31bGTJxTS4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "deepQTrading.py\n",
        "'''\n",
        "# Imports the SPEnv library, which will perform the Agent actions themselves\n",
        "# from spEnv import SpEnv\n",
        "\n",
        "# Callback used to print the results at each episode\n",
        "# from callback import ValidationCallback\n",
        "\n",
        "# Keras library for the NN considered\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Keras libraries for layers, activations and optimizers used\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# RL Agent \n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "\n",
        "# Mathematical operations used later\n",
        "from math import floor\n",
        "\n",
        "# Library to manipulate the dataset in a csv file\n",
        "import pandas as pd\n",
        "\n",
        "# Library used to manipulate time\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Prefix of the name of the market (S&P500) files used to load the data\n",
        "MK=\"dax\"\n",
        "\n",
        "class DeepQTrading:\n",
        "    '''\n",
        "    Class constructor\n",
        "    model: Keras model considered\n",
        "    Explorations is a vector containing (i) probability of random predictions; (ii) how many epochs will be \n",
        "    runned by the algorithm (we run the algorithm several times-several iterations)  \n",
        "    trainSize: size of the training set\n",
        "    validationSize: size of the validation set\n",
        "    testSize: size of the testing set \n",
        "    outputFile: name of the file to print results\n",
        "    begin: Initial date\n",
        "    end: final date\n",
        "    nbActions: number of decisions (0-Hold 1-Long 2-Short) \n",
        "    nOutput is the number of walks. We are doing 5 walks.  \n",
        "    operationCost: Price for the transaction (we set they are free)\n",
        "    '''\n",
        "    def __init__(self, model, explorations, trainSize, validationSize, testSize, outputFile, begin, end, nbActions, isOnlyShort, ensembleFolderName, operationCost=0):\n",
        "        \n",
        "        self.isOnlyShort = isOnlyShort\n",
        "        self.ensembleFolderName = ensembleFolderName\n",
        "\n",
        "        # Define the policy, explorations, actions and model as received by parameters\n",
        "        self.policy = EpsGreedyQPolicy()\n",
        "        self.explorations = explorations\n",
        "        self.nbActions = nbActions\n",
        "        self.model = model\n",
        "\n",
        "        # Define the memory\n",
        "        self.memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "        # Instantiate the agent with parameters received\n",
        "        self.agent = DQNAgent(model=self.model, policy=self.policy,  nb_actions=self.nbActions, memory=self.memory, nb_steps_warmup=200, target_model_update=1e-1,\n",
        "                                    enable_double_dqn=True, enable_dueling_network=True)\n",
        "        \n",
        "        # Compile the agent with the adam optimizer and with the mean absolute error metric\n",
        "        self.agent.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "        # Save the weights of the agents in the q.weights file\n",
        "        # Save random weights\n",
        "        self.agent.save_weights(\"q.weights\", overwrite=True)\n",
        "\n",
        "        # Define the current starting point as the initial date\n",
        "        self.currentStartingPoint = begin\n",
        "\n",
        "        # Define the training, validation and testing size as informed by the call\n",
        "        # Train: 5 years\n",
        "        # Validation: 6 months\n",
        "        # Test: 6 months\n",
        "        self.trainSize = trainSize\n",
        "        self.validationSize = validationSize\n",
        "        self.testSize = testSize\n",
        "        \n",
        "        # The walk size is simply summing up the train, validation and test sizes\n",
        "        self.walkSize = trainSize + validationSize + testSize\n",
        "        \n",
        "        # Define the ending point as the final date (January 1st of 2010)\n",
        "        self.endingPoint = end\n",
        "\n",
        "        # Read the hourly dataset\n",
        "        # We join data from different files\n",
        "        # Here hour data is read \n",
        "        self.dates = pd.read_csv('datasets/'+MK+'Hour.csv')\n",
        "        self.sp = pd.read_csv('datasets/'+MK+'Hour.csv')\n",
        "        # Convert the pandas format to date and time format\n",
        "        self.sp['Datetime'] = pd.to_datetime(self.sp['Date'] + ' ' + self.sp['Time'])\n",
        "        # Set an index to Datetime on the pandas loaded dataset. Registers will be indexes through these values\n",
        "        self.sp = self.sp.set_index('Datetime')\n",
        "        # Drop Time and Date from the Dataset\n",
        "        self.sp = self.sp.drop(['Time','Date'], axis=1)\n",
        "        # Just the index considering date and time will be important, because date and time will be used to define the train, \n",
        "        # validation and test for each walk\n",
        "        self.sp = self.sp.index\n",
        "\n",
        "        # Receives the operation cost, which is 0\n",
        "        # Operation cost is the cost for long and short. It is defined as zero\n",
        "        self.operationCost = operationCost\n",
        "        \n",
        "        # Call the callback for training, validation and test in order to show results for each episode \n",
        "        self.trainer = ValidationCallback()\n",
        "        self.validator = ValidationCallback()\n",
        "        self.tester = ValidationCallback()\n",
        "        self.outputFileName = outputFile\n",
        "\n",
        "    def run(self):\n",
        "        # Initiates the environments\n",
        "        trainEnv = validEnv = testEnv = \" \"\n",
        "        iteration = -1\n",
        "\n",
        "        # While we did not pass through all the dates (i.e., while all the walks were not finished)\n",
        "        # walk size is train+validation+test size\n",
        "        # currentStarting point begins with begin date\n",
        "        while(self.currentStartingPoint + self.walkSize <= self.endingPoint):\n",
        "\n",
        "            # Iteration is the current walk\n",
        "            iteration+=1\n",
        "\n",
        "            # Initiate the output file\n",
        "            self.outputFile = open(self.outputFileName+str(iteration+1)+\".csv\", \"w+\")\n",
        "            # write the first row of the csv\n",
        "            self.outputFile.write(\n",
        "                \"Iteration,\"+\n",
        "                \"trainAccuracy,\"+\n",
        "                \"trainCoverage,\"+\n",
        "                \"trainReward,\"+\n",
        "                \"trainLong%,\"+\n",
        "                \"trainShort%,\"+\n",
        "                \"trainLongAcc,\"+\n",
        "                \"trainShortAcc,\"+\n",
        "                \"trainLongPrec,\"+\n",
        "                \"trainShortPrec,\"+\n",
        "\n",
        "                \"validationAccuracy,\"+\n",
        "                \"validationCoverage,\"+\n",
        "                \"validationReward,\"+\n",
        "                \"validationLong%,\"+\n",
        "                \"validationShort%,\"+\n",
        "                \"validationLongAcc,\"+\n",
        "                \"validationShortAcc,\"+\n",
        "                \"validLongPrec,\"+\n",
        "                \"validShortPrec,\"+\n",
        "                \n",
        "                \"testAccuracy,\"+\n",
        "                \"testCoverage,\"+\n",
        "                \"testReward,\"+\n",
        "                \"testLong%,\"+\n",
        "                \"testShort%,\"+\n",
        "                \"testLongAcc,\"+\n",
        "                \"testShortAcc,\"+\n",
        "                \"testLongPrec,\"+\n",
        "                \"testShortPrec\\n\")\n",
        "\n",
        "\n",
        "            \n",
        "            # Empty the memory and agent\n",
        "            del(self.memory)\n",
        "            del(self.agent)\n",
        "\n",
        "            # Define the memory and agent\n",
        "            # Memory is Sequential\n",
        "            self.memory = SequentialMemory(limit=10000, window_length=1)\n",
        "            # Agent is initiated as passed through parameters\n",
        "            self.agent = DQNAgent(model=self.model, policy=self.policy,  nb_actions=self.nbActions, memory=self.memory, nb_steps_warmup=200, target_model_update=1e-1,\n",
        "                                    enable_double_dqn=True,enable_dueling_network=True)\n",
        "            # Compile the agent with Adam initialization\n",
        "            self.agent.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "            \n",
        "            # Load the weights saved before in a random way if it is the first time\n",
        "            self.agent.load_weights(\"q.weights\")\n",
        "            \n",
        "            ########################################TRAINING STAGE########################################################\n",
        "            \n",
        "            # The TrainMinLimit will be loaded as the initial date at the beginning, and will be updated later.\n",
        "            # If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date    \n",
        "            trainMinLimit = None\n",
        "            while(trainMinLimit is None):\n",
        "                try:\n",
        "                    trainMinLimit = self.sp.get_loc(self.currentStartingPoint)\n",
        "                except:\n",
        "                    # datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0, 0, 0, 0, 0, 1, 0)\n",
        "\n",
        "            # The TrainMaxLimit will be loaded as the interval between the initial date plus the training size.\n",
        "            # If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date    \n",
        "            trainMaxLimit=None\n",
        "            while(trainMaxLimit is None):\n",
        "                try:\n",
        "                    trainMaxLimit = self.sp.get_loc(self.currentStartingPoint + self.trainSize)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0, 0, 0, 0, 0, 1, 0)\n",
        "            \n",
        "            ########################################VALIDATION STAGE#######################################################\n",
        "            # The ValidMinLimit will be loaded as the next element of the TrainMax limit\n",
        "            validMinLimit = trainMaxLimit+1\n",
        "\n",
        "            # The ValidMaxLimit will be loaded as the interval after the begin + train size +validation size\n",
        "            # If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date  \n",
        "            validMaxLimit = None\n",
        "            while(validMaxLimit is None):\n",
        "                try:\n",
        "                    validMaxLimit = self.sp.get_loc(self.currentStartingPoint + self.trainSize + self.validationSize)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0, 0, 0, 0, 0, 1, 0)\n",
        "\n",
        "            ########################################TESTING STAGE######################################################## \n",
        "            # The TestMinLimit will be loaded as the next element of ValidMaxlimit \n",
        "            testMinLimit = validMaxLimit+1\n",
        "\n",
        "            # The testMaxLimit will be loaded as the interval after the begin + train size +validation size + Testsize\n",
        "            # If the initial date cannot be used, add 1 hour to the initial date and consider it the initial date \n",
        "            testMaxLimit = None\n",
        "            while(testMaxLimit is None):\n",
        "                try:\n",
        "                    testMaxLimit = self.sp.get_loc(self.currentStartingPoint + self.trainSize + self.validationSize + self.testSize)\n",
        "                except:\n",
        "                    self.currentStartingPoint+=datetime.timedelta(0, 0, 0, 0, 0, 1, 0)\n",
        "\n",
        "            # Separate the Validation and testing data according to the limits found before\n",
        "            # Prepare the training and validation files for saving them later \n",
        "            ensambleValid = pd.DataFrame(index=self.dates[validMinLimit:validMaxLimit].loc[:,'Date'].drop_duplicates().tolist())\n",
        "            ensambleTest = pd.DataFrame(index=self.dates[testMinLimit:testMaxLimit].loc[:,'Date'].drop_duplicates().tolist())\n",
        "            \n",
        "            # Put the name of the index for validation and testing\n",
        "            ensambleValid.index.name = 'Date'\n",
        "            ensambleTest.index.name = 'Date'\n",
        "            \n",
        "            # Explorations are epochs considered, or how many times the agent will play the game.  \n",
        "            for eps in self.explorations:\n",
        "\n",
        "                # policy will be 0.2, so the randomness of predictions (actions) will happen with 20% of probability \n",
        "                self.policy.eps = eps[0]\n",
        "                \n",
        "                # there will be 100 iterations (epochs), or eps[1])\n",
        "                for i in range(0, eps[1]):\n",
        "                    \n",
        "                    del(trainEnv)\n",
        "\n",
        "                    # Define the training, validation and testing environments with their respective callbacks\n",
        "                    trainEnv = SpEnv(operationCost=self.operationCost,minLimit=trainMinLimit,maxLimit=trainMaxLimit,callback=self.trainer,isOnlyShort=self.isOnlyShort)\n",
        "                    del(validEnv)\n",
        "                    validEnv = SpEnv(operationCost=self.operationCost,minLimit=validMinLimit,maxLimit=validMaxLimit,callback=self.validator,isOnlyShort=self.isOnlyShort,ensamble=ensambleValid,columnName=\"iteration\"+str(i))\n",
        "                    del(testEnv)\n",
        "                    testEnv = SpEnv(operationCost=self.operationCost,minLimit=testMinLimit,maxLimit=testMaxLimit,callback=self.tester,isOnlyShort=self.isOnlyShort,ensamble=ensambleTest,columnName=\"iteration\"+str(i))\n",
        "\n",
        "                    # Reset the callback\n",
        "                    self.trainer.reset()\n",
        "                    self.validator.reset()\n",
        "                    self.tester.reset()\n",
        "\n",
        "                    # Reset the training environment\n",
        "                    trainEnv.resetEnv()\n",
        "                    # Train the agent\n",
        "                    self.agent.fit(trainEnv, nb_steps=floor(self.trainSize.days-self.trainSize.days*0.2),visualize=False,verbose=0)\n",
        "                    # Get the info from the train callback\n",
        "                    (_,trainCoverage,trainAccuracy,trainReward,trainLongPerc,trainShortPerc,trainLongAcc,trainShortAcc,trainLongPrec,trainShortPrec)=self.trainer.getInfo()\n",
        "                    # Print Callback values on the screen\n",
        "                    print(str(i) + \" TRAIN:  acc: \" + str(trainAccuracy)+ \" cov: \" + str(trainCoverage)+ \" rew: \" + str(trainReward))\n",
        "\n",
        "                    # Reset the validation environment\n",
        "                    validEnv.resetEnv()\n",
        "                    # Test the agent on validation data\n",
        "                    self.agent.test(validEnv,nb_episodes=floor(self.validationSize.days-self.validationSize.days*0.2),visualize=False,verbose=0)\n",
        "                    # Get the info from the validation callback\n",
        "                    (_,validCoverage,validAccuracy,validReward,validLongPerc,validShortPerc,validLongAcc,validShortAcc,validLongPrec,validShortPrec)=self.validator.getInfo()\n",
        "                    # Print callback values on the screen\n",
        "                    print(str(i) + \" VALID:  acc: \" + str(validAccuracy)+ \" cov: \" + str(validCoverage)+ \" rew: \" + str(validReward))\n",
        "\n",
        "                    # Reset the testing environment\n",
        "                    testEnv.resetEnv()\n",
        "                    # Test the agent on testing data\n",
        "                    self.agent.test(testEnv,nb_episodes=floor(self.validationSize.days-self.validationSize.days*0.2),visualize=False,verbose=0)\n",
        "                    # Get the info from the testing callback\n",
        "                    (_,testCoverage,testAccuracy,testReward,testLongPerc,testShortPerc,testLongAcc,testShortAcc,testLongPrec,testShortPrec)=self.tester.getInfo()\n",
        "                    # Print callback values on the screen\n",
        "                    print(str(i) + \" TEST:  acc: \" + str(testAccuracy)+ \" cov: \" + str(testCoverage)+ \" rew: \" + str(testReward))\n",
        "                    print(\" \")\n",
        "                    \n",
        "                    # write the walk data on the text file\n",
        "                    self.outputFile.write(\n",
        "                        str(i)+\",\"+\n",
        "                        str(trainAccuracy)+\",\"+\n",
        "                        str(trainCoverage)+\",\"+\n",
        "                        str(trainReward)+\",\"+\n",
        "                        str(trainLongPerc)+\",\"+\n",
        "                        str(trainShortPerc)+\",\"+\n",
        "                        str(trainLongAcc)+\",\"+\n",
        "                        str(trainShortAcc)+\",\"+\n",
        "                        str(trainLongPrec)+\",\"+\n",
        "                        str(trainShortPrec)+\",\"+\n",
        "                        \n",
        "                        str(validAccuracy)+\",\"+\n",
        "                        str(validCoverage)+\",\"+\n",
        "                        str(validReward)+\",\"+\n",
        "                        str(validLongPerc)+\",\"+\n",
        "                        str(validShortPerc)+\",\"+\n",
        "                        str(validLongAcc)+\",\"+\n",
        "                        str(validShortAcc)+\",\"+\n",
        "                        str(validLongPrec)+\",\"+\n",
        "                        str(validShortPrec)+\",\"+\n",
        "                        \n",
        "                        str(testAccuracy)+\",\"+\n",
        "                        str(testCoverage)+\",\"+\n",
        "                        str(testReward)+\",\"+\n",
        "                        str(testLongPerc)+\",\"+\n",
        "                        str(testShortPerc)+\",\"+\n",
        "                        str(testLongAcc)+\",\"+\n",
        "                        str(testShortAcc)+\",\"+\n",
        "                        str(testLongPrec)+\",\"+\n",
        "                        str(testShortPrec)+\"\\n\")\n",
        "\n",
        "            # Close the file                \n",
        "            self.outputFile.close()\n",
        "\n",
        "            # For the next walk, the current starting point will be the current starting point + the test size\n",
        "            # It means that, for the next walk, the training data will start 6 months after the training data of \n",
        "            # the previous walk   \n",
        "            self.currentStartingPoint += self.testSize\n",
        "\n",
        "            # Write validation and Testing data into files\n",
        "            # Save the files for processing later with the ensemble considering the 100 epochs\n",
        "            ensambleValid.to_csv(\"Output/ensemble/\"+self.ensembleFolderName+\"/walk\"+str(iteration)+\"ensemble_valid.csv\")\n",
        "            ensambleTest.to_csv(\"Output/ensemble/\"+self.ensembleFolderName+\"/walk\"+str(iteration)+\"ensemble_test.csv\")\n",
        "\n",
        "    # Function to end the Agent\n",
        "    def end(self):\n",
        "        print(\"END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hISBRm7HzF64"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR_r2Ivdw-KN",
        "outputId": "2c147958-844b-423c-eb2c-96e72fdfeebb"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:109: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function mean_q at 0x7f99c9298950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function mean_q at 0x7f99c9298950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bf5cfb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bf5cfb90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bf568b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bf568b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99c954bb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99c954bb00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bb416170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bb416170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "0 TRAIN:  acc: 0.5066225165562914 cov: 0.6291666666666667 rew: -0.2784956085235818\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "0 VALID:  acc: 0.43 cov: 0.6944444444444444 rew: -0.09876666391546934\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "0 TEST:  acc: 0.345679012345679 cov: 0.5625 rew: -0.1598948442169609\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "1 TRAIN:  acc: 0.6508810572687225 cov: 0.6305555555555555 rew: 4.138648417058045\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "1 VALID:  acc: 0.6020408163265306 cov: 0.6805555555555556 rew: -0.04474231694356505\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "1 TEST:  acc: 0.4935064935064935 cov: 0.5347222222222222 rew: -0.04539313804639586\n",
            " \n",
            "Resetted: episode 1241; Index 14899 over the limit (14899)\n",
            "2 TRAIN:  acc: 0.7263045793397231 cov: 0.6520833333333333 rew: 5.964262886280958\n",
            "Resetted: episode 120; Index 1672 over the limit (1672)\n",
            "2 VALID:  acc: 0.524390243902439 cov: 0.5694444444444444 rew: -0.07089396904009397\n",
            "Resetted: episode 127; Index 1952 over the limit (1952)\n",
            "2 TEST:  acc: 0.5238095238095238 cov: 0.5833333333333334 rew: -0.07201166000835284\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b94fbef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b94fbef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b94d08c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b94d08c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "0 TRAIN:  acc: 0.5214521452145214 cov: 0.63125 rew: 0.48744764199068763\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "0 VALID:  acc: 0.44761904761904764 cov: 0.7291666666666666 rew: -0.07734654718576309\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "0 TEST:  acc: 0.49 cov: 0.6944444444444444 rew: -0.04395049326322561\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "1 TRAIN:  acc: 0.6559139784946236 cov: 0.6458333333333334 rew: 3.782099029924698\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "1 VALID:  acc: 0.5714285714285714 cov: 0.6319444444444444 rew: 0.10996488141800334\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "1 TEST:  acc: 0.5 cov: 0.625 rew: -0.06196586316868246\n",
            " \n",
            "Resetted: episode 1237; Index 15078 over the limit (15078)\n",
            "2 TRAIN:  acc: 0.7015384615384616 cov: 0.6770833333333334 rew: 5.324665741696495\n",
            "Resetted: episode 126; Index 1923 over the limit (1923)\n",
            "2 VALID:  acc: 0.5119047619047619 cov: 0.5833333333333334 rew: 0.002755084640774808\n",
            "Resetted: episode 122; Index 1835 over the limit (1835)\n",
            "2 TEST:  acc: 0.5176470588235295 cov: 0.5902777777777778 rew: -0.001785635596751196\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b94d0170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b94d0170> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bab99d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bab99d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1240; Index 15541 over the limit (15541)\n",
            "0 TRAIN:  acc: 0.5195681511470985 cov: 0.5145833333333333 rew: 0.7021210939068072\n",
            "Resetted: episode 121; Index 1806 over the limit (1806)\n",
            "0 VALID:  acc: 0.48214285714285715 cov: 0.7777777777777778 rew: -0.053615317051169654\n",
            "Resetted: episode 128; Index 1933 over the limit (1933)\n",
            "0 TEST:  acc: 0.425531914893617 cov: 0.6527777777777778 rew: -0.048170830058636635\n",
            " \n",
            "Resetted: episode 1240; Index 15541 over the limit (15541)\n",
            "1 TRAIN:  acc: 0.6532356532356532 cov: 0.56875 rew: 3.8017941952568775\n",
            "Resetted: episode 121; Index 1806 over the limit (1806)\n",
            "1 VALID:  acc: 0.46153846153846156 cov: 0.18055555555555555 rew: -0.056707813727995056\n",
            "Resetted: episode 128; Index 1933 over the limit (1933)\n",
            "1 TEST:  acc: 0.4 cov: 0.3472222222222222 rew: -0.03222253990685648\n",
            " \n",
            "Resetted: episode 1240; Index 15541 over the limit (15541)\n",
            "2 TRAIN:  acc: 0.7021028037383178 cov: 0.5944444444444444 rew: 4.815312312846153\n",
            "Resetted: episode 121; Index 1806 over the limit (1806)\n",
            "2 VALID:  acc: 0.6470588235294118 cov: 0.7083333333333334 rew: 0.16390231924637205\n",
            "Resetted: episode 128; Index 1933 over the limit (1933)\n",
            "2 TEST:  acc: 0.47619047619047616 cov: 0.7291666666666666 rew: 0.05761478779582745\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bab99710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bab99710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8ef18c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8ef18c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1236; Index 15851 over the limit (15851)\n",
            "0 TRAIN:  acc: 0.503461918892186 cov: 0.7020833333333333 rew: 0.6546652209882631\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "0 VALID:  acc: 0.4117647058823529 cov: 0.4722222222222222 rew: 0.010801317289075137\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "0 TEST:  acc: 0.6216216216216216 cov: 0.5138888888888888 rew: 0.2540292858577487\n",
            " \n",
            "Resetted: episode 1236; Index 15851 over the limit (15851)\n",
            "1 TRAIN:  acc: 0.6617647058823529 cov: 0.6138888888888889 rew: 4.791037325294823\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "1 VALID:  acc: 0.4247787610619469 cov: 0.7847222222222222 rew: -0.007837418427729902\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "1 TEST:  acc: 0.5684210526315789 cov: 0.6597222222222222 rew: 0.23623462077512777\n",
            " \n",
            "Resetted: episode 1236; Index 15851 over the limit (15851)\n",
            "2 TRAIN:  acc: 0.7086223984142715 cov: 0.7006944444444444 rew: 5.71634758140963\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "2 VALID:  acc: 0.4909090909090909 cov: 0.3819444444444444 rew: 0.05411430712891708\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "2 TEST:  acc: 0.6507936507936508 cov: 0.4375 rew: 0.2869366103892129\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8ef1290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8ef1290> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8bf39e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8bf39e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1241; Index 16314 over the limit (16314)\n",
            "0 TRAIN:  acc: 0.5320139697322468 cov: 0.5965277777777778 rew: 0.7533248445471327\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "0 VALID:  acc: 0.5632183908045977 cov: 0.6041666666666666 rew: 0.13615697691120368\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "0 TEST:  acc: 0.6046511627906976 cov: 0.5972222222222222 rew: 0.4893823567017896\n",
            " \n",
            "Resetted: episode 1241; Index 16314 over the limit (16314)\n",
            "1 TRAIN:  acc: 0.6523702031602708 cov: 0.6152777777777778 rew: 3.0935078670527685\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "1 VALID:  acc: 0.47058823529411764 cov: 0.8263888888888888 rew: 0.11170207429734952\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "1 TEST:  acc: 0.5803571428571429 cov: 0.7777777777777778 rew: 0.15687680120075972\n",
            " \n",
            "Resetted: episode 1241; Index 16314 over the limit (16314)\n",
            "2 TRAIN:  acc: 0.7209533267130089 cov: 0.6993055555555555 rew: 5.235202013936665\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "2 VALID:  acc: 0.48148148148148145 cov: 0.75 rew: 0.12899984914170098\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "2 TEST:  acc: 0.5363636363636364 cov: 0.7638888888888888 rew: 0.269485567223564\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8bf3320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8bf3320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8e45050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b8e45050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1236; Index 16605 over the limit (16605)\n",
            "0 TRAIN:  acc: 0.5156092648539778 cov: 0.6895833333333333 rew: 0.006695373797164058\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "0 VALID:  acc: 0.44565217391304346 cov: 0.6388888888888888 rew: 0.06852728526507285\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "0 TEST:  acc: 0.5689655172413793 cov: 0.8055555555555556 rew: 0.08568352825045908\n",
            " \n",
            "Resetted: episode 1236; Index 16605 over the limit (16605)\n",
            "1 TRAIN:  acc: 0.6394230769230769 cov: 0.5777777777777777 rew: 2.45189567593247\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "1 VALID:  acc: 0.5543478260869565 cov: 0.6388888888888888 rew: 0.22498281643519544\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "1 TEST:  acc: 0.44036697247706424 cov: 0.7569444444444444 rew: -0.36259622796265867\n",
            " \n",
            "Resetted: episode 1236; Index 16605 over the limit (16605)\n",
            "2 TRAIN:  acc: 0.7298474945533769 cov: 0.6375 rew: 3.6070076026347477\n",
            "Resetted: episode 128; Index 1913 over the limit (1913)\n",
            "2 VALID:  acc: 0.5555555555555556 cov: 0.75 rew: 0.2875234757499222\n",
            "Resetted: episode 121; Index 1817 over the limit (1817)\n",
            "2 TEST:  acc: 0.39473684210526316 cov: 0.7916666666666666 rew: -0.41128498819624537\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b88d84d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b88d84d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b85d6b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b85d6b00> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1239; Index 17027 over the limit (17027)\n",
            "0 TRAIN:  acc: 0.4989451476793249 cov: 0.6583333333333333 rew: -0.1483018133475173\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "0 VALID:  acc: 0.41509433962264153 cov: 0.7361111111111112 rew: -0.2813657771332323\n",
            "Resetted: episode 129; Index 1944 over the limit (1944)\n",
            "0 TEST:  acc: 0.49504950495049505 cov: 0.7013888888888888 rew: 0.09926891113320199\n",
            " \n",
            "Resetted: episode 1239; Index 17027 over the limit (17027)\n",
            "1 TRAIN:  acc: 0.6063454759106933 cov: 0.5909722222222222 rew: 2.2204915320815637\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "1 VALID:  acc: 0.43 cov: 0.6944444444444444 rew: -0.26505842707084876\n",
            "Resetted: episode 129; Index 1944 over the limit (1944)\n",
            "1 TEST:  acc: 0.5283018867924528 cov: 0.7361111111111112 rew: 0.08283937167586719\n",
            " \n",
            "Resetted: episode 1239; Index 17027 over the limit (17027)\n",
            "2 TRAIN:  acc: 0.6840981856990395 cov: 0.6506944444444445 rew: 3.4446973762293567\n",
            "Resetted: episode 120; Index 1788 over the limit (1788)\n",
            "2 VALID:  acc: 0.45544554455445546 cov: 0.7013888888888888 rew: -0.20596366431639307\n",
            "Resetted: episode 129; Index 1944 over the limit (1944)\n",
            "2 TEST:  acc: 0.5495495495495496 cov: 0.7708333333333334 rew: 0.17316846722675422\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b85d64d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b85d64d0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b82e2a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b82e2a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1239; Index 17389 over the limit (17389)\n",
            "0 TRAIN:  acc: 0.521311475409836 cov: 0.6354166666666666 rew: 0.13094707763581387\n",
            "Resetted: episode 128; Index 1915 over the limit (1915)\n",
            "0 VALID:  acc: 0.4025974025974026 cov: 0.5347222222222222 rew: -0.037445094786017846\n",
            "Resetted: episode 123; Index 1842 over the limit (1842)\n",
            "0 TEST:  acc: 0.45054945054945056 cov: 0.6319444444444444 rew: 0.01350813846790634\n",
            " \n",
            "Resetted: episode 1239; Index 17389 over the limit (17389)\n",
            "1 TRAIN:  acc: 0.6419902912621359 cov: 0.5722222222222222 rew: 2.3943252281115504\n",
            "Resetted: episode 128; Index 1915 over the limit (1915)\n",
            "1 VALID:  acc: 0.4166666666666667 cov: 0.5833333333333334 rew: -0.09767149078208417\n",
            "Resetted: episode 123; Index 1842 over the limit (1842)\n",
            "1 TEST:  acc: 0.5375 cov: 0.5555555555555556 rew: 0.14481525994491787\n",
            " \n",
            "Resetted: episode 1239; Index 17389 over the limit (17389)\n",
            "2 TRAIN:  acc: 0.6702767749699158 cov: 0.5770833333333333 rew: 3.4053200681433275\n",
            "Resetted: episode 128; Index 1915 over the limit (1915)\n",
            "2 VALID:  acc: 0.4774774774774775 cov: 0.7708333333333334 rew: -0.025865835051894416\n",
            "Resetted: episode 123; Index 1842 over the limit (1842)\n",
            "2 TEST:  acc: 0.5304347826086957 cov: 0.7986111111111112 rew: 0.15230019308144369\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b82b3e60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b82b3e60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7fe1710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7fe1710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1243; Index 17823 over the limit (17823)\n",
            "0 TRAIN:  acc: 0.5394990366088632 cov: 0.7208333333333333 rew: 0.6720148862424742\n",
            "Resetted: episode 122; Index 1813 over the limit (1813)\n",
            "0 VALID:  acc: 0.5 cov: 0.5138888888888888 rew: 0.062315220188213685\n",
            "Resetted: episode 129; Index 1948 over the limit (1948)\n",
            "0 TEST:  acc: 0.5789473684210527 cov: 0.5277777777777778 rew: 0.25849481341648\n",
            " \n",
            "Resetted: episode 1243; Index 17823 over the limit (17823)\n",
            "1 TRAIN:  acc: 0.6367980884109916 cov: 0.58125 rew: 2.429221228475082\n",
            "Resetted: episode 122; Index 1813 over the limit (1813)\n",
            "1 VALID:  acc: 0.34146341463414637 cov: 0.5694444444444444 rew: -0.1528660626461482\n",
            "Resetted: episode 129; Index 1948 over the limit (1948)\n",
            "1 TEST:  acc: 0.5232558139534884 cov: 0.5972222222222222 rew: 0.1417766605395218\n",
            " \n",
            "Resetted: episode 1243; Index 17823 over the limit (17823)\n",
            "2 TRAIN:  acc: 0.6786961583236322 cov: 0.5965277777777778 rew: 3.413471012161078\n",
            "Resetted: episode 122; Index 1813 over the limit (1813)\n",
            "2 VALID:  acc: 0.4247787610619469 cov: 0.7847222222222222 rew: -0.08348622849449591\n",
            "Resetted: episode 129; Index 1948 over the limit (1948)\n",
            "2 TEST:  acc: 0.5192307692307693 cov: 0.7222222222222222 rew: -0.025782679276193644\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7fe10e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7fe10e0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7ce7950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7ce7950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1243; Index 18185 over the limit (18185)\n",
            "0 TRAIN:  acc: 0.4984894259818731 cov: 0.6895833333333333 rew: -0.3809221998600991\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "0 VALID:  acc: 0.6052631578947368 cov: 0.5277777777777778 rew: 0.07751207374647864\n",
            "Resetted: episode 125; Index 1879 over the limit (1879)\n",
            "0 TEST:  acc: 0.5280898876404494 cov: 0.6180555555555556 rew: 0.04569609811153303\n",
            " \n",
            "Resetted: episode 1243; Index 18185 over the limit (18185)\n",
            "1 TRAIN:  acc: 0.6007556675062973 cov: 0.5513888888888889 rew: 2.0904009977389193\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "1 VALID:  acc: 0.4318181818181818 cov: 0.3055555555555556 rew: -0.0949020656250303\n",
            "Resetted: episode 125; Index 1879 over the limit (1879)\n",
            "1 TEST:  acc: 0.5454545454545454 cov: 0.3819444444444444 rew: 0.02900941580540621\n",
            " \n",
            "Resetted: episode 1243; Index 18185 over the limit (18185)\n",
            "2 TRAIN:  acc: 0.6043256997455471 cov: 0.5458333333333333 rew: 2.3696445230034513\n",
            "Resetted: episode 128; Index 1919 over the limit (1919)\n",
            "2 VALID:  acc: 0.4507042253521127 cov: 0.4930555555555556 rew: -0.06849092797666936\n",
            "Resetted: episode 125; Index 1879 over the limit (1879)\n",
            "2 TEST:  acc: 0.5616438356164384 cov: 0.5069444444444444 rew: 0.06013652814266671\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7ce7320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7ce7320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b79e6950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b79e6950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1248; Index 18586 over the limit (18586)\n",
            "0 TRAIN:  acc: 0.5029761904761905 cov: 0.7 rew: 0.24452059253053868\n",
            "Resetted: episode 124; Index 1850 over the limit (1850)\n",
            "0 VALID:  acc: 0.5822784810126582 cov: 0.5486111111111112 rew: 0.07974956839373691\n",
            "Resetted: episode 129; Index 1946 over the limit (1946)\n",
            "0 TEST:  acc: 0.43902439024390244 cov: 0.5694444444444444 rew: -0.1317204440535274\n",
            " \n",
            "Resetted: episode 1248; Index 18586 over the limit (18586)\n",
            "1 TRAIN:  acc: 0.6206140350877193 cov: 0.6333333333333333 rew: 3.587428795764645\n",
            "Resetted: episode 124; Index 1850 over the limit (1850)\n",
            "1 VALID:  acc: 0.5189873417721519 cov: 0.5486111111111112 rew: 0.011545425981802093\n",
            "Resetted: episode 129; Index 1946 over the limit (1946)\n",
            "1 TEST:  acc: 0.4634146341463415 cov: 0.5694444444444444 rew: 0.12318582627197215\n",
            " \n",
            "Resetted: episode 1248; Index 18586 over the limit (18586)\n",
            "2 TRAIN:  acc: 0.656350053361793 cov: 0.6506944444444445 rew: 3.880273650906528\n",
            "Resetted: episode 124; Index 1850 over the limit (1850)\n",
            "2 VALID:  acc: 0.47540983606557374 cov: 0.8472222222222222 rew: -0.08171184199932924\n",
            "Resetted: episode 129; Index 1946 over the limit (1946)\n",
            "2 TEST:  acc: 0.3853211009174312 cov: 0.7569444444444444 rew: -0.19990476656141443\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b81265f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b81265f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b76e0680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b76e0680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1250; Index 18734 over the limit (18734)\n",
            "0 TRAIN:  acc: 0.5178571428571429 cov: 0.6611111111111111 rew: -0.14851960479639817\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "0 VALID:  acc: 0.44 cov: 0.5208333333333334 rew: -0.11447840635734163\n",
            "Resetted: episode 124; Index 1866 over the limit (1866)\n",
            "0 TEST:  acc: 0.4647887323943662 cov: 0.4930555555555556 rew: -0.07656862597131321\n",
            " \n",
            "Resetted: episode 1250; Index 18734 over the limit (18734)\n",
            "1 TRAIN:  acc: 0.63121387283237 cov: 0.6006944444444444 rew: 3.7246850026649616\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "1 VALID:  acc: 0.49 cov: 0.6944444444444444 rew: -0.10575657712604353\n",
            "Resetted: episode 124; Index 1866 over the limit (1866)\n",
            "1 TEST:  acc: 0.5217391304347826 cov: 0.6388888888888888 rew: 0.0012116028594713632\n",
            " \n",
            "Resetted: episode 1250; Index 18734 over the limit (18734)\n",
            "2 TRAIN:  acc: 0.6981327800829875 cov: 0.6694444444444444 rew: 5.2785213186783295\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "2 VALID:  acc: 0.4090909090909091 cov: 0.6111111111111112 rew: -0.37332024824568877\n",
            "Resetted: episode 124; Index 1866 over the limit (1866)\n",
            "2 TEST:  acc: 0.4605263157894737 cov: 0.5277777777777778 rew: -0.15174272605379727\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b76e0050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b76e0050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7441950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7441950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1253; Index 18758 over the limit (18758)\n",
            "0 TRAIN:  acc: 0.5304182509505704 cov: 0.7305555555555555 rew: 0.6923083749321255\n",
            "Resetted: episode 122; Index 1836 over the limit (1836)\n",
            "0 VALID:  acc: 0.44642857142857145 cov: 0.7777777777777778 rew: -0.33499287835612784\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "0 TEST:  acc: 0.4392523364485981 cov: 0.7430555555555556 rew: -0.14601996152456145\n",
            " \n",
            "Resetted: episode 1253; Index 18758 over the limit (18758)\n",
            "1 TRAIN:  acc: 0.6323366555924695 cov: 0.6270833333333333 rew: 4.513276435481963\n",
            "Resetted: episode 122; Index 1836 over the limit (1836)\n",
            "1 VALID:  acc: 0.44761904761904764 cov: 0.7291666666666666 rew: -0.21876791759198963\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "1 TEST:  acc: 0.4824561403508772 cov: 0.7916666666666666 rew: -0.08066287965939696\n",
            " \n",
            "Resetted: episode 1253; Index 18758 over the limit (18758)\n",
            "2 TRAIN:  acc: 0.7093844601412714 cov: 0.6881944444444444 rew: 6.864815042272912\n",
            "Resetted: episode 122; Index 1836 over the limit (1836)\n",
            "2 VALID:  acc: 0.5789473684210527 cov: 0.6597222222222222 rew: 0.022960741937302638\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "2 TEST:  acc: 0.5 cov: 0.6666666666666666 rew: 0.056481338650957336\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bb10b5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99bb10b5f0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7113680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b7113680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1254; Index 18758 over the limit (18758)\n",
            "0 TRAIN:  acc: 0.5275310834813499 cov: 0.7819444444444444 rew: 0.8891029530203753\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "0 VALID:  acc: 0.44155844155844154 cov: 0.5347222222222222 rew: 0.12638327680748224\n",
            "Resetted: episode 121; Index 1821 over the limit (1821)\n",
            "0 TEST:  acc: 0.5084745762711864 cov: 0.4097222222222222 rew: -0.012333418869529284\n",
            " \n",
            "Resetted: episode 1254; Index 18758 over the limit (18758)\n",
            "1 TRAIN:  acc: 0.6420940170940171 cov: 0.65 rew: 4.487286522896937\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "1 VALID:  acc: 0.425531914893617 cov: 0.6527777777777778 rew: -0.08096525811635252\n",
            "Resetted: episode 121; Index 1821 over the limit (1821)\n",
            "1 TEST:  acc: 0.5957446808510638 cov: 0.6527777777777778 rew: 0.07724002937205761\n",
            " \n",
            "Resetted: episode 1254; Index 18758 over the limit (18758)\n",
            "2 TRAIN:  acc: 0.7172413793103448 cov: 0.7048611111111112 rew: 7.328168123758615\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "2 VALID:  acc: 0.5306122448979592 cov: 0.6805555555555556 rew: 0.11293812708344024\n",
            "Resetted: episode 121; Index 1821 over the limit (1821)\n",
            "2 TEST:  acc: 0.5057471264367817 cov: 0.6041666666666666 rew: -0.006840977129213097\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b84c6cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b84c6cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6e59950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6e59950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1256; Index 18803 over the limit (18803)\n",
            "0 TRAIN:  acc: 0.5015576323987538 cov: 0.66875 rew: 0.8495868294102914\n",
            "Resetted: episode 119; Index 1791 over the limit (1791)\n",
            "0 VALID:  acc: 0.6862745098039216 cov: 0.3541666666666667 rew: 0.08243346126149628\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "0 TEST:  acc: 0.5324675324675324 cov: 0.5347222222222222 rew: 0.07504717687144272\n",
            " \n",
            "Resetted: episode 1256; Index 18803 over the limit (18803)\n",
            "1 TRAIN:  acc: 0.6832369942196532 cov: 0.6006944444444444 rew: 5.04747505440533\n",
            "Resetted: episode 119; Index 1791 over the limit (1791)\n",
            "1 VALID:  acc: 0.5333333333333333 cov: 0.3125 rew: -0.018792257048703426\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "1 TEST:  acc: 0.42028985507246375 cov: 0.4791666666666667 rew: -0.12664761360423735\n",
            " \n",
            "Resetted: episode 1256; Index 18803 over the limit (18803)\n",
            "2 TRAIN:  acc: 0.727076591154261 cov: 0.64375 rew: 7.26361001087348\n",
            "Resetted: episode 119; Index 1791 over the limit (1791)\n",
            "2 VALID:  acc: 0.5853658536585366 cov: 0.8541666666666666 rew: 0.06630018586532682\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "2 TEST:  acc: 0.4883720930232558 cov: 0.8958333333333334 rew: -0.0098378223984741\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6e59320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6e59320> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6ba4950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6ba4950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1254; Index 18761 over the limit (18761)\n",
            "0 TRAIN:  acc: 0.5377176015473888 cov: 0.7180555555555556 rew: 1.6835808759152742\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "0 VALID:  acc: 0.4838709677419355 cov: 0.8611111111111112 rew: -0.03446355069515546\n",
            "Resetted: episode 121; Index 1829 over the limit (1829)\n",
            "0 TEST:  acc: 0.4690265486725664 cov: 0.7847222222222222 rew: -0.1030754062711723\n",
            " \n",
            "Resetted: episode 1254; Index 18761 over the limit (18761)\n",
            "1 TRAIN:  acc: 0.6705263157894736 cov: 0.6597222222222222 rew: 6.09133736123643\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "1 VALID:  acc: 0.4666666666666667 cov: 0.7291666666666666 rew: -0.018615194669961928\n",
            "Resetted: episode 121; Index 1829 over the limit (1829)\n",
            "1 TEST:  acc: 0.46846846846846846 cov: 0.7708333333333334 rew: -0.1368010806693979\n",
            " \n",
            "Resetted: episode 1254; Index 18761 over the limit (18761)\n",
            "2 TRAIN:  acc: 0.7385057471264368 cov: 0.725 rew: 8.19027173240659\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "2 VALID:  acc: 0.5425531914893617 cov: 0.6527777777777778 rew: 0.1203650211726401\n",
            "Resetted: episode 121; Index 1829 over the limit (1829)\n",
            "2 TEST:  acc: 0.48484848484848486 cov: 0.6875 rew: 0.027680394398319912\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99ba284a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99ba284a70> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b68f3680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b68f3680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1253; Index 18769 over the limit (18769)\n",
            "0 TRAIN:  acc: 0.5367573011077543 cov: 0.6895833333333333 rew: 1.2662313035048096\n",
            "Resetted: episode 119; Index 1799 over the limit (1799)\n",
            "0 VALID:  acc: 0.5050505050505051 cov: 0.6875 rew: 0.029503118778229268\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "0 TEST:  acc: 0.5172413793103449 cov: 0.6041666666666666 rew: -0.14655298405972111\n",
            " \n",
            "Resetted: episode 1253; Index 18769 over the limit (18769)\n",
            "1 TRAIN:  acc: 0.6794871794871795 cov: 0.65 rew: 5.414930759316468\n",
            "Resetted: episode 119; Index 1799 over the limit (1799)\n",
            "1 VALID:  acc: 0.5892857142857143 cov: 0.7777777777777778 rew: 0.1790972592174374\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "1 TEST:  acc: 0.4803921568627451 cov: 0.7083333333333334 rew: -0.11046294948393509\n",
            " \n",
            "Resetted: episode 1253; Index 18769 over the limit (18769)\n",
            "2 TRAIN:  acc: 0.749748743718593 cov: 0.6909722222222222 rew: 6.787254894133873\n",
            "Resetted: episode 119; Index 1799 over the limit (1799)\n",
            "2 VALID:  acc: 0.5833333333333334 cov: 0.6666666666666666 rew: 0.20652579467053883\n",
            "Resetted: episode 128; Index 1934 over the limit (1934)\n",
            "2 TEST:  acc: 0.4942528735632184 cov: 0.6041666666666666 rew: -0.03473983994506954\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6e59ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6e59ef0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6632950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6632950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1254; Index 18778 over the limit (18778)\n",
            "0 TRAIN:  acc: 0.5213930348258706 cov: 0.6979166666666666 rew: 0.34164404800885134\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "0 VALID:  acc: 0.594059405940594 cov: 0.7013888888888888 rew: -0.032703855997035534\n",
            "Resetted: episode 121; Index 1828 over the limit (1828)\n",
            "0 TEST:  acc: 0.5175438596491229 cov: 0.7916666666666666 rew: 0.0909155627540996\n",
            " \n",
            "Resetted: episode 1254; Index 18778 over the limit (18778)\n",
            "1 TRAIN:  acc: 0.6466666666666666 cov: 0.625 rew: 3.576628363913676\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "1 VALID:  acc: 0.5431034482758621 cov: 0.8055555555555556 rew: 0.07508987105924401\n",
            "Resetted: episode 121; Index 1828 over the limit (1828)\n",
            "1 TEST:  acc: 0.49107142857142855 cov: 0.7777777777777778 rew: 0.08102020199478803\n",
            " \n",
            "Resetted: episode 1254; Index 18778 over the limit (18778)\n",
            "2 TRAIN:  acc: 0.7172211350293543 cov: 0.7097222222222223 rew: 6.125530307543716\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "2 VALID:  acc: 0.5887850467289719 cov: 0.7430555555555556 rew: 0.0442203680347381\n",
            "Resetted: episode 121; Index 1828 over the limit (1828)\n",
            "2 TEST:  acc: 0.5137614678899083 cov: 0.7569444444444444 rew: 0.23385350507877367\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6556e60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6556e60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6371680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6371680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1253; Index 18767 over the limit (18767)\n",
            "0 TRAIN:  acc: 0.5281285878300803 cov: 0.6048611111111111 rew: 0.6299247408634545\n",
            "Resetted: episode 118; Index 1783 over the limit (1783)\n",
            "0 VALID:  acc: 0.42168674698795183 cov: 0.5763888888888888 rew: -0.14799681818376353\n",
            "Resetted: episode 128; Index 1932 over the limit (1932)\n",
            "0 TEST:  acc: 0.5180722891566265 cov: 0.5763888888888888 rew: 0.02628374301106321\n",
            " \n",
            "Resetted: episode 1253; Index 18767 over the limit (18767)\n",
            "1 TRAIN:  acc: 0.6876484560570071 cov: 0.5847222222222223 rew: 3.9145015760477797\n",
            "Resetted: episode 118; Index 1783 over the limit (1783)\n",
            "1 VALID:  acc: 0.46938775510204084 cov: 0.6805555555555556 rew: 0.04476590316346294\n",
            "Resetted: episode 128; Index 1932 over the limit (1932)\n",
            "1 TEST:  acc: 0.5116279069767442 cov: 0.5972222222222222 rew: -0.014118118675572925\n",
            " \n",
            "Resetted: episode 1253; Index 18767 over the limit (18767)\n",
            "2 TRAIN:  acc: 0.7394366197183099 cov: 0.6902777777777778 rew: 5.943000170812769\n",
            "Resetted: episode 118; Index 1783 over the limit (1783)\n",
            "2 VALID:  acc: 0.42727272727272725 cov: 0.7638888888888888 rew: -0.03372778933256825\n",
            "Resetted: episode 128; Index 1932 over the limit (1932)\n",
            "2 TEST:  acc: 0.5113636363636364 cov: 0.6111111111111112 rew: -0.030984375593417088\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6371050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6371050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b60bd950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b60bd950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1250; Index 18737 over the limit (18737)\n",
            "0 TRAIN:  acc: 0.5237592397043295 cov: 0.6576388888888889 rew: 0.600388779770952\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "0 VALID:  acc: 0.5858585858585859 cov: 0.6875 rew: 0.16658685276813223\n",
            "Resetted: episode 122; Index 1844 over the limit (1844)\n",
            "0 TEST:  acc: 0.45454545454545453 cov: 0.6875 rew: -0.058907158641588964\n",
            " \n",
            "Resetted: episode 1250; Index 18737 over the limit (18737)\n",
            "1 TRAIN:  acc: 0.6613816534541337 cov: 0.6131944444444445 rew: 3.213483399300512\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "1 VALID:  acc: 0.5783132530120482 cov: 0.5763888888888888 rew: 0.010021724922445685\n",
            "Resetted: episode 122; Index 1844 over the limit (1844)\n",
            "1 TEST:  acc: 0.5238095238095238 cov: 0.5833333333333334 rew: 0.0325453585304763\n",
            " \n",
            "Resetted: episode 1250; Index 18737 over the limit (18737)\n",
            "2 TRAIN:  acc: 0.7060773480662983 cov: 0.6284722222222222 rew: 4.995527435233145\n",
            "Resetted: episode 127; Index 1917 over the limit (1917)\n",
            "2 VALID:  acc: 0.5204081632653061 cov: 0.6805555555555556 rew: -0.09731685974169142\n",
            "Resetted: episode 122; Index 1844 over the limit (1844)\n",
            "2 TEST:  acc: 0.48 cov: 0.6944444444444444 rew: -0.0832017608377487\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99ba2d8440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99ba2d8440> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b5d86950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b5d86950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1250; Index 18736 over the limit (18736)\n",
            "0 TRAIN:  acc: 0.541501976284585 cov: 0.7027777777777777 rew: 1.4085810794826672\n",
            "Resetted: episode 120; Index 1814 over the limit (1814)\n",
            "0 VALID:  acc: 0.5106382978723404 cov: 0.6527777777777778 rew: 0.03676933532412184\n",
            "Resetted: episode 128; Index 1936 over the limit (1936)\n",
            "0 TEST:  acc: 0.5 cov: 0.6666666666666666 rew: 0.15956278614359248\n",
            " \n",
            "Resetted: episode 1250; Index 18736 over the limit (18736)\n",
            "1 TRAIN:  acc: 0.6876267748478702 cov: 0.6847222222222222 rew: 4.931924414280986\n",
            "Resetted: episode 120; Index 1814 over the limit (1814)\n",
            "1 VALID:  acc: 0.4368932038834951 cov: 0.7152777777777778 rew: -0.10190210562727373\n",
            "Resetted: episode 128; Index 1936 over the limit (1936)\n",
            "1 TEST:  acc: 0.5913978494623656 cov: 0.6458333333333334 rew: 0.2254280582593713\n",
            " \n",
            "Resetted: episode 1250; Index 18736 over the limit (18736)\n",
            "2 TRAIN:  acc: 0.7425650557620818 cov: 0.7472222222222222 rew: 7.023217258664055\n",
            "Resetted: episode 120; Index 1814 over the limit (1814)\n",
            "2 VALID:  acc: 0.49523809523809526 cov: 0.7291666666666666 rew: -0.09185966711611823\n",
            "Resetted: episode 128; Index 1936 over the limit (1936)\n",
            "2 TEST:  acc: 0.5494505494505495 cov: 0.6319444444444444 rew: 0.14770796500373193\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b68f3710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b68f3710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b5acf680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b5acf680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1247; Index 18699 over the limit (18699)\n",
            "0 TRAIN:  acc: 0.5508559919436052 cov: 0.6895833333333333 rew: 1.8351422412804406\n",
            "Resetted: episode 126; Index 1906 over the limit (1906)\n",
            "0 VALID:  acc: 0.5742574257425742 cov: 0.7013888888888888 rew: 0.08882447221555965\n",
            "Resetted: episode 125; Index 1889 over the limit (1889)\n",
            "0 TEST:  acc: 0.5473684210526316 cov: 0.6597222222222222 rew: 0.057003565764225425\n",
            " \n",
            "Resetted: episode 1247; Index 18699 over the limit (18699)\n",
            "1 TRAIN:  acc: 0.677115987460815 cov: 0.6645833333333333 rew: 5.278404803927431\n",
            "Resetted: episode 126; Index 1906 over the limit (1906)\n",
            "1 VALID:  acc: 0.5217391304347826 cov: 0.6388888888888888 rew: 0.001692731759487958\n",
            "Resetted: episode 125; Index 1889 over the limit (1889)\n",
            "1 TEST:  acc: 0.4375 cov: 0.6666666666666666 rew: -0.0959000151550564\n",
            " \n",
            "Resetted: episode 1247; Index 18699 over the limit (18699)\n",
            "2 TRAIN:  acc: 0.7371980676328502 cov: 0.71875 rew: 6.947784521119083\n",
            "Resetted: episode 126; Index 1906 over the limit (1906)\n",
            "2 VALID:  acc: 0.5480769230769231 cov: 0.7222222222222222 rew: 0.1355313735594531\n",
            "Resetted: episode 125; Index 1889 over the limit (1889)\n",
            "2 TEST:  acc: 0.5412844036697247 cov: 0.7569444444444444 rew: 0.08772596561110699\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b5acf050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b5acf050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b581f950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b581f950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1246; Index 18688 over the limit (18688)\n",
            "0 TRAIN:  acc: 0.5403780068728522 cov: 0.8083333333333333 rew: 0.879862823032692\n",
            "Resetted: episode 123; Index 1859 over the limit (1859)\n",
            "0 VALID:  acc: 0.5 cov: 0.2777777777777778 rew: 0.01950667634065125\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "0 TEST:  acc: 0.4857142857142857 cov: 0.24305555555555555 rew: -0.05890144068882864\n",
            " \n",
            "Resetted: episode 1246; Index 18688 over the limit (18688)\n",
            "1 TRAIN:  acc: 0.7136797454931071 cov: 0.6548611111111111 rew: 4.471035886162633\n",
            "Resetted: episode 123; Index 1859 over the limit (1859)\n",
            "1 VALID:  acc: 0.5405405405405406 cov: 0.7708333333333334 rew: 0.10523546136282169\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "1 TEST:  acc: 0.5204081632653061 cov: 0.6805555555555556 rew: 0.032959509070652655\n",
            " \n",
            "Resetted: episode 1246; Index 18688 over the limit (18688)\n",
            "2 TRAIN:  acc: 0.7540360873694207 cov: 0.73125 rew: 5.955906807316984\n",
            "Resetted: episode 123; Index 1859 over the limit (1859)\n",
            "2 VALID:  acc: 0.5346534653465347 cov: 0.7013888888888888 rew: 0.10395599504079724\n",
            "Resetted: episode 126; Index 1904 over the limit (1904)\n",
            "2 TEST:  acc: 0.49411764705882355 cov: 0.5902777777777778 rew: 0.01802559650091497\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6371f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b6371f80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b555b680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b555b680> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1247; Index 18711 over the limit (18711)\n",
            "0 TRAIN:  acc: 0.5469223007063572 cov: 0.6881944444444444 rew: 0.597985460002826\n",
            "Resetted: episode 124; Index 1874 over the limit (1874)\n",
            "0 VALID:  acc: 0.5 cov: 0.3472222222222222 rew: -0.006009731754100011\n",
            "Resetted: episode 123; Index 1854 over the limit (1854)\n",
            "0 TEST:  acc: 0.75 cov: 0.4722222222222222 rew: 0.23292484415150244\n",
            " \n",
            "Resetted: episode 1247; Index 18711 over the limit (18711)\n",
            "1 TRAIN:  acc: 0.6968325791855203 cov: 0.6138888888888889 rew: 3.6070059036905184\n",
            "Resetted: episode 124; Index 1874 over the limit (1874)\n",
            "1 VALID:  acc: 0.5263157894736842 cov: 0.5277777777777778 rew: 0.004247220957896033\n",
            "Resetted: episode 123; Index 1854 over the limit (1854)\n",
            "1 TEST:  acc: 0.573170731707317 cov: 0.5694444444444444 rew: 0.1425536966424275\n",
            " \n",
            "Resetted: episode 1247; Index 18711 over the limit (18711)\n",
            "2 TRAIN:  acc: 0.743 cov: 0.6944444444444444 rew: 4.6756013890153865\n",
            "Resetted: episode 124; Index 1874 over the limit (1874)\n",
            "2 VALID:  acc: 0.49019607843137253 cov: 0.7083333333333334 rew: -0.0015114566848947871\n",
            "Resetted: episode 123; Index 1854 over the limit (1854)\n",
            "2 TEST:  acc: 0.5729166666666666 cov: 0.6666666666666666 rew: 0.07457338766955872\n",
            " \n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b555b050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b555b050> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b52a2950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function DQNAgent.compile.<locals>.<lambda> at 0x7f99b52a2950> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Resetted: episode 1244; Index 18666 over the limit (18666)\n",
            "0 TRAIN:  acc: 0.5304695304695305 cov: 0.6951388888888889 rew: 0.42277202851583756\n",
            "Resetted: episode 120; Index 1809 over the limit (1809)\n",
            "0 VALID:  acc: 0.43820224719101125 cov: 0.6180555555555556 rew: -0.08583220072918096\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "0 TEST:  acc: 0.5072463768115942 cov: 0.4791666666666667 rew: 0.002055829204299849\n",
            " \n",
            "Resetted: episode 1244; Index 18666 over the limit (18666)\n",
            "1 TRAIN:  acc: 0.675645342312009 cov: 0.61875 rew: 2.993247367059611\n",
            "Resetted: episode 120; Index 1809 over the limit (1809)\n",
            "1 VALID:  acc: 0.4444444444444444 cov: 0.6875 rew: -0.06417434575554823\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "1 TEST:  acc: 0.43 cov: 0.6944444444444444 rew: 0.03408832938967694\n",
            " \n",
            "Resetted: episode 1244; Index 18666 over the limit (18666)\n",
            "2 TRAIN:  acc: 0.703205791106515 cov: 0.6715277777777777 rew: 3.7266725348542233\n",
            "Resetted: episode 120; Index 1809 over the limit (1809)\n",
            "2 VALID:  acc: 0.4423076923076923 cov: 0.7222222222222222 rew: -0.13487076616637628\n",
            "Resetted: episode 127; Index 1919 over the limit (1919)\n",
            "2 TEST:  acc: 0.46601941747572817 cov: 0.7152777777777778 rew: 0.028117207583424342\n",
            " \n",
            "END\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "main.py\n",
        "'''\n",
        "#os library is used to define the GPU to be used by the code, needed only in cerain situations (Better not to use it, use only if the main gpu is Busy)\n",
        "#import os\n",
        "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";\n",
        "\n",
        "#This is the class call for the Agent which will perform the experiment\n",
        "# from deepQTrading import DeepQTrading\n",
        "\n",
        "#Date library to manipulate time in the source code\n",
        "import datetime\n",
        "\n",
        "#Keras library to define the NN to be used\n",
        "from keras.models import Sequential\n",
        "\n",
        "#Layers used in the NN considered\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "\n",
        "#Activation Layers used in the source code\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU, ReLU\n",
        "\n",
        "#Optimizer used in the NN\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#Libraries used for the Agent considered\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "\n",
        "\n",
        "#Library used for showing the exception in the case of error \n",
        "import sys\n",
        "\n",
        "#import tensorflow as tf\n",
        "#from keras.backend.tensorflow_backend import set_session\n",
        "#config = tf.ConfigProto()\n",
        "#config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "#set_session(tf.Session(config=config))\n",
        "\n",
        "\n",
        "\n",
        "#Let's capture the starting time and send it to the destination in order to tell that the experiment started \n",
        "startingTime=datetime.datetime.now()\n",
        "\n",
        "#There are three actions possible in the stock market\n",
        "#Hold(id 0): do nothing.\n",
        "#Long(id 1): It predicts that the stock market value will raise at the end of the day. \n",
        "#So, the action performed in this case is buying at the beginning of the day and sell it at the end of the day (aka long).\n",
        "#Short(id 2): It predicts that the stock market value will decrease at the end of the day.\n",
        "#So, the action that must be done is selling at the beginning of the day and buy it at the end of the day (aka short). \n",
        "\n",
        "nb_actions = 3\n",
        "isOnlyShort = 0\n",
        "ensembleFolderName = \"ensembleFolder\"\n",
        "\n",
        "#This is a simple NN considered. It is composed of:\n",
        "#One flatten layer to get 68 dimensional vectors as input\n",
        "#One dense layer with 35 neurons and LeakyRelu activation\n",
        "#One final Dense Layer with the 3 actions considered\n",
        "#the input is 20 observation days from the past, 8 observations from the past week and \n",
        "#40 observations from the past hours\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1,1,68)))\n",
        "model.add(Dense(35,activation='linear'))\n",
        "model.add(LeakyReLU(alpha=.001))\n",
        "model.add(Dense(nb_actions))\n",
        "model.add(Activation('linear'))\n",
        "\n",
        "\n",
        "#Define the DeepQTrading class with the following parameters:\n",
        "#explorations: 0.2 operations are random, and 100 epochs.\n",
        "#in this case, epochs parameter is used because the Agent acts on daily basis, so its better to repeat the experiments several\n",
        "#times so, its defined that each epoch will work on the data from training, validation and testing.\n",
        "#trainSize: the size of the train data gotten from the dataset, we are setting 5 stock market years, or 1800 days\n",
        "#validationSize: the size of the validation data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "#testSize: the size of the testing data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "#outputFile: where the results will be written\n",
        "#begin: where the walks will start from. We are defining January 1st of 2010\n",
        "#end: where the walks will finish. We are defining February 22nd of 2019\n",
        "#nOutput:number of walks\n",
        "dqt = DeepQTrading(\n",
        "    model=model,\n",
        "    explorations=[(0.2, 3)],\n",
        "    trainSize=datetime.timedelta(days=360*5),\n",
        "    validationSize=datetime.timedelta(days=30*6),\n",
        "    testSize=datetime.timedelta(days=30*6),\n",
        "    outputFile=\"Output/csv/walks/walks\",\n",
        "    begin=datetime.datetime(2001,1,1,0,0,0,0),\n",
        "    end=datetime.datetime(2019,2,28,0,0,0,0),\n",
        "    nbActions=nb_actions,\n",
        "    isOnlyShort=isOnlyShort,\n",
        "    ensembleFolderName=ensembleFolderName\n",
        "    )\n",
        "\n",
        "dqt.run()\n",
        "\n",
        "dqt.end()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble"
      ],
      "metadata": {
        "id": "2wj4ga3jyjiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ensemble"
      ],
      "metadata": {
        "id": "UPhKn84a0m2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ensemble.py\n",
        "'''\n",
        "def full_ensemble(df):\n",
        "    m1 = df.eq(1).all(axis=1)\n",
        "    m2 = df.eq(2).all(axis=1)\n",
        "    local_df = df.copy()\n",
        "    local_df['ensemble'] = np.select([m1, m2], [1, 2], 0)\n",
        "    local_df = local_df.drop(local_df.columns.difference(['ensemble']), axis=1)\n",
        "    return local_df\n",
        "\n",
        "\n",
        "def perc_ensemble(df, thr = 0.7):\n",
        "    c1 = (df.eq(1).sum(1) / df.shape[1]).gt(thr)\n",
        "    c2 = (df.eq(2).sum(1) / df.shape[1]).gt(thr)\n",
        "    return pd.DataFrame(np.select([c1, c2], [1, 2], 0), index=df.index, columns=['ensemble'])\n",
        "\n",
        "\n",
        "def ensemble(numWalks, perc, type, numDel):\n",
        "    dollSum=0\n",
        "    rewSum=0\n",
        "    posSum=0\n",
        "    negSum=0\n",
        "    covSum=0\n",
        "    numSum=0\n",
        "\n",
        "    values=[]\n",
        "    # output=open(\"daxValidDel9th60.csv\",\"w+\")\n",
        "    # output.write(\"Iteration,Reward%,#Wins,#Losses,Euro,Coverage,Accuracy\\n\")\n",
        "    columns = [\"Iteration\",\"Reward%\",\"#Wins\",\"#Losses\",\"Dollars\",\"Coverage\",\"Accuracy\"]\n",
        "    dax=pd.read_csv(\"datasets/sp500Day.csv\",index_col='Date')\n",
        "    for j in range(0, numWalks):\n",
        "\n",
        "        df=pd.read_csv(\"Output/ensemble/ensembleFolder/walk\"+str(j)+\"ensemble_\"+type+\".csv\",index_col='Date')\n",
        "\n",
        "        for deleted in range(1, numDel):\n",
        "            del df['iteration'+str(deleted)]\n",
        "        \n",
        "        if perc==0:\n",
        "            df=full_ensemble(df)\n",
        "        else:\n",
        "            df=perc_ensemble(df,perc)\n",
        "\n",
        "        num=0\n",
        "        rew=0\n",
        "        pos=0\n",
        "        neg=0\n",
        "        doll=0\n",
        "        cov=0\n",
        "        for date, i in df.iterrows():\n",
        "            num+=1\n",
        "\n",
        "            if date in dax.index:\n",
        "                if (i['ensemble']==1):\n",
        "                    pos+= 1 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                    \n",
        "                    neg+= 0 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                    rew+=(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                    doll+=(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "                    cov+=1\n",
        "                elif (i['ensemble']==2):\n",
        "                    \n",
        "                    neg+= 0 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                    pos+= 1 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                    rew+=-(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                    cov+=1\n",
        "                    doll+=-(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "        \n",
        "        values.append([str(round(j,2)),str(round(rew,2)),str(round(pos,2)),str(round(neg,2)),str(round(doll,2)),str(round(cov/num,2)),(str(round(pos/cov,2)) if (cov>0) else \"\")])\n",
        "        \n",
        "        dollSum+=doll\n",
        "        rewSum+=rew\n",
        "        posSum+=pos\n",
        "        negSum+=neg\n",
        "        covSum+=cov\n",
        "        numSum+=num\n",
        "\n",
        "\n",
        "    values.append([\"sum\",str(round(rewSum,2)),str(round(posSum,2)),str(round(negSum,2)),str(round(dollSum,2)),str(round(covSum/numSum,2)),(str(round(posSum/covSum,2)) if (covSum>0) else \"\")])\n",
        "    return values, columns\n",
        "\n",
        "\n",
        "def evaluate(csvname=\"\"):\n",
        "    \n",
        "    output=open(\"resultsSPFinal.csv\",\"w+\")\n",
        "    output.write(\"Iteration,Reward%,#Wins,#Losses,Euro,Coverage,Accuracy\\n\")\n",
        "    df=pd.read_csv(csvname)\n",
        "    dax=pd.read_csv(\"datasets/sp500Day.csv\",index_col='Date')\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df['date'] = df['date'].dt.strftime('%m/%d/%Y')\n",
        "    df.set_index('date', inplace=True)\n",
        "    print(df)\n",
        "    num=0\n",
        "    rew=0\n",
        "    pos=0\n",
        "    neg=0\n",
        "    doll=0\n",
        "    cov=0\n",
        "    for date, i in df.iterrows():\n",
        "        num+=1\n",
        "\n",
        "        if date in dax.index:\n",
        "            if (i['ensemble']==1):\n",
        "                pos+= 1 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                \n",
        "                neg+= 0 if (dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                rew+=(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                doll+=(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "                cov+=1\n",
        "            elif (i['ensemble']==-1):\n",
        "                \n",
        "                neg+= 0 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 1\n",
        "                pos+= 1 if -(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open'] > 0 else 0\n",
        "                rew+=-(dax.at[date,'Close']-dax.at[date,'Open'])/dax.at[date,'Open']\n",
        "                cov+=1\n",
        "                doll+=-(dax.at[date,'Close']-dax.at[date,'Open'])*50\n",
        "    \n",
        "    output.write(str(0)+ \",\" + str(round(rew,2))+ \",\" + str(round(pos,2))+ \",\" + str(round(neg,2))+ \",\" + str(round(doll,2))+ \",\" + str(round(cov/num,2))+ \",\" +(str(round(pos/cov,2)) if (cov>0) else \"\") + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "ensemble(numWalks=25, perc=0, type=\"valid\", numDel=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E5pWH7rykvW",
        "outputId": "5fe89cd3-ee00-4582-fb95-125eaa7180c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['0', '-0.03', '17', '17', '-2012.5', '0.28', '0.5'],\n",
              "  ['1', '-0.04', '24', '27', '-2475.0', '0.4', '0.47'],\n",
              "  ['2', '0.02', '23', '17', '1775.0', '0.33', '0.57'],\n",
              "  ['3', '-0.12', '8', '14', '-8762.5', '0.17', '0.36'],\n",
              "  ['4', '0.08', '25', '20', '5175.0', '0.37', '0.56'],\n",
              "  ['5', '0.17', '32', '29', '7550.0', '0.47', '0.52'],\n",
              "  ['6', '-0.35', '23', '40', '-14375.0', '0.52', '0.37'],\n",
              "  ['7', '-0.04', '17', '28', '-2287.5', '0.35', '0.38'],\n",
              "  ['8', '0.01', '23', '19', '112.5', '0.34', '0.55'],\n",
              "  ['9', '0.09', '23', '14', '4575.0', '0.29', '0.62'],\n",
              "  ['10', '0.03', '32', '15', '1787.5', '0.38', '0.68'],\n",
              "  ['11', '-0.0', '24', '21', '-225.0', '0.35', '0.53'],\n",
              "  ['12', '-0.01', '27', '31', '-525.0', '0.47', '0.47'],\n",
              "  ['13', '0.01', '21', '21', '400.0', '0.33', '0.5'],\n",
              "  ['14', '0.04', '17', '19', '2775.0', '0.3', '0.47'],\n",
              "  ['15', '0.12', '36', '21', '9850.0', '0.45', '0.63'],\n",
              "  ['16', '0.02', '27', '20', '1950.0', '0.39', '0.57'],\n",
              "  ['17', '0.05', '27', '21', '4800.0', '0.38', '0.56'],\n",
              "  ['18', '-0.04', '22', '24', '-4175.0', '0.39', '0.48'],\n",
              "  ['19', '0.05', '30', '28', '4837.5', '0.45', '0.52'],\n",
              "  ['20', '-0.02', '25', '29', '-1812.5', '0.45', '0.46'],\n",
              "  ['21', '0.12', '32', '29', '13012.5', '0.48', '0.52'],\n",
              "  ['22', '-0.02', '14', '16', '-2000.0', '0.24', '0.47'],\n",
              "  ['23', '-0.01', '17', '16', '-1000.0', '0.26', '0.52'],\n",
              "  ['24', '0.02', '15', '16', '3075.0', '0.26', '0.48'],\n",
              "  ['sum', '0.16', '581', '552', '22025.0', '0.36', '0.51']],\n",
              " ['Iteration',\n",
              "  'Reward%',\n",
              "  '#Wins',\n",
              "  '#Losses',\n",
              "  'Dollars',\n",
              "  'Coverage',\n",
              "  'Accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\"Output\\results\\finalEnsembleSP500.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "Vg52qmVF50Dk",
        "outputId": "8c3ac65c-6f98-4fd5-b600-fcb8127c605f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3c2f6e4f24c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output\\results\\finalEnsembleSP500.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-5adc8adaebd1>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(csvname)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resultsSPFinal.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration,Reward%,#Wins,#Losses,Euro,Coverage,Accuracy\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mdax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/sp500Day.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Output\\results\\x0cinalEnsembleSP500.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## splitEnsemble"
      ],
      "metadata": {
        "id": "vqWUd5Z-0sk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "splitEnsemble.py\n",
        "'''\n",
        "\n",
        "long = [[],[]]\n",
        "short = [[],[]]\n",
        "\n",
        "longs=pd.read_csv(\"Output/results/spLong.csv\")\n",
        "shorts=pd.read_csv(\"Output/results/spShort.csv\")\n",
        "\n",
        "long[0]= longs.loc[:,\"Date\"].tolist()\n",
        "long[1]= longs.loc[:,\"ensemble\"].tolist()\n",
        "short[0] = shorts.loc[:,\"Date\"].tolist()\n",
        "short[1] = shorts.loc[:,\"ensemble\"].tolist()\n",
        "\n",
        "output = open(\"finalEnsemble.csv\", \"w+\")\n",
        "output.write(\"date,ensemble\\n\")\n",
        "\n",
        "for i in range(0,len(long[0])):\n",
        "    if(long[0][i]==short[0][i]):\n",
        "        output.write(str(long[0][i]) + \",\" + str(long[1][i]+short[1][i]) + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "TTgineAvyyRZ",
        "outputId": "c56cd039-db89-4de2-c936-07ae86ffe961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0df78ea6ed9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlongs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output/results/spLong.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mshorts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output/results/spShort.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Output/results/spLong.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n4FZrA4czCg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# parserWeek.py"
      ],
      "metadata": {
        "id": "9kRS45IsYbAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas # library to work with (.csv) datasets\n",
        "# library to work with datetime data\n",
        "from datetime import datetime \n",
        "from datetime import timedelta\n",
        "\n",
        "file = open(\"daxWeek.csv\", \"w+\") # creating a new file (.csv) to store the results\n",
        "spTimeserie = pandas.read_csv('daxDay.csv') # reading \"daxDay.csv\" dataset to start processing\n",
        "file.write(\"Date,Time,Open,High,Low,Close\\n\") # assigning headers (column names) to the newly-created output dataset\n",
        "\n",
        "# creating some lists according to columns of the datasets, which contain values of the input dataset's columns as lists. \n",
        "Date = spTimeserie.loc[:, 'Date'].tolist() \n",
        "Time = spTimeserie.loc[:, 'Time'].tolist()\n",
        "Open = spTimeserie.loc[:, 'Open'].tolist()\n",
        "High = spTimeserie.loc[:, 'High'].tolist()\n",
        "Low = spTimeserie.loc[:, 'Low'].tolist()\n",
        "Close = spTimeserie.loc[:, 'Close'].tolist()\n",
        "Volume = spTimeserie.loc[:, 'Volume'].tolist()\n",
        "\n",
        "records = [] # creatting an empty list\n",
        "limit = len(Open) # setting a limit according to the size of the input dataset\n",
        "for i in range(0,limit): # this loop turns 'records' to a kind of dataset which contains all values of the input with their column names\n",
        "    records.append({'Date' : Date[i],'Time' : Time[i], 'Open': Open[i], 'High': High[i], 'Low': Low[i], 'Close': Close[i], 'Volume': Volume[i] })\n",
        "\n",
        "# initializing some variables\n",
        "close=0 # initializing 'closing price' with 0\n",
        "opeN = records[0]['Open'] # initializing 'opening price' with the 1st record of 'records'\n",
        "low = records[0]['Low'] # initializing 'lowest price' with the 1st record of 'records'\n",
        "high = records[0]['High'] # initializing 'highest price' with the 1st record of 'records'\n",
        "currentDate=datetime.strptime(records[0]['Date'], '%m/%d/%Y') # initializing 'currentDate' with the 1st record of 'records'\n",
        "delta = timedelta(days = 7) # initializing 'delta' as 7 days or 1 week\n",
        "volume=0 # setting initial volume to zero\n",
        "\n",
        "for record in records: # loop over 'records' dataset\n",
        "    \n",
        "    if(record['High']>high): # checking if the current 'high' is more than the initial one\n",
        "        high=record['High'] # ... if so, we reassign variable 'high'\n",
        "    if(record['Low']<low): # checking if the current 'low' is less than the initial one\n",
        "        low=record['Low'] # ... if so, we reassign variable 'low'\n",
        "    nextDate=record['Date'] # with the help of this line we go to the next date\n",
        "\n",
        "    # prints two bounds of the week that we are investigating (starting with nextDate, ending with currentDate + 7)\n",
        "    print( datetime.strptime(nextDate, '%m/%d/%Y').strftime(\"%d/%m/%Y\") + \"  \" + (currentDate + delta).strftime(\"%d/%m/%Y\")) \n",
        "    print(currentDate.strftime(\"%d/%m/%Y\")) # prints currentDate in the output\n",
        "\n",
        "    # ???\n",
        "    print(str(datetime.strptime(nextDate, '%m/%d/%Y') >= (currentDate + delta))  + \" or \" + str(datetime.strptime(nextDate, '%m/%d/%Y') < currentDate) + \" = \" + \n",
        "          str(datetime.strptime(nextDate, '%m/%d/%Y') >= (currentDate + delta) or datetime.strptime(nextDate, '%m/%d/%Y') < currentDate ) )\n",
        "    \n",
        "    # checking edge cases and boundries :\n",
        "    if(datetime.strptime(nextDate, '%m/%d/%Y') >= (currentDate + delta) or datetime.strptime(nextDate, '%m/%d/%Y') < currentDate ):\n",
        "        print(\"writing\")\n",
        "        if(datetime.strptime(nextDate, '%m/%d/%Y') < currentDate): # checking if our iteration is before todays date\n",
        "            # storing data based on the last written record:\n",
        "            file.write(str(records[-1]['Date']) + ',' + \"00:00\" + ',' + str(opeN) + ',' + str(high) + ',' + str(low) + ',' + str(close) + '\\n')\n",
        "        else: # (if our iteration is after the next weeks date)\n",
        "            # storing in the output dataset:\n",
        "            file.write(str(nextDate) + ',' + \"00:00\" + ',' + str(opeN) + ',' + str(high) + ',' + str(low) + ',' + str(close) + '\\n')\n",
        "        \n",
        "        high = record['High'] # updating value of 'high'\n",
        "        opeN = record['Open'] # updating value of 'open'\n",
        "        low = record['Low'] # updating value of 'low'\n",
        "        volume=0 # reassigning 'volume' to zero\n",
        "        currentDate=datetime.strptime(nextDate, '%m/%d/%Y') # updating 'currentDate'\n",
        "    \n",
        "    volume+=record['Volume'] # updating 'volume'\n",
        "    close=record['Close'] # updating 'close'\n",
        "\n",
        "print(\"Done\") # notifying that the notebook has been completed"
      ],
      "metadata": {
        "id": "efnnDgo5YhuU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "mahdi-deep-q-trading.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}