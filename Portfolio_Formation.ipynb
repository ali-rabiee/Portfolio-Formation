{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-rabiee/Portfolio-Formation/blob/main/Portfolio_Formation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_weG2085js1I"
      },
      "source": [
        "# Requirements & Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO48s139j1ux",
        "outputId": "37d5250f-892b-4934-9632-cbf1030785c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-rl in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.7/dist-packages (from keras-rl) (2.8.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: keras-rl in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.7/dist-packages (from keras-rl) (2.8.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: rl in /usr/local/lib/python3.7/dist-packages (3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rl) (57.4.0)\n",
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.12)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.25.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.21.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.44.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (4.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-rl2) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.27.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "  Attempting uninstall: tf-estimator-nightly\n",
            "    Found existing installation: tf-estimator-nightly 2.10.0.dev2022051408\n",
            "    Uninstalling tf-estimator-nightly-2.10.0.dev2022051408:\n",
            "      Successfully uninstalled tf-estimator-nightly-2.10.0.dev2022051408\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-nightly 2.10.0.dev20220514 requires tf-estimator-nightly~=2.10.0.dev, but you have tf-estimator-nightly 2.8.0.dev2021122109 which is incompatible.\u001b[0m\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Requirement already satisfied: Callbacks in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: callbacks in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement rl.callbacks (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for rl.callbacks\u001b[0m\n",
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.7/dist-packages (2.10.0.dev20220514)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: keras-nightly~=2.10.0.dev in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.10.0.dev2022051407)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.14.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (4.2.0)\n",
            "Collecting tf-estimator-nightly~=2.10.0.dev\n",
            "  Using cached tf_estimator_nightly-2.10.0.dev2022051408-py2.py3-none-any.whl (438 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.44.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.25.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (14.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: tb-nightly~=2.10.0.a in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (2.10.0a20220513)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly) (2.27.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.10.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.10.0.a->tf-nightly) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.10.0.a->tf-nightly) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.10.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.10.0.a->tf-nightly) (2.0.12)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.10.0.a->tf-nightly) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tf-nightly) (3.0.8)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "  Attempting uninstall: tf-estimator-nightly\n",
            "    Found existing installation: tf-estimator-nightly 2.8.0.dev2021122109\n",
            "    Uninstalling tf-estimator-nightly-2.8.0.dev2021122109:\n",
            "      Successfully uninstalled tf-estimator-nightly-2.8.0.dev2021122109\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, but you have tf-estimator-nightly 2.10.0.dev2022051408 which is incompatible.\u001b[0m\n",
            "Successfully installed tf-estimator-nightly-2.10.0.dev2022051408\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.8.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: minisom in /usr/local/lib/python3.7/dist-packages (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install keras-rl\n",
        "!pip install keras\n",
        "!pip install keras-rl\n",
        "!pip install gym\n",
        "!pip install rl\n",
        "!pip install keras-rl2\n",
        "!pip install Callbacks \n",
        "!pip install callbacks\n",
        "!pip install rl.callbacks\n",
        "!pip install tf-nightly\n",
        "!pip install yfinance\n",
        "!pip install minisom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pEH2djqcrQZ"
      },
      "source": [
        "# Google Drive Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eKy9ZcaPcvD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02973c84-fb2d-4722-d9a6-aba6ef73612b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "os.chdir('drive/My Drive/Colab Notebooks/DQN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjjvgBnm41PL"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqSrnQ8_45PW",
        "outputId": "980a4992-faa5-4f3c-980c-d3c52ddea67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Stocks: 57\n"
          ]
        }
      ],
      "source": [
        "# Name of 60 Stocks  \n",
        "stocks = ['CDEV', 'GILD', 'JBLU', 'HBAN','SLB',\n",
        "          'CS', 'PLUG', 'USB', 'ABBV','CTRA', 'SIRI',\n",
        "          'SCHW', 'M', 'FCX', 'MO','UAL', 'ET','KGC',\n",
        "          'NCLH', 'NKE','ERIC', 'ZNGA','PTON',\n",
        "          'CLF', 'PYPL', 'MRO','CMCSA', 'INFY',\n",
        "          'SNAP','TSM', 'CSCO', 'FB', 'UBER', 'OXY',\n",
        "          'JPM', 'GOLD', 'TSLA', 'BABA', 'NLSN','TLRY',\n",
        "          'AMC', 'VALE', 'DAL', 'TELL','ITUB', 'PCG','AAL',\n",
        "          'NVDA', 'WFC', 'AMD', 'AAPL', 'TWTR', 'MRNA',\n",
        "          'JNJ', 'GOOGL', 'COST', 'WMT']\n",
        "\n",
        "print(f\"Number of Stocks: {len(stocks)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xzqzd0Tepqp"
      },
      "outputs": [],
      "source": [
        "from get_stock import get_stock\n",
        "\n",
        "# Getting Data\n",
        "\n",
        "start = \"2020-05-10\"\n",
        "end = \"2022-04-29\"\n",
        "\n",
        "for ticker in stocks:\n",
        "    # Download datasets\n",
        "    print(f'### Downloading {ticker}:')\n",
        "    Hour = get_stock(ticker, start, end, \"60m\")\n",
        "    Day = get_stock(ticker, start, end, \"1d\")\n",
        "    Week = get_stock(ticker, start, end, \"1wk\")\n",
        "    \n",
        "    # Reset indexes\n",
        "    Hour.reset_index(drop=True, inplace=True)\n",
        "    Day.reset_index(drop=True, inplace=True)\n",
        "    Week.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Save the datasets\n",
        "    PATH = \"datasets/\"\n",
        "    Hour.to_csv(f\"{PATH}{ticker}hour.csv\")\n",
        "    Day.to_csv(f\"{PATH}{ticker}day.csv\")\n",
        "    Week.to_csv(f\"{PATH}{ticker}week.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwdGjA34GIBc"
      },
      "source": [
        "# Train the DQN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56xe9An9nMDH"
      },
      "source": [
        "The code needs three positional parameters to be correctly executed: \\\\\n",
        "python main.py [numberOfActions, isOnlyShort, ensembleFolder]\n",
        "\n",
        "\n",
        "* To run the FULL agent you need to run: python main.py 3 0 ensembleFolder\n",
        "* To run the ONLY LONG agent you need to run: python main.py 2 0 ensembleFolder\n",
        "* To run the ONLY SHORT agent you need to run: python main.py 2 1 ensembleFolder \\\\\n",
        "where the paramenter ensembleFolder is used to set the name of the folder in which you'll get your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR_r2Ivdw-KN",
        "outputId": "e05dc5c9-8d88-4c55-f6de-7cd3681b8be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"This is the class call for the Agent which will perform the experiment\"\"\"\n",
        "\n",
        "#This is the class call for the Agent which will perform the experiment\n",
        "from deepQTrading import DeepQTrading\n",
        "\n",
        "#Date library to manipulate time in the source code\n",
        "import datetime\n",
        "\n",
        "#Keras library to define the NN to be used\n",
        "from keras.models import Sequential\n",
        "\n",
        "#Layers used in the NN considered\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "\n",
        "#Activation Layers used in the source code\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU, ReLU\n",
        "\n",
        "#Optimizer used in the NN\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#Libraries used for the Agent considered\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "\n",
        "\n",
        "#Library used for showing the exception in the case of error \n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from evaluation import perc_ensemble, full_ensemble, ensemble\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "\n",
        "'''\n",
        "There are three actions possible in the stock market\n",
        "Hold(id 0): do nothing.\n",
        "Long(id 1): It predicts that the stock market value will raise at the end of the day. \n",
        "So, the action performed in this case is buying at the beginning of the day and sell it at the end of the day (aka long).\n",
        "Short(id 2): It predicts that the stock market value will decrease at the end of the day.\n",
        "So, the action that must be done is selling at the beginning of the day and buy it at the end of the day (aka short). \n",
        "//////////////////////////////////////////////////////////////\n",
        "The Model is a simple NN considered. It is composed of:\n",
        "One flatten layer to get 68 dimensional vectors as input\n",
        "One dense layer with 35 neurons and LeakyRelu activation\n",
        "One final Dense Layer with the 3 actions considered\n",
        "the input is 20 observation days from the past, 8 observations from the past week and \n",
        "40 observations from the past hours\n",
        "//////////////////////////////////////////////////////////////\n",
        "Define the DeepQTrading class with the following parameters:\n",
        "explorations: 0.2 operations are random, and 100 epochs.\n",
        "in this case, epochs parameter is used because the Agent acts on daily basis, so its better to repeat the experiments several\n",
        "times so, its defined that each epoch will work on the data from training, validation and testing.\n",
        "trainSize: the size of the train data gotten from the dataset, we are setting 5 stock market years, or 1800 days\n",
        "validationSize: the size of the validation data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "testSize: the size of the testing data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "outputFile: where the results will be written\n",
        "begin: where the walks will start from. We are defining January 1st of 2010\n",
        "end: where the walks will finish. We are defining February 22nd of 2019\n",
        "nOutput:number of walks\n",
        "'''\n",
        "# Set Parameters\n",
        "nb_actions = 3\n",
        "isOnlyShort = 0\n",
        "ensembleFolderName = \"ensembleFolder\"\n",
        "\n",
        "\n",
        "# Define the DQN model \n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1, 1, 68)))\n",
        "model.add(Dense(50, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=.001))\n",
        "model.add(Dense(50, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=.001))\n",
        "model.add(Dense(nb_actions))\n",
        "model.add(Activation('linear'))\n",
        "\n",
        "\n",
        "stocks = ['MRO','CMCSA', 'INFY',\n",
        "          'SNAP', 'TSM', 'CSCO', 'FB', 'UBER', 'OXY',\n",
        "          'JPM', 'GOLD', 'TSLA', 'BABA', 'NLSN','TLRY',\n",
        "          'AMC', 'VALE', 'DAL', 'TELL','ITUB', 'PCG','AAL',\n",
        "          'NVDA', 'WFC', 'AMD', 'AAPL', 'TWTR', 'MRNA',\n",
        "          'JNJ', 'GOOGL', 'COST', 'WMT']\n",
        "\n",
        "for ticker in stocks:\n",
        "\n",
        "    print(f\"\\n#### Train {ticker} ####\\n\")\n",
        "    # Define the DeepQTrading class\n",
        "    dqt = DeepQTrading(\n",
        "        ticker=ticker,\n",
        "        model=model,\n",
        "        explorations=[(0.2, 50)],\n",
        "        trainSize=datetime.timedelta(days=30*19),\n",
        "        validationSize=datetime.timedelta(days=30*1),\n",
        "        testSize=datetime.timedelta(days=30*1),\n",
        "        outputFile=\"Output/csv/walks/walks\",\n",
        "        begin=datetime.datetime(2020, 6, 30, 0, 0, 0, 0),\n",
        "        end=datetime.datetime(2022, 4, 1, 0, 0, 0, 0),\n",
        "        nbActions=nb_actions,\n",
        "        isOnlyShort=isOnlyShort,\n",
        "        ensembleFolderName=ensembleFolderName\n",
        "        )\n",
        "    numWalks = dqt.run()\n",
        "    dqt.end()\n",
        "\n",
        "    # Preparing and saving the results\n",
        "    numDel = 0\n",
        "    for j in range(0, numWalks):\n",
        "\n",
        "        df_test = pd.read_csv(\"./Output/ensemble/ensembleFolder/walk\"+str(j)+f\"ensemble_test_{ticker}.csv\", index_col='Date')\n",
        "        df_valid = pd.read_csv(\"./Output/ensemble/ensembleFolder/walk\"+str(j)+f\"ensemble_valid_{ticker}.csv\", index_col='Date')\n",
        "\n",
        "        for deleted in range(1, numDel):\n",
        "            del df_test['iteration'+str(deleted)]\n",
        "            del df_valid['iteration'+str(deleted)]\n",
        "\n",
        "        if j == 0:\n",
        "            fulldf_test = perc_ensemble(df_test)\n",
        "            fulldf_valid = perc_ensemble(df_valid)\n",
        "\n",
        "        else:\n",
        "            fulldf_test = fulldf_test.append(perc_ensemble(df_test))\n",
        "            fulldf_valid = fulldf_valid.append(perc_ensemble(df_valid))\n",
        "\n",
        "\n",
        "    metrics_test = ensemble(numWalks, ticker, data_type='test', numDel=10)\n",
        "    metrics_valid = ensemble(numWalks, ticker, data_type='valid', numDel=10)\n",
        "\n",
        "    # method = \"short\" if isOnlyShort == 1 else \"long\"\n",
        "    # method = '3act' if nb_actions == 3 else method \n",
        "\n",
        "    # Save Predictions\n",
        "    PATH = \"./Output/results/DQN predictions/\"\n",
        "    fulldf_test.to_csv(f\"{PATH}{ticker}_preds_test.csv\")\n",
        "    fulldf_valid.to_csv(f\"{PATH}{ticker}_preds_valid.csv\")\n",
        "\n",
        "    # Save metrics\n",
        "    PATH = \"./Output/results/DQN metrics/\"\n",
        "    metrics_test.to_csv(f\"{PATH}{ticker}_metrics_test.csv\")\n",
        "    metrics_valid.to_csv(f\"{PATH}{ticker}_metrics_valid.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8niLbUgJrjNG"
      },
      "source": [
        "# Portfolio Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Profitable Stocks"
      ],
      "metadata": {
        "id": "XNeq32VQ6srJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vFdkt_3n6mQb"
      },
      "outputs": [],
      "source": [
        "stocks = ['CDEV', 'GILD', 'JBLU', 'HBAN','SLB',\n",
        "          'CS', 'PLUG', 'USB', 'ABBV','CTRA', 'SIRI',\n",
        "          'SCHW', 'M', 'FCX', 'MO','UAL', 'ET','KGC',\n",
        "          'NCLH', 'NKE','ERIC', 'ZNGA','PTON',\n",
        "          'CLF', 'PYPL', 'MRO','CMCSA', 'INFY',\n",
        "          'SNAP','TSM', 'CSCO', 'FB', 'UBER', 'OXY',\n",
        "          'JPM', 'GOLD', 'TSLA', 'BABA', 'NLSN','TLRY',\n",
        "          'AMC', 'VALE', 'DAL', 'TELL','ITUB', 'PCG','AAL',\n",
        "          'NVDA', 'WFC', 'AMD', 'AAPL', 'TWTR', 'MRNA',\n",
        "          'JNJ', 'GOOGL', 'COST', 'WMT']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble the actions for only-long and only-short agents\n",
        "\n",
        "data_type = 'test'\n",
        "\n",
        "for ticker in stocks:\n",
        "    preds_long = pd.read_csv(f\"./Output/results/DQN predictions/{ticker}_long_preds_{data_type}.csv\")\n",
        "    preds_short = pd.read_csv(f\"./Output/results/DQN predictions/{ticker}_short_preds_{data_type}.csv\")\n",
        "    preds_ensemble = []\n",
        "\n",
        "    for i in range(len(preds_long)):\n",
        "        if preds_long[\"ensemble\"][i] == 1 and preds_short[\"ensemble\"][i] == 0:\n",
        "            preds_ensemble.append(1)\n",
        "        elif preds_long[\"ensemble\"][i] == 0 and preds_short[\"ensemble\"][i] == 2:\n",
        "            preds_ensemble.append(2)\n",
        "        else:\n",
        "            preds_ensemble.append(0) \n",
        "\n",
        "    # Read predictions file\n",
        "    preds = pd.read_csv(f\"./Output/results/DQN predictions/{ticker}_preds_{data_type}.csv\")\n",
        "    preds['ensemble preds'] = preds_ensemble\n",
        "    # Save \n",
        "    PATH = \"./Output/results/DQN prediction/\"\n",
        "    preds.to_csv(f\"{PATH}{ticker}_preds_{data_type}.csv\")"
      ],
      "metadata": {
        "id": "VALe-Kh9xQ6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################\n",
        "#     Comparison    #\n",
        "#####################"
      ],
      "metadata": {
        "id": "0oHWUfq36KES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7faeENVUrnLl"
      },
      "outputs": [],
      "source": [
        "# Extract Profitable stocks in each day\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "method = \"short\"\n",
        "data_type = \"test\"\n",
        "\n",
        "# Date of the preds\n",
        "preds = pd.read_csv(f\"./Output/results/DQN predictions/{stocks[0]}_preds_{data_type}.csv\")\n",
        "Date = preds_3act[\"Date\"].to_list()\n",
        "portfolio_ensemble = {}\n",
        "portfolio_3act = {}\n",
        " \n",
        "for date in Date:\n",
        "    \n",
        "    profitable_stocks1 = []\n",
        "    profitable_stocks2 = []\n",
        "\n",
        "    for ticker in stocks:\n",
        "        # Read Predictions\n",
        "        preds_3act = pd.read_csv(f\"./Output/results/DQN predictions/{ticker}_preds_{data_type}.csv\")\n",
        "        preds_long = pd.read_csv(f\"./Output/results/DQN predictions/{ticker}_long_preds_{data_type}.csv\")\n",
        "        preds_short = pd.read_csv(f\"./Output/results/DQN predictions/{ticker}_short_preds_{data_type}.csv\")\n",
        "        # preds = pd.read_csv(f\"./Output/results/predictions/{ticker}_{method}_preds_{data_type}.csv\")\n",
        "\n",
        "        # Get Predictions\n",
        "        pred_3act = int(preds_3act[preds_3act[\"Date\"] == date][\"ensemble\"])\n",
        "        pred_long = int(preds_long[preds_3act[\"Date\"] == date][\"ensemble\"])\n",
        "        pred_short = int(preds_short[preds_3act[\"Date\"] == date][\"ensemble\"])\n",
        "\n",
        "        if pred_long == 1 and pred_short == 0:\n",
        "            profitable_stocks1.append(ticker)\n",
        "\n",
        "        if pred_3act == 1:\n",
        "            profitable_stocks2.append(ticker)\n",
        "\n",
        "    portfolio_ensemble[date] = profitable_stocks1\n",
        "    portfolio_3act[date] = profitable_stocks2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rank the Rewards base on validation set\n",
        "\n",
        "data_type = 'valid'\n",
        "columns = [\"Iteration\", \"Reward_Long%\", \"Reward_Short%\", \"Reward%\", \"Wins%\", \"Losses%\", \"Coverage%\", \"Accuracy\", \"Dataset\"]\n",
        "df_metrics = pd.DataFrame(columns=columns)\n",
        "for ticker in stocks:\n",
        "    metrics = pd.read_csv(f\"./Output/results/DQN metrics/{ticker}_metrics_{data_type}.csv\")\n",
        "    metrics = metrics[[metrics['Iteration']=='sum']] \n",
        "    metrics['Dataset'] = ticker\n",
        "    df_metrics.append(metrics)"
      ],
      "metadata": {
        "id": "hfSiPi0qrn9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQHQXXVae2BI"
      },
      "source": [
        "## Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "383WfBJNe5oz"
      },
      "outputs": [],
      "source": [
        "from clustering import calculate_correlation, visualize_clusters\n",
        "import datetime\n",
        "\n",
        "# Calculate the correlation of time series from the base for last num days\n",
        "base = \"2020-10-25\"\n",
        "base = datetime.datetime.strptime(base, '%Y-%m-%d')\n",
        "numdays = 30\n",
        "som_x, som_y, win_map, clusters = calculate_correlation(base, numdays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtdCAeky0Lig"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "visualize_clusters(som_x, som_y, win_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU + Attention"
      ],
      "metadata": {
        "id": "oLHz-kgw51Nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "#     Implement Model     #\n",
        "###########################"
      ],
      "metadata": {
        "id": "iTSHQtfl553I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "xpBKOUWv5ZZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "#     Implement Model     #\n",
        "###########################"
      ],
      "metadata": {
        "id": "SgjhbooD5qlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM + Attention"
      ],
      "metadata": {
        "id": "KkHtF2IE5mJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################\n",
        "#     Implement Model     #\n",
        "###########################"
      ],
      "metadata": {
        "id": "u6FDnt7-5dl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9I7FPPFAeDp"
      },
      "source": [
        "### LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xemvvWCHAgSF",
        "outputId": "8d60a17e-8b2c-408f-e970-d259ff99b6e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0        Date   Time    Datetime        Open        High  \\\n",
              "0             0  2020-05-11  00:00  2020-05-11   77.025002   79.262497   \n",
              "1             1  2020-05-12  00:00  2020-05-12   79.457497   79.922501   \n",
              "2             2  2020-05-13  00:00  2020-05-13   78.037498   78.987503   \n",
              "3             3  2020-05-14  00:00  2020-05-14   76.127502   77.447502   \n",
              "4             4  2020-05-15  00:00  2020-05-15   75.087502   76.974998   \n",
              "..          ...         ...    ...         ...         ...         ...   \n",
              "492         492  2022-04-22  00:00  2022-04-22  166.460007  167.869995   \n",
              "493         493  2022-04-25  00:00  2022-04-25  161.119995  163.169998   \n",
              "494         494  2022-04-26  00:00  2022-04-26  162.250000  162.339996   \n",
              "495         495  2022-04-27  00:00  2022-04-27  155.910004  159.789993   \n",
              "496         496  2022-04-28  00:00  2022-04-28  159.250000  164.520004   \n",
              "\n",
              "            Low       Close   Adj Close     Volume    reward  \n",
              "0     76.809998   78.752502   78.225410  145946400  0.022428  \n",
              "1     77.727501   77.852501   77.331436  162301200  0.000000  \n",
              "2     75.802498   76.912498   76.397720  200622400  0.000000  \n",
              "3     75.382500   77.385002   76.867065  158929200  0.016518  \n",
              "4     75.052498   76.927498   76.412621  166348400  0.024505  \n",
              "..          ...         ...         ...        ...       ...  \n",
              "492  161.500000  161.789993  161.789993   84775200  0.000000  \n",
              "493  158.460007  162.880005  162.880005   96046400  0.010924  \n",
              "494  156.720001  156.800003  156.800003   95623200  0.000000  \n",
              "495  155.380005  156.570007  156.570007   88063200  0.004233  \n",
              "496  158.929993  163.639999  163.639999  130216800  0.027567  \n",
              "\n",
              "[497 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d35a049e-1241-4297-8593-cc6dc360023f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>reward</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020-05-11</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2020-05-11</td>\n",
              "      <td>77.025002</td>\n",
              "      <td>79.262497</td>\n",
              "      <td>76.809998</td>\n",
              "      <td>78.752502</td>\n",
              "      <td>78.225410</td>\n",
              "      <td>145946400</td>\n",
              "      <td>0.022428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2020-05-12</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2020-05-12</td>\n",
              "      <td>79.457497</td>\n",
              "      <td>79.922501</td>\n",
              "      <td>77.727501</td>\n",
              "      <td>77.852501</td>\n",
              "      <td>77.331436</td>\n",
              "      <td>162301200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-05-13</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2020-05-13</td>\n",
              "      <td>78.037498</td>\n",
              "      <td>78.987503</td>\n",
              "      <td>75.802498</td>\n",
              "      <td>76.912498</td>\n",
              "      <td>76.397720</td>\n",
              "      <td>200622400</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2020-05-14</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2020-05-14</td>\n",
              "      <td>76.127502</td>\n",
              "      <td>77.447502</td>\n",
              "      <td>75.382500</td>\n",
              "      <td>77.385002</td>\n",
              "      <td>76.867065</td>\n",
              "      <td>158929200</td>\n",
              "      <td>0.016518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2020-05-15</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2020-05-15</td>\n",
              "      <td>75.087502</td>\n",
              "      <td>76.974998</td>\n",
              "      <td>75.052498</td>\n",
              "      <td>76.927498</td>\n",
              "      <td>76.412621</td>\n",
              "      <td>166348400</td>\n",
              "      <td>0.024505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>492</td>\n",
              "      <td>2022-04-22</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2022-04-22</td>\n",
              "      <td>166.460007</td>\n",
              "      <td>167.869995</td>\n",
              "      <td>161.500000</td>\n",
              "      <td>161.789993</td>\n",
              "      <td>161.789993</td>\n",
              "      <td>84775200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>493</td>\n",
              "      <td>2022-04-25</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2022-04-25</td>\n",
              "      <td>161.119995</td>\n",
              "      <td>163.169998</td>\n",
              "      <td>158.460007</td>\n",
              "      <td>162.880005</td>\n",
              "      <td>162.880005</td>\n",
              "      <td>96046400</td>\n",
              "      <td>0.010924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>494</td>\n",
              "      <td>2022-04-26</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2022-04-26</td>\n",
              "      <td>162.250000</td>\n",
              "      <td>162.339996</td>\n",
              "      <td>156.720001</td>\n",
              "      <td>156.800003</td>\n",
              "      <td>156.800003</td>\n",
              "      <td>95623200</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>495</td>\n",
              "      <td>2022-04-27</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2022-04-27</td>\n",
              "      <td>155.910004</td>\n",
              "      <td>159.789993</td>\n",
              "      <td>155.380005</td>\n",
              "      <td>156.570007</td>\n",
              "      <td>156.570007</td>\n",
              "      <td>88063200</td>\n",
              "      <td>0.004233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>496</td>\n",
              "      <td>2022-04-28</td>\n",
              "      <td>00:00</td>\n",
              "      <td>2022-04-28</td>\n",
              "      <td>159.250000</td>\n",
              "      <td>164.520004</td>\n",
              "      <td>158.929993</td>\n",
              "      <td>163.639999</td>\n",
              "      <td>163.639999</td>\n",
              "      <td>130216800</td>\n",
              "      <td>0.027567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>497 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d35a049e-1241-4297-8593-cc6dc360023f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d35a049e-1241-4297-8593-cc6dc360023f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d35a049e-1241-4297-8593-cc6dc360023f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Adding rewards to dataset \n",
        "\n",
        "stocks = [\"AAPL\"]\n",
        "\n",
        "for ticker in stocks:\n",
        "    df = pd.read_csv(f'./datasets/{ticker}day.csv')\n",
        "    reward = []\n",
        "    for i in range(len(df)):\n",
        "        reward_day = (df[\"Close\"][i] - df[\"Open\"][i]) / df[\"Open\"][i]\n",
        "        if reward_day < 0:\n",
        "            reward_day = 0\n",
        "        reward.append(reward_day)\n",
        "    df[\"reward\"] = reward\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN1DBaHoGoGS"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# fig = plt.figure(1)\t#identifies the figure \n",
        "# plt.figure(figsize=(20, 10))\n",
        "# plt.title(\"Reward\", fontsize='16')\t#title\n",
        "# plt.plot(df[\"reward\"][:100])\t#plot the points\n",
        "# plt.xlabel(\"X\",fontsize='13')\t#adds a label in the x axis\n",
        "# plt.ylabel(\"Y\",fontsize='13')\t#adds a label in the y axis\n",
        "# plt.legend(('YvsX'),loc='best')\t#creates a legend to identify the plot\n",
        "# plt.grid()\t#shows a grid under the plot\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select usefull columns\n",
        "df = df[['Open', 'Close', 'Volume']]\n",
        "df"
      ],
      "metadata": {
        "id": "md2Qrid0y8k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c0mxj7IXWd97"
      },
      "outputs": [],
      "source": [
        "dataset_size = len(df)\n",
        "training_size = round(dataset_size * 0.80)\n",
        "train_data = df[:training_size]\n",
        "test_data  = df[training_size:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = df.iloc[:800, 1:2].values\n",
        "test_set = df.iloc[800:, 1:2].values\n",
        "look_back = 7 \n",
        "\n",
        "\n",
        "# Feature Scaling\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "training_set_scaled = sc.fit_transform(training_set)\n",
        "\n",
        "# Creating a data structure\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(look_back, dataset_size):\n",
        "    X_train.append(training_set_scaled[i - look_back:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "gRjOcQdrxuVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qN9iSIOJ-jf"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "#Adding the first LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "# Adding the output layer\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compiling the RNN\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Portfolio Formation"
      ],
      "metadata": {
        "id": "fXnaXMu76BOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict Rewards"
      ],
      "metadata": {
        "id": "zve8D4K8V_Wj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdLhodtrER3-"
      },
      "source": [
        "# Trading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra4jsEiQETdS"
      },
      "outputs": [],
      "source": [
        "from Trading_Metrics import trade, metrics\n",
        "\n",
        "\n",
        "# Load the Decisions\n",
        "actions_long = pd.read_csv(\"resultEnsembleTest_Long.csv\")\n",
        "actions_short = pd.read_csv(\"resultEnsembleTest_Short.csv\")\n",
        "df = pd.read_csv(\"datasets/aaplDay.csv\")\n",
        "# Drop the useless columns\n",
        "# df = df.reindex(columns = ['Date', 'Open', 'Close'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XNeq32VQ6srJ",
        "TQHQXXVae2BI",
        "oLHz-kgw51Nw",
        "xpBKOUWv5ZZu",
        "KkHtF2IE5mJ6",
        "u9I7FPPFAeDp",
        "zdLhodtrER3-"
      ],
      "name": "Portfolio Formation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}