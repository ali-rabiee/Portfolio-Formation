{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-rabiee/Portfolio-Formation/blob/main/Portfolio_Formation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_weG2085js1I"
      },
      "source": [
        "# Requirements & Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO48s139j1ux"
      },
      "outputs": [],
      "source": [
        "!pip3 install Keras\n",
        "!pip3 install keras-rl\n",
        "!pip install tensorflow==1.15\n",
        "!pip install keras\n",
        "!pip install keras-rl\n",
        "!pip install gym\n",
        "!pip install pandas\n",
        "!pip install rl\n",
        "!pip install keras-rl2\n",
        "!pip install Callbacks \n",
        "!pip install callbacks\n",
        "!pip install rl.callbacks\n",
        "!pip install tf-nightly\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive Connection"
      ],
      "metadata": {
        "id": "4pEH2djqcrQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "os.chdir('drive/My Drive/Colab Notebooks/DQN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKy9ZcaPcvD9",
        "outputId": "77492591-8539-4d57-a855-9764be6eacb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparing"
      ],
      "metadata": {
        "id": "CjjvgBnm41PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from get_stock import get_stock\n",
        "\n",
        "# Get stocks\n",
        "stocks = [\"MRNA\", \"PFE\", \"JNJ\", \"GOOGL\", \n",
        "          \"FB\", \"AAPL\", \"COST\", \"WMT\", \"KR\", \"JPM\", \n",
        "          \"BAC\", \"HSBC\"]\n",
        "\n",
        "start = \"2020-04-20\"\n",
        "end = \"2022-04-10\"\n",
        "\n",
        "for ticker in stocks:\n",
        "    # Download datasets\n",
        "    Hour = get_stock(ticker, start, end, \"60m\")\n",
        "    Day = get_stock(ticker, start, end, \"1d\")\n",
        "    Week = get_stock(ticker, start, end, \"1wk\")\n",
        "\n",
        "    # Drop an useless row\n",
        "    # this line is for yahoo finance datasets\n",
        "    # if the code does not error in training stage uncomment it. \n",
        "    Hour = Hour.drop(Hour.index[1757])\n",
        "    \n",
        "    # Reset indexes\n",
        "    Hour.reset_index(drop=True, inplace=True)\n",
        "    Day.reset_index(drop=True, inplace=True)\n",
        "    Week.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Save the datasets\n",
        "    PATH = \"datasets/\"\n",
        "    Hour.to_csv(f\"{PATH}{ticker}hour.csv\")\n",
        "    Day.to_csv(f\"{PATH}{ticker}day.csv\")\n",
        "    Week.to_csv(f\"{PATH}{ticker}week.csv\")\n"
      ],
      "metadata": {
        "id": "wqSrnQ8_45PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwdGjA34GIBc"
      },
      "source": [
        "# Train the DQN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56xe9An9nMDH"
      },
      "source": [
        "The code needs three positional parameters to be correctly executed: \\\\\n",
        "python main.py [numberOfActions, isOnlyShort, ensembleFolder]\n",
        "\n",
        "\n",
        "* To run the FULL agent you need to run: python main.py 3 0 ensembleFolder\n",
        "* To run the ONLY LONG agent you need to run: python main.py 2 0 ensembleFolder\n",
        "* To run the ONLY SHORT agent you need to run: python main.py 2 1 ensembleFolder \\\\\n",
        "where the paramenter ensembleFolder is used to set the name of the folder in which you'll get your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR_r2Ivdw-KN"
      },
      "outputs": [],
      "source": [
        "\"\"\"This is the class call for the Agent which will perform the experiment\"\"\"\n",
        "\n",
        "#This is the class call for the Agent which will perform the experiment\n",
        "from deepQTrading import DeepQTrading\n",
        "\n",
        "#Date library to manipulate time in the source code\n",
        "import datetime\n",
        "\n",
        "#Keras library to define the NN to be used\n",
        "from keras.models import Sequential\n",
        "\n",
        "#Layers used in the NN considered\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "\n",
        "#Activation Layers used in the source code\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU, ReLU\n",
        "\n",
        "#Optimizer used in the NN\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#Libraries used for the Agent considered\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "\n",
        "\n",
        "#Library used for showing the exception in the case of error \n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ensemble import perc_ensemble, full_ensemble\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "\n",
        "'''\n",
        "There are three actions possible in the stock market\n",
        "Hold(id 0): do nothing.\n",
        "Long(id 1): It predicts that the stock market value will raise at the end of the day. \n",
        "So, the action performed in this case is buying at the beginning of the day and sell it at the end of the day (aka long).\n",
        "Short(id 2): It predicts that the stock market value will decrease at the end of the day.\n",
        "So, the action that must be done is selling at the beginning of the day and buy it at the end of the day (aka short). \n",
        "//////////////////////////////////////////////////////////////\n",
        "The Model is a simple NN considered. It is composed of:\n",
        "One flatten layer to get 68 dimensional vectors as input\n",
        "One dense layer with 35 neurons and LeakyRelu activation\n",
        "One final Dense Layer with the 3 actions considered\n",
        "the input is 20 observation days from the past, 8 observations from the past week and \n",
        "40 observations from the past hours\n",
        "//////////////////////////////////////////////////////////////\n",
        "Define the DeepQTrading class with the following parameters:\n",
        "explorations: 0.2 operations are random, and 100 epochs.\n",
        "in this case, epochs parameter is used because the Agent acts on daily basis, so its better to repeat the experiments several\n",
        "times so, its defined that each epoch will work on the data from training, validation and testing.\n",
        "trainSize: the size of the train data gotten from the dataset, we are setting 5 stock market years, or 1800 days\n",
        "validationSize: the size of the validation data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "testSize: the size of the testing data gotten from dataset, we are setting 6 stock market months, or 180 days\n",
        "outputFile: where the results will be written\n",
        "begin: where the walks will start from. We are defining January 1st of 2010\n",
        "end: where the walks will finish. We are defining February 22nd of 2019\n",
        "nOutput:number of walks\n",
        "'''\n",
        "# Set Parameters\n",
        "nb_actions = 2\n",
        "isOnlyShort = 1\n",
        "ensembleFolderName = \"ensembleFolder\"\n",
        "# ticker = \"AAPL\"\n",
        "\n",
        "# Define the model \n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1, 1, 68)))\n",
        "model.add(Dense(35, activation='linear'))\n",
        "model.add(LeakyReLU(alpha=.001))\n",
        "model.add(Dense(nb_actions))\n",
        "model.add(Activation('linear'))\n",
        "\n",
        "\n",
        "for ticker in stocks:\n",
        "\n",
        "    # Define the DeepQTrading class\n",
        "    dqt = DeepQTrading(\n",
        "        ticker=ticker,\n",
        "        model=model,\n",
        "        explorations=[(0.2, 1)],\n",
        "        trainSize=datetime.timedelta(days=30*8),\n",
        "        validationSize=datetime.timedelta(days=30*1),\n",
        "        testSize=datetime.timedelta(days=30*1),\n",
        "        outputFile=\"Output/csv/walks/walks\",\n",
        "        begin=datetime.datetime(2020, 6, 30, 0, 0, 0, 0),\n",
        "        end=datetime.datetime(2022, 4, 1, 0, 0, 0, 0),\n",
        "        nbActions=nb_actions,\n",
        "        isOnlyShort=isOnlyShort,\n",
        "        ensembleFolderName=ensembleFolderName\n",
        "        )\n",
        "    numwalks = dqt.run()\n",
        "    dqt.end()\n",
        "\n",
        "    # Preparing and saving the results\n",
        "    numDel = 0\n",
        "    for j in range(0, numwalks):\n",
        "        df = pd.read_csv(\"./Output/ensemble/ensembleFolder/walk\"+str(j)+\"ensemble_test.csv\", index_col='Date')\n",
        "\n",
        "        for deleted in range(1, numDel):\n",
        "            del df['iteration'+str(deleted)]\n",
        "        \n",
        "        if j == 0:\n",
        "            fulldf = perc_ensemble(df)\n",
        "        else:\n",
        "            fulldf = fulldf.append(perc_ensemble(df))\n",
        "\n",
        "    # Save results\n",
        "    PATH = \"./Output/results/\"\n",
        "    method = \"short\" if isOnlyShort == 1 else \"long\"\n",
        "    fulldf.to_csv(f\"{PATH}{ticker}_{method}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trading"
      ],
      "metadata": {
        "id": "zdLhodtrER3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Trading_Metrics import trade, metrics\n",
        "\n",
        "\n",
        "# Load the Decisions\n",
        "actions_long = pd.read_csv(\"resultEnsembleTest_Long.csv\")\n",
        "actions_short = pd.read_csv(\"resultEnsembleTest_Short.csv\")\n",
        "df = pd.read_csv(\"datasets/aaplDay.csv\")\n",
        "# Drop the useless columns\n",
        "# df = df.reindex(columns = ['Date', 'Open', 'Close'])"
      ],
      "metadata": {
        "id": "ra4jsEiQETdS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Portfolio Formation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}